---
title: "ç¬¬30å›: ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆå®Œå…¨ç‰ˆ: 30ç§’ã®é©šãâ†’æ•°å¼ä¿®è¡Œâ†’å®Ÿè£…ãƒã‚¹ã‚¿ãƒ¼"
emoji: "ğŸ¤–"
type: "tech"
topics: ["machinelearning", "agent", "rust", "elixir", "julia"]
published: true
---

# ç¬¬30å›: ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆå®Œå…¨ç‰ˆ â€” ReAct Loopãƒ»Tool Useãƒ»Planningãƒ»Memoryãƒ»Multi-Agentãƒ»MCP

> **ç¬¬29å›ã§RAGã«ã‚ˆã‚Šå¤–éƒ¨çŸ¥è­˜ã‚’æ¥ç¶šã—ãŸã€‚ä»Šå›ã¯çŸ¥è­˜ã ã‘ã§ãªã"è¡Œå‹•"ã§ãã‚‹AIã¸ â€” ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆå®Œå…¨ç‰ˆã€‚ReAct Loop / Tool Use / Planning / Memory / Multi-Agent / MCPã®å…¨é ˜åŸŸã‚’ç¶²ç¾…ã™ã‚‹ã€‚**

AIã¯"èª­ã‚€"ã‹ã‚‰"è¡Œå‹•ã™ã‚‹"å­˜åœ¨ã¸ã¨é€²åŒ–ã—ã¦ã„ã‚‹ã€‚ChatGPTã‚„Claudeã€Geminiã¯å˜ãªã‚‹ãƒ†ã‚­ã‚¹ãƒˆç”Ÿæˆå™¨ã§ã¯ãªãã€ãƒ„ãƒ¼ãƒ«ã‚’å‘¼ã³å‡ºã—ã€è¨ˆç”»ã‚’ç«‹ã¦ã€éå»ã®è¨˜æ†¶ã‚’å‚ç…§ã—ã€è¤‡æ•°ã®ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã¨å”èª¿ã—ã¦è¤‡é›‘ãªã‚¿ã‚¹ã‚¯ã‚’é‚è¡Œã™ã‚‹**ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆ**ã ã€‚

æœ¬è¬›ç¾©ã§ã¯ã€ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã®å…¨ä½“åƒã‚’å®Œå…¨ã«è§£èª¬ã™ã‚‹:

1. **ReAct LoopåŸºç¤** â€” Observation-Thought-Action-Repeat ã®ã‚µã‚¤ã‚¯ãƒ«
2. **Tool Useå®Œå…¨å®Ÿè£…** â€” Function Calling / Tool Registry / Error Handling
3. **Planningæ‰‹æ³•** â€” Zero-shot / Plan-and-Execute / ReWOO
4. **Memory Systems** â€” Short-term / Long-term / Episodic / Semantic / Vector Memory
5. **Multi-Agent** â€” Communication / Role Assignment / Consensus & Debate
6. **MCPå®Œå…¨è§£èª¬** â€” Model Context Protocol ã®ä»•æ§˜ã¨å®Ÿè£…
7. **å®Ÿè£…ç·¨** â€” ğŸ¦€ Rust Agent Engine + ğŸ”® Elixir Multi-Agent + âš¡ Julia Orchestration

ã“ã‚Œã¯Course IIIã®ç¬¬12å› â€” å®Ÿè·µç·¨ã®é›†å¤§æˆã§ã‚ã‚Šã€ç¬¬31å›MLOpsã¸ã®æ©‹æ¸¡ã—ã§ã‚‚ã‚ã‚‹ã€‚

:::message
**å‰æçŸ¥è­˜**: ç¬¬28å›(Prompt Engineering), ç¬¬29å›(RAG)ã€‚Rust/Julia/Elixirã®åŸºç¤ã¯ç¬¬9-19å›ã§ç¿’å¾—æ¸ˆã¿ã€‚
:::

```mermaid
graph TD
    A["ğŸ§  Agent Loop<br/>Observationâ†’Thoughtâ†’Action"] --> B["ğŸ› ï¸ Tool Use<br/>Function Calling"]
    B --> C["ğŸ“‹ Planning<br/>ReWOO/Hierarchical"]
    C --> D["ğŸ’¾ Memory<br/>Vector+Episodic"]
    D --> E["ğŸ‘¥ Multi-Agent<br/>Communication"]
    E --> F["ğŸ”Œ MCP<br/>Standard Protocol"]
    F --> G["ğŸš€ Production<br/>Rust+Elixir+Julia"]
    style A fill:#e3f2fd
    style G fill:#c8e6c9
```

**æ‰€è¦æ™‚é–“ã®ç›®å®‰**:

| ã‚¾ãƒ¼ãƒ³ | å†…å®¹ | æ™‚é–“ | é›£æ˜“åº¦ |
|:-------|:-----|:-----|:-------|
| Zone 0 | ã‚¯ã‚¤ãƒƒã‚¯ã‚¹ã‚¿ãƒ¼ãƒˆ | 30ç§’ | â˜…â˜†â˜†â˜†â˜† |
| Zone 1 | ä½“é¨“ã‚¾ãƒ¼ãƒ³ | 10åˆ† | â˜…â˜…â˜†â˜†â˜† |
| Zone 2 | ç›´æ„Ÿã‚¾ãƒ¼ãƒ³ | 15åˆ† | â˜…â˜…â˜…â˜†â˜† |
| Zone 3 | æ•°å¼ä¿®è¡Œã‚¾ãƒ¼ãƒ³ | 90åˆ† | â˜…â˜…â˜…â˜…â˜… |
| Zone 4 | å®Ÿè£…ã‚¾ãƒ¼ãƒ³ | 60åˆ† | â˜…â˜…â˜…â˜…â˜† |
| Zone 5 | å®Ÿé¨“ã‚¾ãƒ¼ãƒ³ | 30åˆ† | â˜…â˜…â˜…â˜…â˜† |
| Zone 6 | ç™ºå±•ã‚¾ãƒ¼ãƒ³ | 20åˆ† | â˜…â˜…â˜…â˜…â˜… |
| Zone 7 | æŒ¯ã‚Šè¿”ã‚Šã‚¾ãƒ¼ãƒ³ | 10åˆ† | â˜…â˜…â˜†â˜†â˜† |

---

## ğŸš€ 0. ã‚¯ã‚¤ãƒƒã‚¯ã‚¹ã‚¿ãƒ¼ãƒˆï¼ˆ30ç§’ï¼‰â€” ReAct Loopã‚’3è¡Œã§ä½“é¨“

**ã‚´ãƒ¼ãƒ«**: ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã®æœ¬è³ª Observationâ†’Thoughtâ†’Action ã‚’30ç§’ã§ä½“æ„Ÿã™ã‚‹ã€‚

ReAct [^1] ãƒ‘ã‚¿ãƒ¼ãƒ³ã‚’3è¡Œã§å‹•ã‹ã™ã€‚

```julia
using HTTP, JSON3

# Minimal ReAct loop: Thought â†’ Action â†’ Observation
function react_step(state::Dict, tools::Dict)
    # Thought: LLM decides next action (simplified: just take first tool)
    thought = "Need to search for $(state[:query])"

    # Action: Execute tool
    tool_name = "search"
    tool_input = state[:query]
    observation = tools[tool_name](tool_input)

    # State update
    state[:history] = push!(get(state, :history, []),
                            (thought=thought, action=tool_name, observation=observation))
    return state
end

# Define tool
tools = Dict(
    "search" => (query) -> "Found: $query is a programming language for AI agents"
)

# Run one ReAct step
state = Dict(:query => "What is Julia?", :history => [])
state = react_step(state, tools)

println("Thought: $(state[:history][1].thought)")
println("Action: $(state[:history][1].action)")
println("Observation: $(state[:history][1].observation)")
```

å‡ºåŠ›:
```
Thought: Need to search for What is Julia?
Action: search
Observation: Found: What is Julia? is a programming language for AI agents
```

**3è¡Œã§ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã®å¿ƒè‡“éƒ¨ã‚’å‹•ã‹ã—ãŸã€‚** ã“ã‚ŒãŒ ReAct [^1] ã :

- **Thought (æ¨è«–)**: æ¬¡ã«ä½•ã‚’ã™ã¹ãã‹è€ƒãˆã‚‹
- **Action (è¡Œå‹•)**: ãƒ„ãƒ¼ãƒ«ã‚’å‘¼ã³å‡ºã™
- **Observation (è¦³å¯Ÿ)**: çµæœã‚’å—ã‘å–ã‚‹

ã“ã®ãƒ«ãƒ¼ãƒ—ã‚’ç¹°ã‚Šè¿”ã™ã“ã¨ã§ã€ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã¯è¤‡é›‘ãªã‚¿ã‚¹ã‚¯ã‚’æ®µéšçš„ã«è§£æ±ºã—ã¦ã„ãã€‚

:::message
**progress: 3%** â€” Zone 0å®Œäº†ã€‚ReAct Loopã®æœ¬è³ªã‚’ä½“æ„Ÿã—ãŸã€‚Zone 1ã§ReActã‚’å‹•ã‹ã—ãªãŒã‚‰ç†è§£ã‚’æ·±ã‚ã‚‹ã€‚
:::

---

## ğŸ® 1. ä½“é¨“ã‚¾ãƒ¼ãƒ³ï¼ˆ10åˆ†ï¼‰â€” ReAct Loopå®Œå…¨ç‰ˆã‚’å‹•ã‹ã™

**ã‚´ãƒ¼ãƒ«**: ReAct Loopã‚’LLMå‘¼ã³å‡ºã—ã¨çµ„ã¿åˆã‚ã›ã¦ã€å®Ÿéš›ã®ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆå‹•ä½œã‚’è¦³å¯Ÿã™ã‚‹ã€‚

### 1.1 ReAct Loopã®æ§‹é€ 

ReAct [^1] (Reasoning + Acting) ã¯ã€æ¨è«–(Thought)ã¨è¡Œå‹•(Action)ã‚’äº¤äº’ã«ç¹°ã‚Šè¿”ã™ãƒ‘ãƒ©ãƒ€ã‚¤ãƒ ã ã€‚

```mermaid
graph LR
    A["ğŸ“¥ Input<br/>User Query"] --> B["ğŸ’­ Thought<br/>LLM Reasoning"]
    B --> C["âš™ï¸ Action<br/>Tool Call"]
    C --> D["ğŸ‘ï¸ Observation<br/>Tool Result"]
    D --> B
    B -->|"Goal Reached"| E["âœ… Final Answer"]
    style A fill:#e3f2fd
    style E fill:#c8e6c9
```

å¾“æ¥ã®Chain-of-Thought (CoT)ã¯ã€Œæ€è€ƒã®é€£é–ã€ã ã‘ã‚’æ‰±ã†ã€‚ReActã¯ãã“ã«ã€Œè¡Œå‹•ã€ã‚’çµ„ã¿è¾¼ã¿ã€å¤–éƒ¨ç’°å¢ƒã¨ç›¸äº’ä½œç”¨ã—ãªãŒã‚‰æ¨è«–ã§ãã‚‹ã€‚

### 1.2 ReAct Loopã®å®Ÿè£…

å®Œå…¨ãªReAct Loopã‚’å®Ÿè£…ã™ã‚‹ã€‚

```julia
using HTTP, JSON3

# Tool definition
mutable struct Tool
    name::String
    description::String
    function_::Function
end

# Agent state
mutable struct AgentState
    query::String
    history::Vector{NamedTuple}
    max_steps::Int
    current_step::Int
end

# LLM call (simplified: rule-based for demo)
function llm_think(state::AgentState, tools::Vector{Tool})
    # In production: call OpenAI/Anthropic API
    # Here: simple rule-based logic
    if state.current_step == 1
        return (thought="I need to search for the query",
                action="search",
                action_input=state.query)
    elseif state.current_step == 2
        last_obs = state.history[end].observation
        return (thought="I have the answer from search",
                action="finish",
                action_input=last_obs)
    else
        return (thought="Task complete",
                action="finish",
                action_input="Done")
    end
end

# Execute tool
function execute_tool(tool_name::String, tool_input::String, tools::Vector{Tool})
    for tool in tools
        if tool.name == tool_name
            return tool.function_(tool_input)
        end
    end
    return "Error: Tool not found"
end

# ReAct loop
function react_loop(query::String, tools::Vector{Tool}, max_steps::Int=5)
    state = AgentState(query, [], max_steps, 0)

    while state.current_step < max_steps
        state.current_step += 1

        # Step 1: Thought (LLM reasoning)
        decision = llm_think(state, tools)

        # Step 2: Action (Tool execution)
        if decision.action == "finish"
            push!(state.history, (thought=decision.thought,
                                  action=decision.action,
                                  observation=decision.action_input))
            break
        end

        observation = execute_tool(decision.action, decision.action_input, tools)

        # Step 3: Update state
        push!(state.history, (thought=decision.thought,
                              action=decision.action,
                              observation=observation))
    end

    return state
end

# Define tools
tools = [
    Tool("search", "Search the web for information",
         (query) -> "Julia is a high-level, high-performance programming language for technical computing."),
    Tool("calculator", "Perform arithmetic calculations",
         (expr) -> string(eval(Meta.parse(expr))))
]

# Run ReAct loop
result = react_loop("What is Julia?", tools)

# Print execution trace
for (i, step) in enumerate(result.history)
    println("\n--- Step $i ---")
    println("ğŸ’­ Thought: $(step.thought)")
    println("âš™ï¸ Action: $(step.action)")
    println("ğŸ‘ï¸ Observation: $(step.observation)")
end
```

å‡ºåŠ›:
```
--- Step 1 ---
ğŸ’­ Thought: I need to search for the query
âš™ï¸ Action: search
ğŸ‘ï¸ Observation: Julia is a high-level, high-performance programming language for technical computing.

--- Step 2 ---
ğŸ’­ Thought: I have the answer from search
âš™ï¸ Action: finish
ğŸ‘ï¸ Observation: Julia is a high-level, high-performance programming language for technical computing.
```

**ReAct Loopã®å®Ÿè¡Œãƒˆãƒ¬ãƒ¼ã‚¹ã‚’è¦³å¯Ÿã§ããŸã€‚** å„ã‚¹ãƒ†ãƒƒãƒ—ã§:
1. LLMãŒæ¬¡ã®è¡Œå‹•ã‚’æ±ºå®š (Thought)
2. ãƒ„ãƒ¼ãƒ«ã‚’å®Ÿè¡Œ (Action)
3. çµæœã‚’è¦³å¯Ÿ (Observation)
4. çŠ¶æ…‹ã‚’æ›´æ–°ã—ã¦ãƒ«ãƒ¼ãƒ—ç¶™ç¶š

### 1.3 ReAct vs Chain-of-Thought

| æ‰‹æ³• | æ¨è«– | è¡Œå‹• | å¤–éƒ¨æƒ…å ± | ãƒãƒ«ã‚·ãƒãƒ¼ã‚·ãƒ§ãƒ³å¯¾ç­– |
|:-----|:-----|:-----|:---------|:---------------------|
| **CoT** | âœ… å†…éƒ¨æ¨è«–ã®ã¿ | âŒ ãªã— | âŒ ãªã— | âŒ å¼±ã„ (æ¤œè¨¼æ‰‹æ®µãªã—) |
| **ReAct** | âœ… æ¨è«– + æ¤œè¨¼ | âœ… Toolå‘¼ã³å‡ºã— | âœ… Wikipedia/API | âœ… å¼·ã„ (å¤–éƒ¨æ¤œè¨¼) |

ReAct [^1] ã®è«–æ–‡ã§ã¯ã€HotpotQAãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ã§CoTã¨æ¯”è¼ƒ:
- **CoT**: æ­£è§£ç‡ 34.0%
- **ReAct**: æ­£è§£ç‡ **29.4% â†’ 34.0%** (Wikipediaãƒ„ãƒ¼ãƒ«åˆ©ç”¨ã§æ”¹å–„)
- **ReAct + CoT**: æ­£è§£ç‡ **36.5%** (æœ€è‰¯)

å¤–éƒ¨ãƒ„ãƒ¼ãƒ«ã«ã‚ˆã‚‹æ¤œè¨¼ãŒãƒãƒ«ã‚·ãƒãƒ¼ã‚·ãƒ§ãƒ³ã‚’å¤§å¹…ã«å‰Šæ¸›ã™ã‚‹ã“ã¨ãŒå®Ÿè¨¼ã•ã‚ŒãŸã€‚

### 1.4 ReAct Promptã®æ§‹é€ 

å®Ÿéš›ã®LLMå‘¼ã³å‡ºã—ã§ã¯ã€ä»¥ä¸‹ã®ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆã‚’ä½¿ã†:

```
You run in a loop of Thought, Action, Observation.
At the end of the loop you output an Answer.

Use Thought to describe your thoughts about the question you have been asked.
Use Action to run one of the actions available to you - then return PAUSE.
Observation will be the result of running those actions.

Your available actions are:

search:
e.g. search: "What is the capital of France?"
Searches Wikipedia and returns a summary.

calculate:
e.g. calculate: "2 + 2"
Evaluates a mathematical expression.

Example session:

Question: What is the population of Paris plus 1000?
Thought: I need to search for the population of Paris.
Action: search: "population of Paris"
PAUSE

You will be called again with this:

Observation: The population of Paris is approximately 2.16 million.

Thought: I need to add 1000 to this number.
Action: calculate: "2160000 + 1000"
PAUSE

You will be called again with this:

Observation: 2161000

Thought: I have the final answer.
Answer: The population of Paris plus 1000 is 2,161,000.
```

ã“ã®ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆãŒã€LLMã‚’ã€Œæ€è€ƒâ†’è¡Œå‹•â†’è¦³å¯Ÿã€ã®ãƒ«ãƒ¼ãƒ—ã«èª˜å°ã™ã‚‹ã€‚

:::message
**progress: 10%** â€” Zone 1å®Œäº†ã€‚ReAct Loopã®å®Ÿè£…ã‚’å‹•ã‹ã—ã€CoTã¨ã®é•ã„ã‚’ç†è§£ã—ãŸã€‚
:::

---

## ğŸ§© 2. ç›´æ„Ÿã‚¾ãƒ¼ãƒ³ï¼ˆ15åˆ†ï¼‰â€” ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã®å…¨ä½“åƒ

**ã‚´ãƒ¼ãƒ«**: ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã®å…¨ä½“æ§‹é€ ã‚’ä¿¯ç°ã—ã€æœ¬è¬›ç¾©ã§æ‰±ã†7ã¤ã®ã‚³ãƒ³ãƒãƒ¼ãƒãƒ³ãƒˆã®é–¢ä¿‚ã‚’ç†è§£ã™ã‚‹ã€‚

### 2.1 ãªãœã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆãŒå¿…è¦ã‹ï¼Ÿ

LLMã¯å¼·åŠ›ã ãŒã€å˜ä½“ã§ã¯é™ç•ŒãŒã‚ã‚‹:

| é™ç•Œ | ä¾‹ | ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã«ã‚ˆã‚‹è§£æ±º |
|:-----|:---|:--------------------|
| **çŸ¥è­˜ã®é™³è…åŒ–** | ã€Œ2026å¹´ã®æœ€æ–°æƒ…å ±ã¯?ã€ | ğŸ› ï¸ Tool Use (Web Search) |
| **è¨ˆç®—ã®ä¸æ­£ç¢ºæ€§** | ã€Œ123456 Ã— 789012 = ?ã€ | ğŸ› ï¸ Tool Use (Calculator) |
| **é•·æœŸã‚¿ã‚¹ã‚¯ã®è¨ˆç”»ä¸è¶³** | ã€ŒWebã‚¢ãƒ—ãƒªã‚’ä½œã£ã¦ã€ | ğŸ“‹ Planning (Hierarchical) |
| **æ–‡è„ˆã®å¿˜å´** | ã€Œ3æ—¥å‰ã«ä½•ã‚’è©±ã—ãŸ?ã€ | ğŸ’¾ Memory (Long-term) |
| **å˜ä¸€è¦–ç‚¹ã®ãƒã‚¤ã‚¢ã‚¹** | ã€Œã“ã®è«–æ–‡ã¯æ­£ã—ã„?ã€ | ğŸ‘¥ Multi-Agent (Debate) |

ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã¯ã€ã“ã‚Œã‚‰ã®é™ç•Œã‚’**ãƒ„ãƒ¼ãƒ«ãƒ»è¨ˆç”»ãƒ»è¨˜æ†¶ãƒ»å”èª¿**ã§ä¹—ã‚Šè¶Šãˆã‚‹ã€‚

### 2.2 ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã®7ã‚³ãƒ³ãƒãƒ¼ãƒãƒ³ãƒˆ

```mermaid
graph TB
    subgraph "ğŸ§  Agent Core"
        A["1ï¸âƒ£ ReAct Loop<br/>Observationâ†’Thoughtâ†’Action"]
    end

    subgraph "ğŸ› ï¸ Capabilities"
        B["2ï¸âƒ£ Tool Use<br/>Function Calling"]
        C["3ï¸âƒ£ Planning<br/>Task Decomposition"]
        D["4ï¸âƒ£ Memory<br/>Context Management"]
    end

    subgraph "ğŸ‘¥ Collaboration"
        E["5ï¸âƒ£ Multi-Agent<br/>Communication"]
        F["6ï¸âƒ£ MCP<br/>Standard Protocol"]
    end

    subgraph "ğŸš€ Implementation"
        G["7ï¸âƒ£ Production<br/>Rust+Elixir+Julia"]
    end

    A --> B
    A --> C
    A --> D
    B --> E
    C --> E
    D --> E
    E --> F
    F --> G

    style A fill:#e3f2fd
    style G fill:#c8e6c9
```

æœ¬è¬›ç¾©ã§ã¯ã€ã“ã‚Œã‚‰7ã¤ã®ã‚³ãƒ³ãƒãƒ¼ãƒãƒ³ãƒˆã‚’é †ã«è§£èª¬ã™ã‚‹:

1. **ReAct LoopåŸºç¤** (Part A) â€” ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã®å¿ƒè‡“éƒ¨
2. **Tool Useå®Œå…¨å®Ÿè£…** (Part B) â€” å¤–éƒ¨ãƒ„ãƒ¼ãƒ«ã¨ã®æ¥ç¶š
3. **Planningæ‰‹æ³•** (Part C) â€” ã‚¿ã‚¹ã‚¯åˆ†è§£ã¨äº‹å‰è¨ˆç”»
4. **Memory Systems** (Part D) â€” çŸ­æœŸãƒ»é•·æœŸè¨˜æ†¶ã®ç®¡ç†
5. **Multi-Agent** (Part E) â€” è¤‡æ•°ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã®å”èª¿
6. **MCPå®Œå…¨è§£èª¬** (Part F) â€” æ¨™æº–åŒ–ãƒ—ãƒ­ãƒˆã‚³ãƒ«
7. **å®Ÿè£…ç·¨** (Part G) â€” Rust/Elixir/Juliaã§ã®å®Ÿè£…

### 2.3 ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã®å¿œç”¨ä¾‹

| å¿œç”¨ | ä½¿ç”¨ã‚³ãƒ³ãƒãƒ¼ãƒãƒ³ãƒˆ | å®Ÿä¾‹ |
|:-----|:------------------|:-----|
| **ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°ã‚¢ã‚·ã‚¹ã‚¿ãƒ³ãƒˆ** | ReAct + Tool Use | GitHub Copilot, Cursor |
| **ç ”ç©¶ã‚¢ã‚·ã‚¹ã‚¿ãƒ³ãƒˆ** | Planning + Memory + Tool Use | Elicit, Consensus |
| **ã‚½ãƒ•ãƒˆã‚¦ã‚§ã‚¢é–‹ç™º** | Multi-Agent + Planning | MetaGPT [^8], AutoGen [^9] |
| **ã‚¿ã‚¹ã‚¯è‡ªå‹•åŒ–** | ReAct + Tool Use | AutoGPT, BabyAGI |
| **Customer Support** | Memory + Tool Use | Intercom AI, Zendesk AI |

### 2.4 æœ¬è¬›ç¾©ã®æ§‹æˆ

| Part | å†…å®¹ | è¡Œæ•° | é›£æ˜“åº¦ |
|:-----|:-----|:-----|:-------|
| **Part A** | ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆåŸºç¤ (ReAct Loopå®Œå…¨ç‰ˆ) | ~700 | â˜…â˜…â˜… |
| **Part B** | Tool Useå®Œå…¨å®Ÿè£… | ~500 | â˜…â˜…â˜… |
| **Part C** | Planningæ‰‹æ³•å®Œå…¨ç‰ˆ | ~500 | â˜…â˜…â˜… |
| **Part D** | Memory Systemså®Œå…¨ç‰ˆ | ~500 | â˜…â˜…â˜… |
| **Part E** | Multi-Agentå®Œå…¨ç‰ˆ | ~600 | â˜…â˜…â˜…â˜… |
| **Part F** | MCPå®Œå…¨è§£èª¬ | ~300 | â˜…â˜…â˜… |
| **Part G** | å®Ÿè£…ç·¨ (Rust/Elixir/Julia) | ~600 | â˜…â˜…â˜…â˜… |

åˆè¨ˆ ~3,700è¡Œã®å¤§å‹è¬›ç¾©ã¨ãªã‚‹ã€‚

:::message
**progress: 20%** â€” Zone 2å®Œäº†ã€‚ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã®å…¨ä½“åƒã¨7ã‚³ãƒ³ãƒãƒ¼ãƒãƒ³ãƒˆã®é–¢ä¿‚ã‚’ç†è§£ã—ãŸã€‚
:::

---

## ğŸ“ 3. æ•°å¼ä¿®è¡Œã‚¾ãƒ¼ãƒ³ï¼ˆ90åˆ†ï¼‰â€” ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆç†è«–å®Œå…¨ç‰ˆ

**ã‚´ãƒ¼ãƒ«**: ReAct / Tool Use / Planning / Memory / Multi-Agentã®æ•°å­¦çš„å®šå¼åŒ–ã‚’å®Œå…¨ã«ç†è§£ã™ã‚‹ã€‚

### Part A: ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆåŸºç¤ï¼ˆReAct Loopå®Œå…¨ç‰ˆï¼‰

#### 3.1 ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆç’°å¢ƒã®å®šå¼åŒ–

ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã¯**éƒ¨åˆ†è¦³æ¸¬ãƒãƒ«ã‚³ãƒ•æ±ºå®šéç¨‹ (POMDP)** ã¨ã—ã¦å®šå¼åŒ–ã•ã‚Œã‚‹ã€‚

**å®šç¾© (POMDP)**:

POMDP ã¯7ã¤çµ„ $\langle \mathcal{S}, \mathcal{A}, \mathcal{T}, \mathcal{R}, \Omega, \mathcal{O}, \gamma \rangle$ ã§å®šç¾©ã•ã‚Œã‚‹:

- $\mathcal{S}$: çŠ¶æ…‹ç©ºé–“ (State space)
- $\mathcal{A}$: è¡Œå‹•ç©ºé–“ (Action space)
- $\mathcal{T}: \mathcal{S} \times \mathcal{A} \times \mathcal{S} \to [0,1]$: çŠ¶æ…‹é·ç§»ç¢ºç‡ $P(s' \mid s, a)$
- $\mathcal{R}: \mathcal{S} \times \mathcal{A} \to \mathbb{R}$: å ±é…¬é–¢æ•°
- $\Omega$: è¦³æ¸¬ç©ºé–“ (Observation space)
- $\mathcal{O}: \mathcal{S} \times \mathcal{A} \times \Omega \to [0,1]$: è¦³æ¸¬ç¢ºç‡ $P(o \mid s', a)$
- $\gamma \in [0,1)$: å‰²å¼•ç‡

ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã¯ã€è¦³æ¸¬ $o_t \in \Omega$ ã«åŸºã¥ã„ã¦è¡Œå‹• $a_t \in \mathcal{A}$ ã‚’é¸æŠã—ã€ç’°å¢ƒã‹ã‚‰æ¬¡ã®è¦³æ¸¬ $o_{t+1}$ ã¨å ±é…¬ $r_t$ ã‚’å—ã‘å–ã‚‹ã€‚

#### 3.2 ReAct Loopã®æ•°å¼åŒ–

ReAct [^1] ãƒ«ãƒ¼ãƒ—ã¯ã€ä»¥ä¸‹ã®3ã‚¹ãƒ†ãƒƒãƒ—ã‚’ç¹°ã‚Šè¿”ã™:

1. **Observation (è¦³æ¸¬)**: ç’°å¢ƒã‹ã‚‰è¦³æ¸¬ $o_t$ ã‚’å—ã‘å–ã‚‹
2. **Thought (æ¨è«–)**: LLM $\pi_\theta$ ãŒè¡Œå‹•ã‚’é¸æŠ: $a_t \sim \pi_\theta(\cdot \mid o_{1:t}, a_{1:t-1}, \text{thought}_{1:t-1})$
3. **Action (è¡Œå‹•)**: è¡Œå‹• $a_t$ ã‚’å®Ÿè¡Œã—ã€è¦³æ¸¬ $o_{t+1}$ ã‚’å¾—ã‚‹

æ•°å¼ã§è¡¨ã™ã¨:

$$
\begin{align}
\text{thought}_t &= \text{LLM}(o_{1:t}, a_{1:t-1}, \text{thought}_{1:t-1}) \\
a_t &\sim \pi_\theta(\cdot \mid \text{thought}_t) \\
o_{t+1} &\sim P(\cdot \mid s_t, a_t)
\end{align}
$$

ã“ã“ã§ã€$\text{thought}_t$ ã¯æ¨è«–ãƒˆãƒ¬ãƒ¼ã‚¹ (reasoning trace) ã§ã‚ã‚Šã€LLMãŒç”Ÿæˆã™ã‚‹å†…éƒ¨çš„ãªæ€è€ƒéç¨‹ã‚’è¡¨ã™ã€‚

**CoTã¨ã®é•ã„**:

- **CoT**: $\text{thought}_t \to \text{thought}_{t+1}$ (æ€è€ƒã®ã¿)
- **ReAct**: $\text{thought}_t \to a_t \to o_{t+1} \to \text{thought}_{t+1}$ (æ€è€ƒâ†’è¡Œå‹•â†’è¦³æ¸¬)

ReActã¯ã€å¤–éƒ¨ç’°å¢ƒã¨ã®ç›¸äº’ä½œç”¨ (Action + Observation) ã‚’çµ„ã¿è¾¼ã‚€ã“ã¨ã§ã€CoTã®ãƒãƒ«ã‚·ãƒãƒ¼ã‚·ãƒ§ãƒ³å•é¡Œã‚’è»½æ¸›ã™ã‚‹ã€‚

#### 3.3 Agent Loopã®çŠ¶æ…‹é·ç§»å›³

```mermaid
stateDiagram-v2
    [*] --> Init
    Init --> Thought: Receive Query
    Thought --> ActionSelect: LLM Reasoning
    ActionSelect --> ToolCall: tool_name, args
    ActionSelect --> Finish: goal reached
    ToolCall --> Observation: execute tool
    Observation --> Thought: append to context
    Finish --> [*]: return answer
```

çŠ¶æ…‹é·ç§»ã®å„ã‚¹ãƒ†ãƒƒãƒ—:

1. **Init**: ã‚¯ã‚¨ãƒªå—ä¿¡ã€åˆæœŸçŠ¶æ…‹ $s_0$ ã‚’è¨­å®š
2. **Thought**: LLMãŒæ¨è«–ãƒˆãƒ¬ãƒ¼ã‚¹ $\text{thought}_t$ ã‚’ç”Ÿæˆ
3. **ActionSelect**: LLMãŒè¡Œå‹• $a_t$ ã‚’é¸æŠ (toolå‘¼ã³å‡ºã—ã¾ãŸã¯çµ‚äº†)
4. **ToolCall**: ãƒ„ãƒ¼ãƒ«å®Ÿè¡Œ $\text{result} = \text{tool}(a_t)$
5. **Observation**: è¦³æ¸¬ $o_{t+1} = \text{result}$ ã‚’ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆã«è¿½åŠ 
6. **Finish**: ç›®æ¨™é”æˆåˆ¤å®šã€æœ€çµ‚å›ç­”ã‚’è¿”ã™

#### 3.4 ReAct Loopã®çµ‚äº†æ¡ä»¶

ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã¯ã€ä»¥ä¸‹ã®ã„ãšã‚Œã‹ã®æ¡ä»¶ã§çµ‚äº†ã™ã‚‹:

1. **Goal Reached**: LLMãŒã€Œå›ç­”ãŒå¾—ã‚‰ã‚ŒãŸã€ã¨åˆ¤æ–­
2. **Max Steps**: æœ€å¤§ã‚¹ãƒ†ãƒƒãƒ—æ•° $T_{\max}$ ã«åˆ°é”
3. **Error**: ãƒ„ãƒ¼ãƒ«å®Ÿè¡Œå¤±æ•—ã‚„ã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆ

æ•°å¼ã§è¡¨ã™ã¨:

$$
\text{çµ‚äº†} \iff \begin{cases}
\text{LLM}(o_{1:t}, a_{1:t-1}) = \text{"Finish"} \\
t \geq T_{\max} \\
\text{Error occurred}
\end{cases}
$$

#### 3.5 ReAct Loopã®ã‚¨ãƒ©ãƒ¼ãƒãƒ³ãƒ‰ãƒªãƒ³ã‚°

ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã¯ã€ä»¥ä¸‹ã®ã‚¨ãƒ©ãƒ¼ã«å¯¾å‡¦ã™ã‚‹å¿…è¦ãŒã‚ã‚‹:

| ã‚¨ãƒ©ãƒ¼ç¨®é¡ | åŸå›  | å¯¾å‡¦æ³• |
|:---------|:-----|:-------|
| **Tool Execution Failure** | ãƒ„ãƒ¼ãƒ«å®Ÿè¡Œã‚¨ãƒ©ãƒ¼ | Retry (æœ€å¤§3å›) â†’ Fallback tool â†’ çµ‚äº† |
| **Timeout** | ãƒ„ãƒ¼ãƒ«å¿œç­”é…å»¶ | ã‚­ãƒ£ãƒ³ã‚»ãƒ« â†’ åˆ¥ãƒ„ãƒ¼ãƒ«è©¦è¡Œ |
| **Invalid Arguments** | LLMãŒä¸æ­£ãªå¼•æ•°ã‚’ç”Ÿæˆ | Validation â†’ ã‚¨ãƒ©ãƒ¼ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’Observationã«è¿½åŠ  â†’ Re-plan |
| **Infinite Loop** | åŒã˜è¡Œå‹•ã‚’ç¹°ã‚Šè¿”ã™ | Loop detection â†’ å¼·åˆ¶çµ‚äº† |

ã‚¨ãƒ©ãƒ¼ãƒãƒ³ãƒ‰ãƒªãƒ³ã‚°ã®æ•°å¼:

$$
o_{t+1} = \begin{cases}
\text{tool}(a_t) & \text{if execution succeeds} \\
\text{"Error: " + error\_message} & \text{if execution fails}
\end{cases}
$$

LLMã¯ã‚¨ãƒ©ãƒ¼ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’è¦³æ¸¬ã¨ã—ã¦å—ã‘å–ã‚Šã€åˆ¥ã®è¡Œå‹•ã‚’è©¦ã¿ã‚‹ã€‚

### Part B: Tool Useå®Œå…¨å®Ÿè£…

#### 3.6 Function Callingã®æ•°å¼åŒ–

Function Calling (Tool Use) ã¯ã€LLMãŒå¤–éƒ¨é–¢æ•°ã‚’å‘¼ã³å‡ºã™èƒ½åŠ›ã ã€‚

**å®šç¾© (Tool)**:

Tool $\mathcal{T}$ ã¯ã€ä»¥ä¸‹ã®3ã¤çµ„ã§å®šç¾©ã•ã‚Œã‚‹:

$$
\mathcal{T} = \langle \text{name}, \text{schema}, \text{function} \rangle
$$

- $\text{name}$: ãƒ„ãƒ¼ãƒ«å (æ–‡å­—åˆ—)
- $\text{schema}$: å…¥åŠ›ã‚¹ã‚­ãƒ¼ãƒ (JSON Schemaå½¢å¼)
- $\text{function}: \text{Args} \to \text{Result}$: å®Ÿè¡Œé–¢æ•°

ä¾‹: `search` ãƒ„ãƒ¼ãƒ«

```json
{
  "name": "search",
  "description": "Search the web for information",
  "parameters": {
    "type": "object",
    "properties": {
      "query": {
        "type": "string",
        "description": "The search query"
      }
    },
    "required": ["query"]
  }
}
```

#### 3.7 Tool Registryã®å®Ÿè£…

è¤‡æ•°ã®ãƒ„ãƒ¼ãƒ«ã‚’ç®¡ç†ã™ã‚‹ **Tool Registry** ã‚’å®šç¾©ã™ã‚‹:

$$
\mathcal{R} = \{ \mathcal{T}_1, \mathcal{T}_2, \ldots, \mathcal{T}_N \}
$$

Tool Registryã¯ã€ä»¥ä¸‹ã®æ“ä½œã‚’ã‚µãƒãƒ¼ãƒˆã™ã‚‹:

- $\text{register}(\mathcal{T})$: ãƒ„ãƒ¼ãƒ«ã‚’ç™»éŒ²
- $\text{get}(\text{name})$: ãƒ„ãƒ¼ãƒ«åã§ãƒ„ãƒ¼ãƒ«ã‚’å–å¾—
- $\text{list}()$: ç™»éŒ²æ¸ˆã¿ãƒ„ãƒ¼ãƒ«ã®ä¸€è¦§ã‚’è¿”ã™
- $\text{validate}(\text{name}, \text{args})$: å¼•æ•°ã®ãƒãƒªãƒ‡ãƒ¼ã‚·ãƒ§ãƒ³

#### 3.8 Tool Selection (ãƒ„ãƒ¼ãƒ«é¸æŠ)

LLMã¯ã€è¤‡æ•°ã®ãƒ„ãƒ¼ãƒ«ã‹ã‚‰æœ€é©ãªãƒ„ãƒ¼ãƒ«ã‚’é¸æŠã™ã‚‹ã€‚

$$
a_t^* = \arg\max_{a_t \in \mathcal{A}} \mathbb{E}_{o_{t+1} \sim P(\cdot \mid s_t, a_t)} [V(s_{t+1})]
$$

ã“ã“ã§ã€$V(s)$ ã¯çŠ¶æ…‹ $s$ ã®ä¾¡å€¤é–¢æ•° (Value function)ã€‚

å®Ÿéš›ã«ã¯ã€LLMãŒä»¥ä¸‹ã®ç¢ºç‡åˆ†å¸ƒã‹ã‚‰ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°ã™ã‚‹:

$$
P(a_t = \mathcal{T}_i \mid o_{1:t}) = \frac{\exp(\text{score}(\mathcal{T}_i, o_{1:t}))}{\sum_{j=1}^N \exp(\text{score}(\mathcal{T}_j, o_{1:t}))}
$$

$\text{score}(\mathcal{T}_i, o_{1:t})$ ã¯ã€ãƒ„ãƒ¼ãƒ« $\mathcal{T}_i$ ã®é©åˆåº¦ã‚¹ã‚³ã‚¢ (LLMãŒå†…éƒ¨çš„ã«è¨ˆç®—)ã€‚

#### 3.9 Argument Parsing & Validation

LLMãŒç”Ÿæˆã—ãŸå¼•æ•°ã¯ã€JSON Schemaã«åŸºã¥ã„ã¦ãƒãƒªãƒ‡ãƒ¼ã‚·ãƒ§ãƒ³ã•ã‚Œã‚‹ã€‚

$$
\text{valid}(\text{args}, \text{schema}) = \begin{cases}
\text{True} & \text{if args conforms to schema} \\
\text{False} & \text{otherwise}
\end{cases}
$$

ãƒãƒªãƒ‡ãƒ¼ã‚·ãƒ§ãƒ³å¤±æ•—æ™‚ã€ã‚¨ãƒ©ãƒ¼ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ãŒç”Ÿæˆã•ã‚Œã‚‹:

$$
\text{error\_message} = \text{"ValidationError: " + schema\_mismatch\_details}
$$

#### 3.10 Tool Execution & Error Handling

ãƒ„ãƒ¼ãƒ«å®Ÿè¡Œã¯ã€ä»¥ä¸‹ã®ãƒ•ãƒ­ãƒ¼ã§è¡Œã‚ã‚Œã‚‹:

```mermaid
graph LR
    A["ğŸ¯ Select Tool"] --> B["âœ… Validate Args"]
    B -->|"Valid"| C["âš™ï¸ Execute"]
    B -->|"Invalid"| E["âŒ ValidationError"]
    C -->|"Success"| D["ğŸ“¥ Result"]
    C -->|"Timeout"| F["â±ï¸ TimeoutError"]
    C -->|"Failure"| G["âŒ ExecutionError"]
    E --> H["ğŸ”„ Return Error to LLM"]
    F --> H
    G --> H
    D --> I["âœ… Observation"]
```

ã‚¨ãƒ©ãƒ¼ãƒãƒ³ãƒ‰ãƒªãƒ³ã‚°ã®æ•°å¼:

$$
o_{t+1} = \begin{cases}
\text{result} & \text{if execution succeeds} \\
\text{"ValidationError: " + details} & \text{if validation fails} \\
\text{"TimeoutError: " + timeout} & \text{if timeout} \\
\text{"ExecutionError: " + exception} & \text{if execution fails}
\end{cases}
$$

#### 3.11 Retryæˆ¦ç•¥

ãƒ„ãƒ¼ãƒ«å®Ÿè¡Œå¤±æ•—æ™‚ã€Retryæˆ¦ç•¥ã‚’é©ç”¨ã™ã‚‹:

$$
\text{retry\_count} = \begin{cases}
0 & \text{åˆå›å®Ÿè¡Œ} \\
\text{retry\_count} + 1 & \text{å¤±æ•—æ™‚ã€max\_retriesæœªæº€} \\
\text{abort} & \text{max\_retriesã«åˆ°é”}
\end{cases}
$$

Exponential Backoff with Jitterã‚’é©ç”¨:

$$
\text{wait\_time} = \min(2^{\text{retry\_count}} + \text{random}(0, 1), \text{max\_wait})
$$

### Part C: Planningæ‰‹æ³•å®Œå…¨ç‰ˆ

#### 3.12 Planning (è¨ˆç”») ã®å®šç¾©

Planning ã¯ã€ç›®æ¨™ $g$ ã‚’é”æˆã™ã‚‹ãŸã‚ã®è¡Œå‹•åˆ— $\mathbf{a} = (a_1, a_2, \ldots, a_T)$ ã‚’äº‹å‰ã«ç”Ÿæˆã™ã‚‹ãƒ—ãƒ­ã‚»ã‚¹ã ã€‚

**å®šç¾© (Planning Problem)**:

Planning Problemã¯ã€ä»¥ä¸‹ã®4ã¤çµ„ã§å®šç¾©ã•ã‚Œã‚‹:

$$
\langle \mathcal{S}, \mathcal{A}, \mathcal{T}, g \rangle
$$

- $\mathcal{S}$: çŠ¶æ…‹ç©ºé–“
- $\mathcal{A}$: è¡Œå‹•ç©ºé–“
- $\mathcal{T}: \mathcal{S} \times \mathcal{A} \to \mathcal{S}$: çŠ¶æ…‹é·ç§»é–¢æ•° (æ±ºå®šè«–çš„)
- $g \in \mathcal{S}$: ç›®æ¨™çŠ¶æ…‹

ç›®çš„: åˆæœŸçŠ¶æ…‹ $s_0$ ã‹ã‚‰ç›®æ¨™ $g$ ã«åˆ°é”ã™ã‚‹è¡Œå‹•åˆ— $\mathbf{a}$ ã‚’è¦‹ã¤ã‘ã‚‹:

$$
\mathbf{a}^* = \arg\min_{\mathbf{a}} \text{cost}(\mathbf{a}) \quad \text{s.t.} \quad \mathcal{T}(s_0, \mathbf{a}) = g
$$

#### 3.13 Zero-shot Planner

Zero-shot Plannerã¯ã€LLMãŒä¸€åº¦ã«å…¨ä½“ã®è¨ˆç”»ã‚’ç”Ÿæˆã™ã‚‹æ‰‹æ³•ã ã€‚

$$
\text{plan} = \text{LLM}(\text{query}, \text{tools})
$$

å‡ºåŠ›å½¢å¼:

```
Plan:
1. Search for "population of Paris"
2. Extract the population number
3. Calculate population + 1000
4. Return the result
```

**åˆ©ç‚¹**: ã‚·ãƒ³ãƒ—ãƒ«ã€å®Ÿè£…å®¹æ˜“
**æ¬ ç‚¹**: è¤‡é›‘ãªã‚¿ã‚¹ã‚¯ã§å¤±æ•—ã—ã‚„ã™ã„ã€é€”ä¸­ã§ä¿®æ­£ä¸å¯

#### 3.14 Plan-and-Execute

Plan-and-Executeã¯ã€è¨ˆç”»ã¨å®Ÿè¡Œã‚’åˆ†é›¢ã™ã‚‹æ‰‹æ³•ã ã€‚

```mermaid
graph LR
    A["ğŸ“‹ Planner<br/>Generate Plan"] --> B["âš™ï¸ Executor<br/>Execute Steps"]
    B --> C["âœ… Done?"]
    C -->|"No"| D["ğŸ“Š Update Plan"]
    D --> B
    C -->|"Yes"| E["âœ… Final Answer"]
```

æ•°å¼:

$$
\begin{align}
\text{plan}_0 &= \text{Planner}(\text{query}) \\
\text{for } t &= 1, 2, \ldots, T: \\
&\quad a_t = \text{plan}_t[0] \quad \text{(first step)} \\
&\quad o_t = \text{Executor}(a_t) \\
&\quad \text{plan}_{t+1} = \text{Replanner}(\text{plan}_t, o_t)
\end{align}
$$

**åˆ©ç‚¹**: é€”ä¸­ã§è¨ˆç”»ã‚’ä¿®æ­£ã§ãã‚‹
**æ¬ ç‚¹**: Plannerã®å‘¼ã³å‡ºã—å›æ•°ãŒå¢—ãˆã‚‹

#### 3.15 Hierarchical Planning (éšå±¤çš„è¨ˆç”»)

Hierarchical Planning ã¯ã€ã‚¿ã‚¹ã‚¯ã‚’ã‚µãƒ–ã‚¿ã‚¹ã‚¯ã«å†å¸°çš„ã«åˆ†è§£ã™ã‚‹ã€‚

$$
\text{task} \to \{ \text{subtask}_1, \text{subtask}_2, \ldots, \text{subtask}_N \}
$$

å„ã‚µãƒ–ã‚¿ã‚¹ã‚¯ã¯ã€ã•ã‚‰ã«åˆ†è§£å¯èƒ½:

$$
\text{subtask}_i \to \{ \text{subtask}_{i,1}, \text{subtask}_{i,2}, \ldots \}
$$

çµ‚ç«¯æ¡ä»¶: ã‚µãƒ–ã‚¿ã‚¹ã‚¯ãŒ **atomic action** (ãƒ„ãƒ¼ãƒ«å‘¼ã³å‡ºã—) ã«ãªã‚‹ã€‚

#### 3.16 ReWOO (Reasoning WithOut Observation)

ReWOO [^3] ã¯ã€äº‹å‰ã«å…¨ã¦ã®è¨ˆç”»ã‚’ç«‹ã¦ã€ä¸¦åˆ—ã«ãƒ„ãƒ¼ãƒ«ã‚’å®Ÿè¡Œã™ã‚‹æ‰‹æ³•ã ã€‚

```mermaid
graph LR
    A["ğŸ“‹ Planner<br/>Plan all steps"] --> B["âš™ï¸ Worker<br/>Execute in parallel"]
    B --> C["ğŸ”— Solver<br/>Combine results"]
    C --> D["âœ… Final Answer"]
```

æ•°å¼:

$$
\begin{align}
\text{plan} &= \{ (a_1, \text{dep}_1), (a_2, \text{dep}_2), \ldots, (a_N, \text{dep}_N) \} \\
\text{results} &= \text{parallel\_execute}(\text{plan}) \\
\text{answer} &= \text{Solver}(\text{plan}, \text{results})
\end{align}
$$

ã“ã“ã§ã€$\text{dep}_i$ ã¯ä¾å­˜é–¢ä¿‚ (ã©ã®ã‚¹ãƒ†ãƒƒãƒ—ã®çµæœã‚’ä½¿ã†ã‹)ã€‚

**åˆ©ç‚¹**: ä¸¦åˆ—å®Ÿè¡Œã§é«˜é€Ÿã€ãƒˆãƒ¼ã‚¯ãƒ³æ¶ˆè²»ãŒå°‘ãªã„ (5xå‰Šæ¸› [^3])
**æ¬ ç‚¹**: å‹•çš„ãªå†è¨ˆç”»ãŒã§ããªã„ã€è¤‡é›‘ãªä¾å­˜é–¢ä¿‚ã«å¼±ã„

#### 3.17 HuggingGPTå‹ Orchestration

HuggingGPT [^10] ã¯ã€LLMãŒã‚¿ã‚¹ã‚¯ã‚’åˆ†è§£ã—ã€é©åˆ‡ãªãƒ¢ãƒ‡ãƒ«ã‚’é¸æŠã—ã¦å®Ÿè¡Œã™ã‚‹ã€‚

```mermaid
graph TD
    A["ğŸ“¥ User Query"] --> B["ğŸ“‹ Task Planning"]
    B --> C["ğŸ¤– Model Selection"]
    C --> D["âš™ï¸ Task Execution"]
    D --> E["ğŸ”— Response Generation"]
    E --> F["âœ… Final Answer"]
```

æ•°å¼:

$$
\begin{align}
\text{tasks} &= \text{TaskPlanner}(\text{query}) \\
\text{models} &= \text{ModelSelector}(\text{tasks}, \text{model\_zoo}) \\
\text{results} &= \{ \text{model}_i(\text{task}_i) \mid i = 1, \ldots, N \} \\
\text{answer} &= \text{ResponseGenerator}(\text{results})
\end{align}
$$

### Part D: Memory Systemså®Œå…¨ç‰ˆ

#### 3.18 Memoryã®åˆ†é¡

ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã®Memoryã¯ã€ä»¥ä¸‹ã®4ç¨®é¡ã«åˆ†é¡ã•ã‚Œã‚‹:

| Memory Type | ä¿æŒæœŸé–“ | å®¹é‡ | ç”¨é€” | å®Ÿè£… |
|:-----------|:---------|:-----|:-----|:-----|
| **Short-term** | 1ã‚»ãƒƒã‚·ãƒ§ãƒ³ | å° (~8K tokens) | ç¾åœ¨ã®ã‚¿ã‚¹ã‚¯ | LLM context window |
| **Long-term** | æ°¸ç¶š | å¤§ (ç„¡åˆ¶é™) | éå»ã®çµŒé¨“ | Vector DB / Graph DB |
| **Episodic** | æ°¸ç¶š | ä¸­ | ç‰¹å®šã®ã‚¤ãƒ™ãƒ³ãƒˆ | Timestamped logs |
| **Semantic** | æ°¸ç¶š | å¤§ | ä¸€èˆ¬çŸ¥è­˜ | Knowledge Graph |

#### 3.19 Short-term Memory

Short-term Memoryã¯ã€LLMã®ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆã‚¦ã‚£ãƒ³ãƒ‰ã‚¦ã«ä¿æŒã•ã‚Œã‚‹ã€‚

$$
\text{context}_t = [\text{query}, o_1, a_1, \ldots, o_{t-1}, a_{t-1}]
$$

ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆé•·åˆ¶é™:

$$
|\text{context}_t| \leq C_{\max} \quad \text{(e.g., 8K tokens)}
$$

åˆ¶é™ã‚’è¶…ãˆã‚‹å ´åˆã€ä»¥ä¸‹ã®æˆ¦ç•¥ã§åœ§ç¸®:

1. **Truncation**: å¤ã„å±¥æ­´ã‚’å‰Šé™¤
2. **Summarization**: LLMã§è¦ç´„
3. **Sliding Window**: æœ€æ–° $K$ ã‚¹ãƒ†ãƒƒãƒ—ã®ã¿ä¿æŒ

#### 3.20 Long-term Memory

Long-term Memoryã¯ã€å¤–éƒ¨ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã«æ°¸ç¶šåŒ–ã•ã‚Œã‚‹ã€‚

$$
\mathcal{M} = \{ (k_1, v_1), (k_2, v_2), \ldots, (k_N, v_N) \}
$$

- $k_i$: ã‚­ãƒ¼ (åŸ‹ã‚è¾¼ã¿ãƒ™ã‚¯ãƒˆãƒ«)
- $v_i$: å€¤ (è¨˜æ†¶å†…å®¹)

#### 3.21 Episodic Memory

Episodic Memoryã¯ã€ç‰¹å®šã®ã‚¤ãƒ™ãƒ³ãƒˆã‚’æ™‚ç³»åˆ—ã§è¨˜éŒ²ã™ã‚‹ã€‚

$$
\text{episode}_i = \langle \text{timestamp}, \text{event}, \text{context} \rangle
$$

ä¾‹: ã€Œ2026-02-13 15:30 â€” ãƒ¦ãƒ¼ã‚¶ãƒ¼ãŒãƒ‘ãƒªã®äººå£ã‚’è³ªå•ã€

æ¤œç´¢:

$$
\text{retrieve}(t_{\text{start}}, t_{\text{end}}) = \{ \text{episode}_i \mid t_{\text{start}} \leq \text{episode}_i.\text{timestamp} \leq t_{\text{end}} \}
$$

#### 3.22 Semantic Memory

Semantic Memoryã¯ã€ä¸€èˆ¬çš„ãªçŸ¥è­˜ã‚’ä¿æŒã™ã‚‹ã€‚

$$
\mathcal{G} = (\mathcal{V}, \mathcal{E})
$$

- $\mathcal{V}$: ãƒãƒ¼ãƒ‰ (æ¦‚å¿µ)
- $\mathcal{E}$: ã‚¨ãƒƒã‚¸ (é–¢ä¿‚)

ä¾‹: $(Paris, \text{capital\_of}, France)$

æ¤œç´¢:

$$
\text{query}(v) = \{ (v, r, v') \mid (v, r, v') \in \mathcal{E} \}
$$

#### 3.23 Vector Memory (RAGçµ±åˆ)

Vector Memoryã¯ã€ç¬¬29å›ã§å­¦ã‚“ã RAGã¨çµ±åˆã•ã‚Œã‚‹ã€‚

$$
\mathbf{q} = \text{Embed}(\text{query})
$$

é¡ä¼¼åº¦æ¤œç´¢:

$$
\text{topk}(\mathbf{q}, k) = \arg\text{topk}_{i} \langle \mathbf{q}, \mathbf{k}_i \rangle
$$

#### 3.24 Memory-Augmented Agent

Memory-Augmented Agentã¯ã€å„ã‚¹ãƒ†ãƒƒãƒ—ã§è¨˜æ†¶ã‚’æ¤œç´¢ãƒ»æ›´æ–°ã™ã‚‹ã€‚

```mermaid
graph LR
    A["ğŸ“¥ Query"] --> B["ğŸ” Retrieve<br/>from Memory"]
    B --> C["ğŸ’­ Thought<br/>with Memory"]
    C --> D["âš™ï¸ Action"]
    D --> E["ğŸ’¾ Update<br/>Memory"]
    E --> F["ğŸ‘ï¸ Observation"]
    F --> B
```

æ•°å¼:

$$
\begin{align}
\mathbf{m}_t &= \text{Retrieve}(\text{query}_t, \mathcal{M}) \\
\text{thought}_t &= \text{LLM}(o_{1:t}, \mathbf{m}_t) \\
\mathcal{M} &\leftarrow \mathcal{M} \cup \{ (k_t, v_t) \}
\end{align}
$$

#### 3.25 Forgetting Mechanism

Memoryå®¹é‡åˆ¶é™ã«å¯¾å‡¦ã™ã‚‹ãŸã‚ã€Forgetting Mechanismã‚’å°å…¥ã™ã‚‹ã€‚

$$
\text{score}(m_i) = \alpha \cdot \text{recency}(m_i) + \beta \cdot \text{importance}(m_i)
$$

- $\text{recency}(m_i)$: æœ€è¿‘ã‚¢ã‚¯ã‚»ã‚¹ã•ã‚ŒãŸã‹
- $\text{importance}(m_i)$: é‡è¦åº¦ (LLMãŒåˆ¤å®š)

å‰Šé™¤:

$$
\text{delete}(\mathcal{M}, k) = \mathcal{M} \setminus \{ m_i \mid \text{score}(m_i) < \text{threshold} \}
$$

### Part E: Multi-Agentå®Œå…¨ç‰ˆ

#### 3.26 Multi-Agent Systemã®å®šç¾©

Multi-Agent Systemã¯ã€è¤‡æ•°ã®ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆãŒå”èª¿ã—ã¦ã‚¿ã‚¹ã‚¯ã‚’é‚è¡Œã™ã‚‹ã‚·ã‚¹ãƒ†ãƒ ã ã€‚

$$
\mathcal{MAS} = \{ \mathcal{A}_1, \mathcal{A}_2, \ldots, \mathcal{A}_N \}
$$

å„ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆ $\mathcal{A}_i$ ã¯ã€ä»¥ä¸‹ã®è¦ç´ ã‚’æŒã¤:

- $\text{role}_i$: å½¹å‰² (Planner, Executor, Reviewer, etc.)
- $\pi_i$: ãƒãƒªã‚·ãƒ¼ (è¡Œå‹•é¸æŠæˆ¦ç•¥)
- $\mathcal{M}_i$: Memory

#### 3.27 Communication Protocol

ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆé–“ã®é€šä¿¡ã¯ã€ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ãƒ‘ãƒƒã‚·ãƒ³ã‚°ã§è¡Œã‚ã‚Œã‚‹ã€‚

$$
\text{message} = \langle \text{sender}, \text{receiver}, \text{content}, \text{timestamp} \rangle
$$

é€šä¿¡ãƒ—ãƒ­ãƒˆã‚³ãƒ«:

1. **Broadcast**: å…¨ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã«é€ä¿¡
2. **Unicast**: ç‰¹å®šã®ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã«é€ä¿¡
3. **Multicast**: ã‚°ãƒ«ãƒ¼ãƒ—ã«é€ä¿¡

#### 3.28 Role Assignment (å½¹å‰²å‰²ã‚Šå½“ã¦)

ã‚¿ã‚¹ã‚¯ã«å¿œã˜ã¦ã€ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã«å½¹å‰²ã‚’å‰²ã‚Šå½“ã¦ã‚‹ã€‚

$$
\text{assign}(\text{task}) = \{ (\mathcal{A}_i, \text{role}_i) \mid i = 1, \ldots, N \}
$$

ä¾‹:

| ã‚¿ã‚¹ã‚¯ | å½¹å‰² | ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆ |
|:------|:-----|:-----------|
| **ã‚½ãƒ•ãƒˆã‚¦ã‚§ã‚¢é–‹ç™º** | Product Manager | $\mathcal{A}_1$ |
|  | Architect | $\mathcal{A}_2$ |
|  | Engineer | $\mathcal{A}_3$ |
|  | Tester | $\mathcal{A}_4$ |

#### 3.29 Task Delegation (ã‚¿ã‚¹ã‚¯å§”è­²)

ã‚¿ã‚¹ã‚¯ã‚’ã‚µãƒ–ã‚¿ã‚¹ã‚¯ã«åˆ†å‰²ã—ã€å„ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã«å‰²ã‚Šå½“ã¦ã‚‹ã€‚

$$
\text{task} \to \{ \text{subtask}_1, \text{subtask}_2, \ldots, \text{subtask}_N \}
$$

å‰²ã‚Šå½“ã¦é–¢æ•°:

$$
\text{delegate}(\text{subtask}_i) = \arg\max_{\mathcal{A}_j} \text{capability}(\mathcal{A}_j, \text{subtask}_i)
$$

#### 3.30 Consensus & Debate

è¤‡æ•°ã®ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆãŒç•°ãªã‚‹å›ç­”ã‚’ç”Ÿæˆã—ãŸå ´åˆã€Consensus (åˆæ„) ã¾ãŸã¯Debate (è¨è«–) ã§çµ±ä¸€ã™ã‚‹ã€‚

**Majority Voting**:

$$
\text{answer}^* = \arg\max_{a} \sum_{i=1}^N \mathbb{1}[\text{answer}_i = a]
$$

**Confidence Weighting**:

$$
\text{answer}^* = \arg\max_{a} \sum_{i=1}^N \text{confidence}_i \cdot \mathbb{1}[\text{answer}_i = a]
$$

**Debate Protocol**:

1. å„ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆ $\mathcal{A}_i$ ãŒåˆæœŸå›ç­” $\text{answer}_i^{(0)}$ ã‚’ç”Ÿæˆ
2. ä»–ã®ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã®å›ç­”ã‚’è¦³å¯Ÿ
3. è¨è«–ãƒ©ã‚¦ãƒ³ãƒ‰ $t$: $\text{answer}_i^{(t)} = \text{LLM}_i(\text{answers}^{(t-1)}, \text{arguments}^{(t-1)})$
4. åæŸã¾ãŸã¯æœ€å¤§ãƒ©ã‚¦ãƒ³ãƒ‰æ•°ã«åˆ°é”

#### 3.31 Conflict Resolution (è¡çªè§£æ±º)

ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆé–“ã§çŸ›ç›¾ãŒç™ºç”Ÿã—ãŸå ´åˆã€Conflict Resolutionã§è§£æ±ºã™ã‚‹ã€‚

$$
\text{resolve}(\text{conflict}) = \begin{cases}
\text{Leader decides} & \text{éšå±¤çš„} \\
\text{Voting} & \text{æ°‘ä¸»çš„} \\
\text{External arbitrator} & \text{ç¬¬ä¸‰è€…åˆ¤å®š}
\end{cases}
$$

### Part F: MCP (Model Context Protocol) å®Œå…¨è§£èª¬

#### 3.32 MCPã®å‹•æ©Ÿ

å¾“æ¥ã€LLMã¨ãƒ„ãƒ¼ãƒ«/ãƒ‡ãƒ¼ã‚¿ã‚½ãƒ¼ã‚¹ã®æ¥ç¶šã¯ã€å„ã‚µãƒ¼ãƒ“ã‚¹ã”ã¨ã«ã‚«ã‚¹ã‚¿ãƒ å®Ÿè£…ãŒå¿…è¦ã ã£ãŸ:

- OpenAI â†’ Custom Plugin API
- Claude â†’ Custom Tool Use API
- Google Gemini â†’ Function Calling API

ã“ã‚Œã«ã‚ˆã‚Šã€ä»¥ä¸‹ã®å•é¡ŒãŒç™ºç”Ÿ:

1. **å®Ÿè£…ã‚³ã‚¹ãƒˆã®å¢—å¤§**: å„LLM Ã— å„ãƒ„ãƒ¼ãƒ«ã§å€‹åˆ¥å®Ÿè£…
2. **ãƒ¡ãƒ³ãƒ†ãƒŠãƒ³ã‚¹ã®å›°é›£**: APIå¤‰æ›´ã«è¿½å¾“å›°é›£
3. **äº’æ›æ€§ã®æ¬ å¦‚**: ãƒ„ãƒ¼ãƒ«ã‚’ä»–ã®LLMã§å†åˆ©ç”¨ä¸å¯

**MCP** [^11] ã¯ã€LLMã¨ãƒ„ãƒ¼ãƒ«é–“ã®**æ¨™æº–åŒ–ãƒ—ãƒ­ãƒˆã‚³ãƒ«**ã¨ã—ã¦2024å¹´11æœˆã«AnthropicãŒç™ºè¡¨ã—ãŸã€‚

#### 3.33 MCPã®ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£

```mermaid
graph LR
    A["ğŸ¤– LLM Client<br/>Claude/GPT/Gemini"] -->|"MCP Protocol"| B["ğŸ”Œ MCP Server<br/>Tool Provider"]
    B --> C["ğŸ› ï¸ Tools<br/>Search/DB/API"]
    B --> D["ğŸ“Š Resources<br/>Files/Docs"]
    B --> E["ğŸ¯ Prompts<br/>Templates"]

    style A fill:#e3f2fd
    style B fill:#fff3e0
```

MCPã¯ã€**Client-Server Architecture**ã‚’æ¡ç”¨:

- **MCP Client**: LLMå´ (Claude Desktop, VSCode, etc.)
- **MCP Server**: ãƒ„ãƒ¼ãƒ«æä¾›å´ (Filesystem, Database, Web API, etc.)

#### 3.34 MCP Specification

MCPä»•æ§˜ (2025-11-25ç‰ˆ) ã¯ã€ä»¥ä¸‹ã®4ã¤ã®ã‚³ã‚¢æ©Ÿèƒ½ã‚’å®šç¾©:

1. **Resources**: ãƒ•ã‚¡ã‚¤ãƒ«ãƒ»ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã¸ã®ã‚¢ã‚¯ã‚»ã‚¹
2. **Tools**: é–¢æ•°å‘¼ã³å‡ºã— (Function Calling)
3. **Prompts**: ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆ
4. **Sampling**: LLMå‘¼ã³å‡ºã—ã®ãƒªã‚¯ã‚¨ã‚¹ãƒˆ

#### 3.35 MCP Transport Layer

MCPã¯ã€**JSON-RPC 2.0** over **stdio** ã¾ãŸã¯ **HTTP/SSE** ã§ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’ã‚„ã‚Šå–ã‚Šã™ã‚‹ã€‚

**ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸å½¢å¼ (JSON-RPC 2.0)**:

```json
{
  "jsonrpc": "2.0",
  "id": 1,
  "method": "tools/list",
  "params": {}
}
```

**ãƒ¬ã‚¹ãƒãƒ³ã‚¹**:

```json
{
  "jsonrpc": "2.0",
  "id": 1,
  "result": {
    "tools": [
      {
        "name": "search",
        "description": "Search the web",
        "inputSchema": {
          "type": "object",
          "properties": {
            "query": { "type": "string" }
          },
          "required": ["query"]
        }
      }
    ]
  }
}
```

#### 3.36 MCP Tool Registration

MCP Serverã¯ã€`tools/list` ãƒ¡ã‚½ãƒƒãƒ‰ã§ç™»éŒ²æ¸ˆã¿ãƒ„ãƒ¼ãƒ«ã®ãƒªã‚¹ãƒˆã‚’è¿”ã™ã€‚

$$
\text{tools/list}() \to \{ \mathcal{T}_1, \mathcal{T}_2, \ldots, \mathcal{T}_N \}
$$

å„ãƒ„ãƒ¼ãƒ« $\mathcal{T}_i$ ã¯ã€ä»¥ä¸‹ã®æ§‹é€ ã‚’æŒã¤:

$$
\mathcal{T}_i = \langle \text{name}, \text{description}, \text{inputSchema} \rangle
$$

#### 3.37 MCP Tool Execution

MCP Clientã¯ã€`tools/call` ãƒ¡ã‚½ãƒƒãƒ‰ã§ãƒ„ãƒ¼ãƒ«ã‚’å®Ÿè¡Œã™ã‚‹ã€‚

$$
\text{tools/call}(\text{name}, \text{arguments}) \to \text{result}
$$

**ãƒªã‚¯ã‚¨ã‚¹ãƒˆ**:

```json
{
  "jsonrpc": "2.0",
  "id": 2,
  "method": "tools/call",
  "params": {
    "name": "search",
    "arguments": {
      "query": "What is Julia?"
    }
  }
}
```

**ãƒ¬ã‚¹ãƒãƒ³ã‚¹**:

```json
{
  "jsonrpc": "2.0",
  "id": 2,
  "result": {
    "content": [
      {
        "type": "text",
        "text": "Julia is a high-level programming language..."
      }
    ]
  }
}
```

#### 3.38 MCP Resources

MCP Serverã¯ã€ãƒ•ã‚¡ã‚¤ãƒ«ã‚„ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã‚’**Resource**ã¨ã—ã¦å…¬é–‹ã§ãã‚‹ã€‚

$$
\text{resources/list}() \to \{ r_1, r_2, \ldots, r_M \}
$$

å„ãƒªã‚½ãƒ¼ã‚¹ $r_i$ ã¯ã€ä»¥ä¸‹ã®æ§‹é€ ã‚’æŒã¤:

$$
r_i = \langle \text{uri}, \text{name}, \text{mimeType} \rangle
$$

ä¾‹:

```json
{
  "uri": "file:///home/user/notes.txt",
  "name": "My Notes",
  "mimeType": "text/plain"
}
```

#### 3.39 MCP Prompts

MCP Serverã¯ã€**Prompt Template**ã‚’æä¾›ã§ãã‚‹ã€‚

$$
\text{prompts/list}() \to \{ p_1, p_2, \ldots, p_K \}
$$

å„ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆ $p_i$ ã¯ã€ä»¥ä¸‹ã®æ§‹é€ ã‚’æŒã¤:

$$
p_i = \langle \text{name}, \text{description}, \text{arguments} \rangle
$$

ä¾‹:

```json
{
  "name": "code_review",
  "description": "Review code for bugs",
  "arguments": [
    {
      "name": "code",
      "description": "The code to review",
      "required": true
    }
  ]
}
```

#### 3.40 MCPæ¡ç”¨çŠ¶æ³

2024å¹´11æœˆã®ç™ºè¡¨ä»¥æ¥ã€æ€¥é€Ÿã«æ™®åŠ:

- **OpenAI**: ChatGPT Desktop (2025å¹´1æœˆå¯¾å¿œäºˆå®š)
- **Google DeepMind**: Gemini API (2025å¹´å¯¾å¿œæ¤œè¨ä¸­)
- **Tools**: Zed, Sourcegraph, Replit (å¯¾å¿œæ¸ˆã¿)
- **Connectors**: 1,000+ ã‚ªãƒ¼ãƒ—ãƒ³ã‚½ãƒ¼ã‚¹ã‚³ãƒã‚¯ã‚¿ (2025å¹´2æœˆæ™‚ç‚¹)

2025å¹´12æœˆã€Anthropicã¯MCPã‚’ **Agentic AI Foundation (AAIF)** ã«å¯„ä»˜ã—ã€Linux Foundationã®å‚˜ä¸‹ã§æ¨™æº–åŒ–ã‚’é€²ã‚ã‚‹ã€‚

:::message
**progress: 50%** â€” Zone 3 Part A-Få®Œäº†ã€‚ReAct / Tool Use / Planning / Memory / Multi-Agent / MCPã®æ•°å­¦çš„å®šå¼åŒ–ã‚’å®Œå…¨ã«ç†è§£ã—ãŸã€‚
:::

### Part G: å®Ÿè£…ç·¨ (Rust/Elixir/Julia)

ã“ã“ã¾ã§ã§ã€ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã®ç†è«–ã‚’å®Œå…¨ã«å­¦ã‚“ã ã€‚æ¬¡ã¯ã€å®Ÿè£…ç·¨ã ã€‚

#### 3.41 å®Ÿè£…ã®å…¨ä½“è¨­è¨ˆ

ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã‚·ã‚¹ãƒ†ãƒ ã¯ã€ä»¥ä¸‹ã®3å±¤ã§å®Ÿè£…ã™ã‚‹:

```mermaid
graph TD
    subgraph "âš¡ Julia Layer"
        A["Orchestration<br/>Planning & Execution"]
    end

    subgraph "ğŸ¦€ Rust Layer"
        B["Tool Registry<br/>State Machine"]
        C["Planning Engine"]
        D["Memory Storage<br/>Vector DB"]
    end

    subgraph "ğŸ”® Elixir Layer"
        E["Multi-Agent<br/>Actor Model"]
        F["GenServer<br/>Supervision"]
        G["Message Passing"]
    end

    A --> B
    A --> C
    A --> D
    A --> E
    E --> F
    E --> G

    style A fill:#c8e6c9
    style B fill:#fff3e0
    style E fill:#e1bee7
```

| Layer | å½¹å‰² | è¨€èªé¸æŠç†ç”± |
|:------|:-----|:------------|
| **âš¡ Julia** | Orchestration / Planning / Execution | æ•°å¼â†”ã‚³ãƒ¼ãƒ‰ 1:1å¯¾å¿œã€REPLé§†å‹•é–‹ç™º |
| **ğŸ¦€ Rust** | Tool Registry / State Machine / Memory Storage | Zero-copyã€å‹å®‰å…¨ã€C-ABI FFI |
| **ğŸ”® Elixir** | Multi-Agent / Actor Model / Fault Tolerance | BEAM VMã€Supervision Treeã€åˆ†æ•£ä¸¦è¡Œ |

#### 3.42 ğŸ¦€ Rust Agentå®Ÿè£…: Tool Registry

Rustã§ Tool Registry ã‚’å®Ÿè£…ã™ã‚‹ã€‚

```rust
use serde::{Deserialize, Serialize};
use std::collections::HashMap;
use thiserror::Error;

#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct ToolSchema {
    pub name: String,
    pub description: String,
    pub parameters: serde_json::Value, // JSON Schema
}

#[derive(Debug, Error)]
pub enum ToolError {
    #[error("Tool not found: {0}")]
    NotFound(String),
    #[error("Validation error: {0}")]
    Validation(String),
    #[error("Execution error: {0}")]
    Execution(String),
}

pub type ToolResult = Result<serde_json::Value, ToolError>;
pub type ToolFunction = fn(serde_json::Value) -> ToolResult;

pub struct Tool {
    pub schema: ToolSchema,
    pub function: ToolFunction,
}

pub struct ToolRegistry {
    tools: HashMap<String, Tool>,
}

impl ToolRegistry {
    pub fn new() -> Self {
        Self {
            tools: HashMap::new(),
        }
    }

    pub fn register(&mut self, tool: Tool) {
        self.tools.insert(tool.schema.name.clone(), tool);
    }

    pub fn get(&self, name: &str) -> Result<&Tool, ToolError> {
        self.tools
            .get(name)
            .ok_or_else(|| ToolError::NotFound(name.to_string()))
    }

    pub fn list(&self) -> Vec<&ToolSchema> {
        self.tools.values().map(|t| &t.schema).collect()
    }

    pub fn execute(&self, name: &str, args: serde_json::Value) -> ToolResult {
        let tool = self.get(name)?;
        // Validate args against schema (simplified)
        self.validate_args(&tool.schema, &args)?;
        (tool.function)(args)
    }

    fn validate_args(&self, schema: &ToolSchema, args: &serde_json::Value) -> Result<(), ToolError> {
        // In production: use jsonschema crate
        // Here: simplified validation
        if !args.is_object() {
            return Err(ToolError::Validation("Arguments must be an object".to_string()));
        }
        Ok(())
    }
}
```

ãƒ„ãƒ¼ãƒ«ç™»éŒ²:

```rust
fn search_tool(args: serde_json::Value) -> ToolResult {
    let query = args["query"]
        .as_str()
        .ok_or_else(|| ToolError::Validation("Missing query field".to_string()))?;

    // Simulate search
    let result = format!("Search results for: {}", query);
    Ok(serde_json::json!({ "result": result }))
}

let schema = ToolSchema {
    name: "search".to_string(),
    description: "Search the web".to_string(),
    parameters: serde_json::json!({
        "type": "object",
        "properties": {
            "query": { "type": "string" }
        },
        "required": ["query"]
    }),
};

let mut registry = ToolRegistry::new();
registry.register(Tool {
    schema,
    function: search_tool,
});

// Execute
let result = registry.execute("search", serde_json::json!({ "query": "Rust Agent" }));
println!("{:?}", result);
```

#### 3.43 ğŸ¦€ Rust Agentå®Ÿè£…: State Machine

Agent Loopã‚’State Machineã¨ã—ã¦å®Ÿè£…ã™ã‚‹ã€‚

```rust
use serde::{Deserialize, Serialize};

#[derive(Debug, Clone, Serialize, Deserialize)]
pub enum AgentState {
    Init,
    Thinking,
    ActionSelect,
    ToolCall,
    Observation,
    Finished,
    Error(String),
}

#[derive(Debug, Clone)]
pub struct AgentContext {
    pub query: String,
    pub history: Vec<AgentStep>,
    pub state: AgentState,
    pub max_steps: usize,
    pub current_step: usize,
}

#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct AgentStep {
    pub thought: String,
    pub action: String,
    pub observation: String,
}

pub struct Agent {
    context: AgentContext,
    registry: ToolRegistry,
}

impl Agent {
    pub fn new(query: String, registry: ToolRegistry, max_steps: usize) -> Self {
        Self {
            context: AgentContext {
                query,
                history: Vec::new(),
                state: AgentState::Init,
                max_steps,
                current_step: 0,
            },
            registry,
        }
    }

    pub fn step(&mut self) -> Result<(), ToolError> {
        match self.context.state {
            AgentState::Init => self.transition_to_thinking(),
            AgentState::Thinking => self.transition_to_action_select(),
            AgentState::ActionSelect => self.transition_to_tool_call(),
            AgentState::ToolCall => self.transition_to_observation(),
            AgentState::Observation => self.check_goal(),
            AgentState::Finished | AgentState::Error(_) => Ok(()),
        }
    }

    fn transition_to_thinking(&mut self) -> Result<(), ToolError> {
        self.context.state = AgentState::Thinking;
        Ok(())
    }

    fn transition_to_action_select(&mut self) -> Result<(), ToolError> {
        // In production: call LLM here
        // Simplified: hardcoded decision
        self.context.state = AgentState::ActionSelect;
        Ok(())
    }

    fn transition_to_tool_call(&mut self) -> Result<(), ToolError> {
        // In production: parse LLM output
        let action = "search";
        let args = serde_json::json!({ "query": self.context.query });

        match self.registry.execute(action, args) {
            Ok(result) => {
                self.context.history.push(AgentStep {
                    thought: "Need to search".to_string(),
                    action: action.to_string(),
                    observation: result.to_string(),
                });
                self.context.state = AgentState::Observation;
                Ok(())
            }
            Err(e) => {
                self.context.state = AgentState::Error(e.to_string());
                Err(e)
            }
        }
    }

    fn transition_to_observation(&mut self) -> Result<(), ToolError> {
        self.context.current_step += 1;
        self.context.state = AgentState::Observation;
        Ok(())
    }

    fn check_goal(&mut self) -> Result<(), ToolError> {
        // Simplified: finish after 1 step
        if self.context.current_step >= 1 {
            self.context.state = AgentState::Finished;
        } else {
            self.context.state = AgentState::Thinking;
        }
        Ok(())
    }

    pub fn run(&mut self) -> Result<Vec<AgentStep>, ToolError> {
        while !matches!(
            self.context.state,
            AgentState::Finished | AgentState::Error(_)
        ) {
            self.step()?;
            if self.context.current_step >= self.context.max_steps {
                break;
            }
        }
        Ok(self.context.history.clone())
    }
}
```

#### 3.44 ğŸ”® Elixir Multi-Agentå®Ÿè£…: Actor Model

Elixirã®GenServerã§ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã‚’Actorã¨ã—ã¦å®Ÿè£…ã™ã‚‹ã€‚

```elixir
defmodule Agent.Worker do
  use GenServer

  # Client API

  def start_link(opts) do
    GenServer.start_link(__MODULE__, opts, name: opts[:name])
  end

  def execute_task(agent, task) do
    GenServer.call(agent, {:execute, task})
  end

  # Server Callbacks

  @impl true
  def init(opts) do
    state = %{
      name: opts[:name],
      role: opts[:role],
      tools: opts[:tools] || [],
      history: []
    }
    {:ok, state}
  end

  @impl true
  def handle_call({:execute, task}, _from, state) do
    # Simulate task execution
    result = execute_agent_loop(task, state.tools)
    new_state = %{state | history: [result | state.history]}
    {:reply, result, new_state}
  end

  defp execute_agent_loop(task, tools) do
    # Simplified: return mock result
    %{task: task, status: :completed, result: "Task completed"}
  end
end
```

Multi-Agent Supervisor:

```elixir
defmodule Agent.Supervisor do
  use Supervisor

  def start_link(init_arg) do
    Supervisor.start_link(__MODULE__, init_arg, name: __MODULE__)
  end

  @impl true
  def init(_init_arg) do
    children = [
      {Agent.Worker, name: :planner, role: :planner},
      {Agent.Worker, name: :executor, role: :executor},
      {Agent.Worker, name: :reviewer, role: :reviewer}
    ]

    Supervisor.init(children, strategy: :one_for_one)
  end
end
```

Multi-Agent Communication:

```elixir
defmodule Agent.Coordinator do
  def delegate_task(task) do
    # Task decomposition
    subtasks = decompose(task)

    # Assign to agents
    results =
      Enum.map(subtasks, fn subtask ->
        agent = select_agent(subtask.type)
        Agent.Worker.execute_task(agent, subtask)
      end)

    # Combine results
    combine_results(results)
  end

  defp decompose(task) do
    # Simplified: split into 3 subtasks
    [
      %{type: :planning, description: "Plan task"},
      %{type: :execution, description: "Execute task"},
      %{type: :review, description: "Review result"}
    ]
  end

  defp select_agent(:planning), do: :planner
  defp select_agent(:execution), do: :executor
  defp select_agent(:review), do: :reviewer

  defp combine_results(results) do
    %{status: :completed, results: results}
  end
end
```

#### 3.45 âš¡ Julia Agent Orchestration

Juliaã§Orchestration Layerã‚’å®Ÿè£…ã™ã‚‹ã€‚

```julia
using HTTP, JSON3

# LLM client (simplified)
struct LLMClient
    api_key::String
    base_url::String
end

function call_llm(client::LLMClient, prompt::String)
    # In production: call OpenAI/Anthropic API
    # Simplified: return mock response
    return """
    Thought: I need to search for the query.
    Action: search
    Action Input: {"query": "What is Julia?"}
    """
end

# Planning
function plan_task(task::String)
    # In production: call LLM for planning
    return [
        (step=1, action="search", args=Dict("query" => task)),
        (step=2, action="finish", args=Dict())
    ]
end

# Execution
function execute_plan(plan::Vector, tools::Dict)
    results = []
    for step in plan
        if step.action == "finish"
            break
        end

        tool = tools[step.action]
        result = tool(step.args)
        push!(results, (step=step.step, result=result))
    end
    return results
end

# Orchestration
function orchestrate(query::String, tools::Dict)
    println("ğŸš€ Starting orchestration for: $query")

    # Step 1: Planning
    plan = plan_task(query)
    println("ğŸ“‹ Plan: $plan")

    # Step 2: Execution
    results = execute_plan(plan, tools)
    println("âœ… Results: $results")

    return results
end

# Define tools
tools = Dict(
    "search" => (args) -> "Julia is a high-level programming language",
    "calculator" => (args) -> eval(Meta.parse(args["expr"]))
)

# Run orchestration
orchestrate("What is Julia?", tools)
```

#### 3.46 Rust â†” Julia FFIé€£æº

Rustã®Tool Registryã‚’Juliaã‹ã‚‰å‘¼ã³å‡ºã™ã€‚

**Rustå´ (FFI Export)**:

```rust
#[no_mangle]
pub extern "C" fn tool_registry_new() -> *mut ToolRegistry {
    Box::into_raw(Box::new(ToolRegistry::new()))
}

#[no_mangle]
pub extern "C" fn tool_registry_execute(
    registry: *mut ToolRegistry,
    name: *const std::os::raw::c_char,
    args: *const std::os::raw::c_char,
) -> *mut std::os::raw::c_char {
    let registry = unsafe { &*registry };
    let name = unsafe { std::ffi::CStr::from_ptr(name).to_str().unwrap() };
    let args: serde_json::Value = unsafe {
        serde_json::from_str(std::ffi::CStr::from_ptr(args).to_str().unwrap()).unwrap()
    };

    match registry.execute(name, args) {
        Ok(result) => {
            let json = serde_json::to_string(&result).unwrap();
            std::ffi::CString::new(json).unwrap().into_raw()
        }
        Err(e) => {
            let error = format!("{{\"error\": \"{}\"}}", e);
            std::ffi::CString::new(error).unwrap().into_raw()
        }
    }
}
```

**Juliaå´ (FFI Import)**:

```julia
const LIBAGENT = "./target/release/libagent.so"

function tool_execute(name::String, args::Dict)
    registry = ccall((:tool_registry_new, LIBAGENT), Ptr{Cvoid}, ())

    result_ptr = ccall(
        (:tool_registry_execute, LIBAGENT),
        Ptr{Cchar},
        (Ptr{Cvoid}, Cstring, Cstring),
        registry,
        name,
        JSON3.write(args)
    )

    result_str = unsafe_string(result_ptr)
    return JSON3.read(result_str)
end

# Call from Julia
result = tool_execute("search", Dict("query" => "Rust FFI"))
println(result)
```

:::message
**progress: 85%** â€” Zone 3å®Œäº†ã€‚ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆç†è«–ã¨å®Ÿè£…ã®å…¨ä½“åƒã‚’å®Œå…¨ã«ç†è§£ã—ãŸã€‚
:::

---

## ğŸ’» 4. å®Ÿè£…ã‚¾ãƒ¼ãƒ³ï¼ˆ60åˆ†ï¼‰â€” Production Agent System

**ã‚´ãƒ¼ãƒ«**: Rust / Elixir / Juliaã‚’çµ„ã¿åˆã‚ã›ãŸæœ¬ç•ªå“è³ªã®ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã‚·ã‚¹ãƒ†ãƒ ã‚’æ§‹ç¯‰ã™ã‚‹ã€‚

### 4.1 ã‚·ã‚¹ãƒ†ãƒ å…¨ä½“æ§‹æˆ

```mermaid
graph TB
    subgraph "User Interface"
        A["ğŸŒ Web UI<br/>Phoenix LiveView"]
    end

    subgraph "âš¡ Julia Orchestration Layer"
        B["Planning Engine"]
        C["Execution Coordinator"]
    end

    subgraph "ğŸ¦€ Rust Core Layer"
        D["Tool Registry"]
        E["State Machine"]
        F["Vector Memory<br/>qdrant-client"]
    end

    subgraph "ğŸ”® Elixir Multi-Agent Layer"
        G["GenServer Agents"]
        H["Supervision Tree"]
        I["Message Passing"]
    end

    subgraph "External"
        J["ğŸŒ Web APIs"]
        K["ğŸ—„ï¸ Vector DB<br/>Qdrant"]
    end

    A --> B
    B --> C
    C --> D
    C --> E
    C --> F
    C --> G
    G --> H
    G --> I
    D --> J
    F --> K

    style A fill:#e3f2fd
    style B fill:#c8e6c9
    style D fill:#fff3e0
    style G fill:#e1bee7
```

### 4.2 ğŸ¦€ Rust: Tool Registry with Error Handling

å®Œå…¨ãªã‚¨ãƒ©ãƒ¼ãƒãƒ³ãƒ‰ãƒªãƒ³ã‚°ã‚’å®Ÿè£…ã™ã‚‹ã€‚

```rust
use std::time::Duration;
use tokio::time::timeout;

#[derive(Debug)]
pub struct ToolExecutionConfig {
    pub max_retries: usize,
    pub timeout_ms: u64,
    pub exponential_backoff: bool,
}

impl Default for ToolExecutionConfig {
    fn default() -> Self {
        Self {
            max_retries: 3,
            timeout_ms: 5000,
            exponential_backoff: true,
        }
    }
}

impl ToolRegistry {
    pub async fn execute_with_retry(
        &self,
        name: &str,
        args: serde_json::Value,
        config: &ToolExecutionConfig,
    ) -> ToolResult {
        let mut retry_count = 0;

        loop {
            match self.execute_with_timeout(name, args.clone(), config.timeout_ms).await {
                Ok(result) => return Ok(result),
                Err(e) if retry_count < config.max_retries => {
                    retry_count += 1;
                    let wait_ms = if config.exponential_backoff {
                        2_u64.pow(retry_count as u32) * 100
                    } else {
                        100
                    };
                    tokio::time::sleep(Duration::from_millis(wait_ms)).await;
                }
                Err(e) => return Err(e),
            }
        }
    }

    async fn execute_with_timeout(
        &self,
        name: &str,
        args: serde_json::Value,
        timeout_ms: u64,
    ) -> ToolResult {
        match timeout(
            Duration::from_millis(timeout_ms),
            async { self.execute(name, args) }
        ).await {
            Ok(result) => result,
            Err(_) => Err(ToolError::Execution(format!("Timeout after {}ms", timeout_ms))),
        }
    }
}
```

### 4.3 ğŸ¦€ Rust: Memory Storage (Vector DB Integration)

Qdrant Vector DBã¨é€£æºã™ã‚‹ã€‚

```rust
use qdrant_client::prelude::*;
use qdrant_client::qdrant::{CreateCollection, Distance, VectorParams};

pub struct VectorMemory {
    client: QdrantClient,
    collection_name: String,
}

impl VectorMemory {
    pub async fn new(url: &str, collection_name: &str) -> Result<Self, Box<dyn std::error::Error>> {
        let client = QdrantClient::from_url(url).build()?;

        // Create collection if not exists
        let _ = client.create_collection(&CreateCollection {
            collection_name: collection_name.to_string(),
            vectors_config: Some(VectorParams {
                size: 768, // embedding dimension
                distance: Distance::Cosine.into(),
                ..Default::default()
            }.into()),
            ..Default::default()
        }).await;

        Ok(Self {
            client,
            collection_name: collection_name.to_string(),
        })
    }

    pub async fn store(&self, id: u64, vector: Vec<f32>, payload: serde_json::Value) -> Result<(), Box<dyn std::error::Error>> {
        use qdrant_client::qdrant::{PointStruct, UpsertPoints};

        let points = vec![PointStruct::new(
            id,
            vector,
            payload,
        )];

        self.client.upsert_points(UpsertPoints {
            collection_name: self.collection_name.clone(),
            points,
            ..Default::default()
        }).await?;

        Ok(())
    }

    pub async fn search(&self, query_vector: Vec<f32>, top_k: usize) -> Result<Vec<serde_json::Value>, Box<dyn std::error::Error>> {
        use qdrant_client::qdrant::SearchPoints;

        let search_result = self.client.search_points(&SearchPoints {
            collection_name: self.collection_name.clone(),
            vector: query_vector,
            limit: top_k as u64,
            with_payload: Some(true.into()),
            ..Default::default()
        }).await?;

        Ok(search_result.result.into_iter().map(|point| {
            serde_json::from_str(&serde_json::to_string(&point.payload).unwrap()).unwrap()
        }).collect())
    }
}
```

### 4.4 ğŸ”® Elixir: Multi-Agent with Fault Tolerance

Supervision Treeã§éšœå®³è€æ€§ã‚’å®Ÿç¾ã™ã‚‹ã€‚

```elixir
defmodule Agent.Application do
  use Application

  @impl true
  def start(_type, _args) do
    children = [
      # Supervisor for agent workers
      {DynamicSupervisor, name: Agent.WorkerSupervisor, strategy: :one_for_one},
      # Agent coordinator
      Agent.Coordinator,
      # Message broker
      Agent.MessageBroker
    ]

    opts = [strategy: :one_for_one, name: Agent.MainSupervisor]
    Supervisor.start_link(children, opts)
  end
end

defmodule Agent.WorkerSupervisor do
  use DynamicSupervisor

  def start_link(init_arg) do
    DynamicSupervisor.start_link(__MODULE__, init_arg, name: __MODULE__)
  end

  @impl true
  def init(_init_arg) do
    DynamicSupervisor.init(strategy: :one_for_one)
  end

  def start_agent(role, opts) do
    spec = {Agent.Worker, Keyword.put(opts, :role, role)}
    DynamicSupervisor.start_child(__MODULE__, spec)
  end
end
```

Agent with Fault Recovery:

```elixir
defmodule Agent.Worker do
  use GenServer, restart: :transient

  @impl true
  def init(opts) do
    # Trap exits to handle crashes gracefully
    Process.flag(:trap_exit, true)

    state = %{
      name: opts[:name],
      role: opts[:role],
      tools: opts[:tools] || [],
      history: [],
      status: :idle
    }
    {:ok, state}
  end

  @impl true
  def handle_call({:execute, task}, _from, state) do
    state = %{state | status: :working}

    try do
      result = execute_agent_loop(task, state.tools)
      new_state = %{state | history: [result | state.history], status: :idle}
      {:reply, {:ok, result}, new_state}
    rescue
      e ->
        {:reply, {:error, Exception.message(e)}, %{state | status: :error}}
    end
  end

  @impl true
  def terminate(reason, state) do
    # Cleanup on shutdown
    IO.puts("Agent #{state.name} terminating: #{inspect(reason)}")
    :ok
  end
end
```

### 4.5 âš¡ Julia: Complete Orchestration with LLM Integration

å®Ÿéš›ã®LLM APIã¨çµ±åˆã™ã‚‹ã€‚

```julia
using HTTP, JSON3, Base64

# OpenAI API client
struct OpenAIClient
    api_key::String
    base_url::String
    model::String

    function OpenAIClient(;
        api_key::String=ENV["OPENAI_API_KEY"],
        base_url::String="https://api.openai.com/v1",
        model::String="gpt-4"
    )
        new(api_key, base_url, model)
    end
end

function call_llm(client::OpenAIClient, messages::Vector)
    headers = [
        "Authorization" => "Bearer $(client.api_key)",
        "Content-Type" => "application/json"
    ]

    body = JSON3.write(Dict(
        "model" => client.model,
        "messages" => messages,
        "temperature" => 0.7
    ))

    response = HTTP.post(
        "$(client.base_url)/chat/completions",
        headers,
        body
    )

    result = JSON3.read(String(response.body))
    return result.choices[1].message.content
end

# ReAct Agent with LLM
mutable struct ReActAgent
    client::OpenAIClient
    tools::Dict{String, Function}
    history::Vector
    max_steps::Int
end

function step!(agent::ReActAgent)
    # Build context from history
    messages = [
        Dict("role" => "system", "content" => build_system_prompt(agent.tools)),
        [Dict("role" => h.role, "content" => h.content) for h in agent.history]...
    ]

    # LLM reasoning
    response = call_llm(agent.client, messages)

    # Parse response
    action = parse_action(response)

    if action.type == "finish"
        return (status=:finished, answer=action.content)
    end

    # Execute tool
    tool_result = agent.tools[action.name](action.args)

    # Update history
    push!(agent.history, (role="assistant", content=response))
    push!(agent.history, (role="user", content="Observation: $tool_result"))

    return (status=:continue, observation=tool_result)
end

function run!(agent::ReActAgent, query::String)
    push!(agent.history, (role="user", content=query))

    for step in 1:agent.max_steps
        result = step!(agent)

        if result.status == :finished
            return result.answer
        end
    end

    return "Max steps reached"
end

# Build system prompt
function build_system_prompt(tools::Dict)
    tool_descriptions = join([
        "$(name): $(get(tool, :description, ""))"
        for (name, tool) in tools
    ], "\n")

    return """
    You are a helpful AI agent with access to the following tools:

    $tool_descriptions

    Use the following format:

    Thought: [your reasoning]
    Action: [tool name]
    Action Input: [arguments as JSON]

    Observation: [tool result will be provided]

    ... (repeat Thought/Action/Observation as needed)

    When you have the final answer, use:
    Thought: I have the final answer
    Final Answer: [your answer]
    """
end

# Parse LLM response
function parse_action(response::String)
    lines = split(response, "\n")

    for (i, line) in enumerate(lines)
        if startswith(line, "Final Answer:")
            return (type="finish", content=strip(replace(line, "Final Answer:" => "")))
        elseif startswith(line, "Action:")
            action_name = strip(replace(line, "Action:" => ""))
            action_input = i < length(lines) ? strip(replace(lines[i+1], "Action Input:" => "")) : "{}"
            return (type="tool", name=action_name, args=JSON3.read(action_input))
        end
    end

    return (type="thinking", content=response)
end
```

### 4.6 çµ±åˆä¾‹: Complete Agent System

3è¨€èªã‚’çµ±åˆã—ãŸã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã‚·ã‚¹ãƒ†ãƒ ã€‚

```julia
# Initialize components
client = OpenAIClient()

tools = Dict(
    "search" => (args) -> begin
        # Call Rust tool registry via FFI
        tool_execute("search", args)
    end,
    "calculator" => (args) -> begin
        eval(Meta.parse(args["expr"]))
    end
)

# Create agent
agent = ReActAgent(client, tools, [], 10)

# Run agent
answer = run!(agent, "What is 123 * 456 + 789?")
println("Final Answer: $answer")
```

Elixir Multi-Agent Orchestration:

```elixir
# Start supervision tree
{:ok, _} = Agent.Application.start(:normal, [])

# Spawn agents with different roles
{:ok, planner} = Agent.WorkerSupervisor.start_agent(:planner, [name: :planner])
{:ok, executor} = Agent.WorkerSupervisor.start_agent(:executor, [name: :executor])
{:ok, reviewer} = Agent.WorkerSupervisor.start_agent(:reviewer, [name: :reviewer])

# Coordinate multi-agent task
task = %{
  description: "Build a web application",
  requirements: ["Backend API", "Frontend UI", "Database"]
}

result = Agent.Coordinator.delegate_task(task)
IO.inspect(result)
```

:::message
**progress: 70%** â€” Zone 4å®Œäº†ã€‚Rust / Elixir / Juliaã‚’çµ±åˆã—ãŸæœ¬ç•ªå“è³ªã®ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã‚·ã‚¹ãƒ†ãƒ ã‚’æ§‹ç¯‰ã—ãŸã€‚
:::

---

## ğŸ”¬ 5. å®Ÿé¨“ã‚¾ãƒ¼ãƒ³ï¼ˆ30åˆ†ï¼‰â€” ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯

**ã‚´ãƒ¼ãƒ«**: AgentBenchã§æ€§èƒ½ã‚’è©•ä¾¡ã—ã€Planningæ‰‹æ³•ã‚’æ¯”è¼ƒã™ã‚‹ã€‚

### 5.1 AgentBenchæ¦‚è¦

AgentBench [^7] ã¯ã€LLMã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã‚’è©•ä¾¡ã™ã‚‹åŒ…æ‹¬çš„ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ã ã€‚8ã¤ã®ç’°å¢ƒã§è©•ä¾¡:

| ç’°å¢ƒ | ã‚¿ã‚¹ã‚¯ | è©•ä¾¡æŒ‡æ¨™ | é›£æ˜“åº¦ |
|:-----|:------|:---------|:-------|
| **HotpotQA** | Multi-hop QA (2-4ãƒ›ãƒƒãƒ—æ¨è«–) | Exact Match (EM), F1 | â˜…â˜…â˜… |
| **WebShop** | E-commerce navigation (å•†å“æ¤œç´¢ãƒ»è³¼å…¥) | Success Rate, Reward | â˜…â˜…â˜…â˜… |
| **ALFWorld** | Household tasks (ç‰©ä½“æ“ä½œ) | Success Rate | â˜…â˜…â˜… |
| **Mind2Web** | Web browsing (å®ŸWebã‚µã‚¤ãƒˆæ“ä½œ) | Element Accuracy, Success Rate | â˜…â˜…â˜…â˜…â˜… |
| **DB** | Database queries (SQLç”Ÿæˆãƒ»å®Ÿè¡Œ) | Execution Accuracy | â˜…â˜…â˜… |
| **KnowledgeGraph** | Knowledge reasoning (ã‚°ãƒ©ãƒ•æ¨è«–) | F1, Graph Edit Distance | â˜…â˜…â˜…â˜… |
| **OperatingSystem** | OS commands (Bashå®Ÿè¡Œ) | Success Rate, Command Correctness | â˜…â˜…â˜… |
| **DigitalCard** | Card game (æˆ¦ç•¥ã‚²ãƒ¼ãƒ ) | Win Rate, Avg Score | â˜…â˜…â˜…â˜… |

**AgentBenchã®ä¸»è¦çŸ¥è¦‹** (Liu+ 2023 [^7]):

1. **Top Commercial LLMs (GPT-4, Claude 3.5)** ã¯å…¨ç’°å¢ƒã§é«˜æ€§èƒ½ (å¹³å‡ Success Rate 60-70%)
2. **Open Source LLMs (Llama 3.1 70B)** ã¯å¤§å¹…ã«åŠ£ã‚‹ (å¹³å‡ 30-40%)
3. **Long-term Reasoning**ã¨**Decision-making**ãŒæœ€å¤§ã®ãƒœãƒˆãƒ«ãƒãƒƒã‚¯
4. **Tool Useèƒ½åŠ›**ã¯ã€AgentBenchæˆåŠŸã®å¿…è¦æ¡ä»¶

### 5.2 Planningæ‰‹æ³•ã®æ¯”è¼ƒå®Ÿé¨“

Zero-shot / Plan-and-Execute / ReWOOã‚’æ¯”è¼ƒã™ã‚‹ã€‚

```julia
using Statistics, DataFrames, CSV

# Benchmark on HotpotQA subset (2-hop reasoning)
function benchmark_planning_methods()
    # Dataset: 2-hop reasoning questions
    questions = [
        "What is the capital of the country where the Eiffel Tower is located?",
        "Who is the author of the book that inspired the movie 'The Shawshank Redemption'?",
        "What year did the company that makes the iPhone go public?",
        "In what city is the university where Albert Einstein worked in 1905 located?",
        "What is the population of the birthplace of Steve Jobs?"
    ]

    ground_truth = ["Paris", "Stephen King", "1980", "Bern", "San Francisco"]

    # Track detailed metrics
    results = Dict(
        "zero_shot" => Dict("correct" => [], "steps" => [], "tokens" => []),
        "plan_execute" => Dict("correct" => [], "steps" => [], "tokens" => []),
        "rewoo" => Dict("correct" => [], "steps" => [], "tokens" => [])
    )

    for (q, truth) in zip(questions, ground_truth)
        println("\nğŸ” Question: $q")
        println("Ground Truth: $truth")

        # Zero-shot ReAct
        zero_shot_result = run_zero_shot_agent(q)
        is_correct_zs = exact_match(zero_shot_result.answer, truth)
        push!(results["zero_shot"]["correct"], is_correct_zs)
        push!(results["zero_shot"]["steps"], zero_shot_result.steps)
        push!(results["zero_shot"]["tokens"], zero_shot_result.tokens)
        println("  Zero-shot: $(zero_shot_result.answer) | Steps: $(zero_shot_result.steps) | Correct: $is_correct_zs")

        # Plan-and-Execute
        plan_exec_result = run_plan_execute_agent(q)
        is_correct_pe = exact_match(plan_exec_result.answer, truth)
        push!(results["plan_execute"]["correct"], is_correct_pe)
        push!(results["plan_execute"]["steps"], plan_exec_result.steps)
        push!(results["plan_execute"]["tokens"], plan_exec_result.tokens)
        println("  Plan-Execute: $(plan_exec_result.answer) | Steps: $(plan_exec_result.steps) | Correct: $is_correct_pe")

        # ReWOO
        rewoo_result = run_rewoo_agent(q)
        is_correct_rw = exact_match(rewoo_result.answer, truth)
        push!(results["rewoo"]["correct"], is_correct_rw)
        push!(results["rewoo"]["steps"], rewoo_result.steps)
        push!(results["rewoo"]["tokens"], rewoo_result.tokens)
        println("  ReWOO: $(rewoo_result.answer) | Steps: $(rewoo_result.steps) | Correct: $is_correct_rw")
    end

    # Calculate aggregate metrics
    println("\nğŸ“Š Summary:")
    df = DataFrame(
        Method = String[],
        Accuracy = Float64[],
        AvgSteps = Float64[],
        AvgTokens = Float64[]
    )

    for (method, metrics) in results
        acc = mean(metrics["correct"]) * 100
        avg_steps = mean(metrics["steps"])
        avg_tokens = mean(metrics["tokens"])

        push!(df, (method, acc, avg_steps, avg_tokens))

        println("$method:")
        println("  Accuracy: $(round(acc, digits=2))%")
        println("  Avg Steps: $(round(avg_steps, digits=2))")
        println("  Avg Tokens: $(round(avg_tokens, digits=0))")
    end

    return df
end

function exact_match(pred::String, truth::String)
    return lowercase(strip(pred)) == lowercase(strip(truth)) ? 1.0 : 0.0
end

# Simulate Zero-shot ReAct agent
function run_zero_shot_agent(query::String)
    # Simplified simulation: realistic step count and token usage
    # Real: calls LLM API
    steps = rand(3:6)
    tokens = steps * 500  # ~500 tokens per step

    # Mock answer (in production: actual LLM output)
    answer = if contains(query, "Eiffel Tower")
        "Paris"
    elseif contains(query, "Shawshank")
        "Stephen King"
    elseif contains(query, "iPhone")
        "1980"
    elseif contains(query, "Einstein") && contains(query, "1905")
        "Bern"
    elseif contains(query, "Steve Jobs")
        "San Francisco"
    else
        "Unknown"
    end

    return (answer=answer, steps=steps, tokens=tokens)
end

# Simulate Plan-and-Execute agent
function run_plan_execute_agent(query::String)
    # Plan-and-Execute: fewer steps due to explicit planning
    steps = rand(2:4)
    tokens = steps * 600 + 300  # Planning overhead

    answer = if contains(query, "Eiffel Tower")
        "Paris"
    elseif contains(query, "Shawshank")
        "Stephen King"
    elseif contains(query, "iPhone")
        "1980"
    elseif contains(query, "Einstein") && contains(query, "1905")
        "Bern"
    elseif contains(query, "Steve Jobs")
        "San Francisco"
    else
        "Unknown"
    end

    return (answer=answer, steps=steps, tokens=tokens)
end

# Simulate ReWOO agent
function run_rewoo_agent(query::String)
    # ReWOO: parallel execution, fewer steps
    steps = rand(1:3)
    tokens = steps * 400  # 5x token reduction (Xu+ 2023)

    answer = if contains(query, "Eiffel Tower")
        "Paris"
    elseif contains(query, "Shawshank")
        "Stephen King"
    elseif contains(query, "iPhone")
        "1980"
    elseif contains(query, "Einstein") && contains(query, "1905")
        "Bern"
    elseif contains(query, "Steve Jobs")
        "San Francisco"
    else
        "Unknown"
    end

    return (answer=answer, steps=steps, tokens=tokens)
end

# Run benchmark
df = benchmark_planning_methods()

# Save results
CSV.write("planning_benchmark_results.csv", df)
println("\nâœ… Results saved to planning_benchmark_results.csv")
```

**äºˆæƒ³ã•ã‚Œã‚‹çµæœ** (å®Ÿéš›ã®LLM APIã‚’ä½¿ã£ãŸå ´åˆ):

| Method | Accuracy | Avg Steps | Avg Tokens |
|:-------|:---------|:----------|:-----------|
| Zero-shot | 60-70% | 4.5 | 2250 |
| Plan-Execute | 70-80% | 3.2 | 2220 |
| ReWOO | 65-75% | 2.1 | 840 |

**è€ƒå¯Ÿ**:

- **Zero-shot**: ã‚·ãƒ³ãƒ—ãƒ«ã ãŒã€æ¢ç´¢çš„ã«ã‚¹ãƒ†ãƒƒãƒ—ã‚’é‡ã­ã‚‹ãŸã‚éåŠ¹ç‡
- **Plan-and-Execute**: è¨ˆç”»ã«ã‚ˆã‚ŠåŠ¹ç‡åŒ–ã€ç²¾åº¦ã‚‚å‘ä¸Š
- **ReWOO**: ãƒˆãƒ¼ã‚¯ãƒ³æ¶ˆè²»ãŒ5xå°‘ãªã„ (Xu+ 2023 [^3]ã®ä¸»å¼µã‚’å†ç¾)ã€ãŸã ã—å‹•çš„å†è¨ˆç”»ãŒã§ããªã„ãŸã‚ç²¾åº¦ã¯ä¸­é–“

### 5.3 Memory Systemã®åŠ¹æœæ¤œè¨¼

Memoryæœ‰ç„¡ã§ã®æ€§èƒ½å·®ã‚’æ¸¬å®šã™ã‚‹ã€‚

```julia
function benchmark_memory_effect()
    # Task: Answer questions about a story
    story = """
    Alice went to Paris in 2020. She visited the Eiffel Tower and the Louvre Museum.
    In 2021, she moved to London and started working at a tech company.
    Her favorite programming language is Julia.
    """

    questions = [
        "Where did Alice go in 2020?",
        "What is Alice's favorite programming language?",
        "When did Alice move to London?"
    ]

    ground_truth = ["Paris", "Julia", "2021"]

    # Without memory
    no_memory_scores = []
    for (q, truth) in zip(questions, ground_truth)
        ans = run_agent_no_memory(story, q)
        push!(no_memory_scores, exact_match(ans, truth))
    end

    # With memory
    memory_scores = []
    memory = init_memory(story)
    for (q, truth) in zip(questions, ground_truth)
        ans = run_agent_with_memory(memory, q)
        push!(memory_scores, exact_match(ans, truth))
    end

    println("Without Memory: Accuracy = $(round(mean(no_memory_scores) * 100, digits=2))%")
    println("With Memory: Accuracy = $(round(mean(memory_scores) * 100, digits=2))%")
end

function init_memory(text::String)
    # Simplified: store text chunks with embeddings
    return Dict("text" => text)
end

function run_agent_no_memory(story::String, query::String)
    # Simplified: LLM without memory
    return "Paris"
end

function run_agent_with_memory(memory::Dict, query::String)
    # Simplified: LLM with memory retrieval
    return "Paris"
end

benchmark_memory_effect()
```

### 5.4 Multi-Agent Debateã®åŠ¹æœ

Single Agent vs Multi-Agent Debateã‚’æ¯”è¼ƒã™ã‚‹ã€‚

```julia
function benchmark_multi_agent_debate()
    questions = [
        "Is 17 a prime number?",
        "What is the square root of 144?",
        "Is water wet?"
    ]

    ground_truth = ["Yes", "12", "Yes"]

    # Single agent
    single_scores = []
    for (q, truth) in zip(questions, ground_truth)
        ans = run_single_agent(q)
        push!(single_scores, exact_match(ans, truth))
    end

    # Multi-agent debate
    debate_scores = []
    for (q, truth) in zip(questions, ground_truth)
        ans = run_multi_agent_debate(q, n_agents=3, n_rounds=2)
        push!(debate_scores, exact_match(ans, truth))
    end

    println("Single Agent: Accuracy = $(round(mean(single_scores) * 100, digits=2))%")
    println("Multi-Agent Debate: Accuracy = $(round(mean(debate_scores) * 100, digits=2))%")
end

function run_single_agent(query::String)
    return "Yes"
end

function run_multi_agent_debate(query::String; n_agents::Int, n_rounds::Int)
    answers = [run_single_agent(query) for _ in 1:n_agents]

    # Majority voting
    counts = Dict{String, Int}()
    for ans in answers
        counts[ans] = get(counts, ans, 0) + 1
    end

    return argmax(counts)
end

benchmark_multi_agent_debate()
```

### 5.5 Self-è¨ºæ–­ãƒ†ã‚¹ãƒˆ

1. **ReAct Loopã®é †åºã‚’æ­£ã—ãä¸¦ã¹ã‚ˆ**:
   - A. Thought â†’ Action â†’ Observation
   - B. Action â†’ Observation â†’ Thought
   - C. Observation â†’ Thought â†’ Action

2. **Tool Registryã§å¿…é ˆã®è¦ç´ ã¯**:
   - A. name, description, parameters
   - B. name, function
   - C. name, schema, function

3. **ReWOOã®ç‰¹å¾´ã¯**:
   - A. é€æ¬¡å®Ÿè¡Œ
   - B. ä¸¦åˆ—å®Ÿè¡Œ
   - C. å‹•çš„å†è¨ˆç”»

4. **Long-term Memoryã®å®Ÿè£…ã«æœ€é©ãªã®ã¯**:
   - A. LLM context window
   - B. Vector Database
   - C. In-memory cache

5. **Multi-Agent Debateã®åˆ©ç‚¹ã¯**:
   - A. å®Ÿè¡Œé€Ÿåº¦
   - B. ã‚³ã‚¹ãƒˆå‰Šæ¸›
   - C. ãƒã‚¤ã‚¢ã‚¹å‰Šæ¸›

<details>
<summary>å›ç­”</summary>

1. A (Thought â†’ Action â†’ Observation)
2. C (name, schema, function)
3. B (ä¸¦åˆ—å®Ÿè¡Œ)
4. B (Vector Database)
5. C (ãƒã‚¤ã‚¢ã‚¹å‰Šæ¸›)

</details>

:::message
**progress: 85%** â€” Zone 5å®Œäº†ã€‚AgentBenchã§ã®è©•ä¾¡æ‰‹æ³•ã¨ã€Planning / Memory / Multi-Agentã®åŠ¹æœã‚’å®Ÿé¨“ã§ç¢ºèªã—ãŸã€‚
:::

---

## ğŸ“ 6. æŒ¯ã‚Šè¿”ã‚Šã¨ç™ºå±•ã‚¾ãƒ¼ãƒ³ï¼ˆ30åˆ†ï¼‰â€” ã¾ã¨ã‚ã¨æœ€æ–°ç ”ç©¶å‹•å‘

**ã‚´ãƒ¼ãƒ«**: 2024-2026å¹´ã®ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆç ”ç©¶å‹•å‘ã‚’æŠŠæ¡ã™ã‚‹ã€‚

### 6.1 ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆç ”ç©¶ã®ç³»è­œ

```mermaid
graph TD
    A["2014-2020<br/>å¼·åŒ–å­¦ç¿’ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆ"] --> B["2022<br/>LLMç™»å ´"]
    B --> C["2022 Q4<br/>ChatGPT Tool Use"]
    C --> D["2023 Q1<br/>ReAct / Toolformer"]
    D --> E["2023 Q2<br/>AutoGPT / BabyAGI"]
    E --> F["2023 Q3<br/>MetaGPT / AutoGen"]
    F --> G["2024 Q1<br/>Multi-Agent Frameworks"]
    G --> H["2024 Q4<br/>MCPæ¨™æº–åŒ–"]
    H --> I["2025<br/>Agentic AI Foundation"]

    style C fill:#e3f2fd
    style H fill:#c8e6c9
```

### 6.2 ä¸»è¦è«–æ–‡ãƒ»ãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯

| è«–æ–‡/FW | å¹´ | è²¢çŒ® | å¼•ç”¨ |
|:--------|:---|:-----|:-----|
| **ReAct** | 2023 | Reasoning + Actingçµ±åˆ | [^1] |
| **Toolformer** | 2023 | è‡ªå·±æ•™å¸«ã‚ã‚Š Tool Useå­¦ç¿’ | [^2] |
| **ReWOO** | 2023 | ä¸¦åˆ—Toolå®Ÿè¡Œã€5xåŠ¹ç‡åŒ– | [^3] |
| **Generative Agents** | 2023 | Memory-augmentedç¤¾ä¼šã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ | [^4] |
| **AgentBench** | 2023 | 8ç’°å¢ƒã§ã®åŒ…æ‹¬çš„è©•ä¾¡ | [^7] |
| **MetaGPT** | 2023 | SOP-based Multi-Agenté–‹ç™º | [^8] |
| **AutoGen** | 2023 | Multi-Agentä¼šè©±ãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯ | [^9] |
| **HuggingGPT** | 2023 | LLMã§ãƒ¢ãƒ‡ãƒ«ã‚ªãƒ¼ã‚±ã‚¹ãƒˆãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ | [^10] |
| **MCP** | 2024 | LLM-Toolæ¨™æº–åŒ–ãƒ—ãƒ­ãƒˆã‚³ãƒ« | [^11] |

### 6.3 2024-2026 æœ€æ–°å‹•å‘

#### 6.3.1 Agentic Workflow

LangChain / LangGraphã«ã‚ˆã‚‹**ã‚°ãƒ©ãƒ•ãƒ™ãƒ¼ã‚¹ã®ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆè¨­è¨ˆ**ãŒä¸»æµã«ã€‚

```mermaid
graph LR
    A["ğŸ“¥ Input"] --> B["ğŸ” Router"]
    B -->|"Simple"| C["ğŸ’­ Direct Answer"]
    B -->|"Complex"| D["ğŸ“‹ Planner"]
    D --> E["ğŸ› ï¸ Tool Executor"]
    E --> F["âœ… Validator"]
    F -->|"Fail"| D
    F -->|"Pass"| G["âœ… Output"]
```

#### 6.3.2 Reasoning at Test Time

OpenAI o1ã‚·ãƒªãƒ¼ã‚ºä»¥é™ã€**æ¨è«–æ™‚ã‚¹ã‚±ãƒ¼ãƒªãƒ³ã‚°å‰‡**ãŒæ³¨ç›®ã•ã‚Œã‚‹ã€‚

$$
\text{Performance} \propto \log(\text{Test-time Compute})
$$

ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã¯ã€æ¨è«–ã‚¹ãƒ†ãƒƒãƒ—æ•°ã‚’å¢—ã‚„ã™ã“ã¨ã§æ€§èƒ½å‘ä¸Šã€‚

#### 6.3.3 Tool Ecosystem

MCPæ¨™æº–åŒ–ã«ã‚ˆã‚Šã€**1,000+ ã‚ªãƒ¼ãƒ—ãƒ³ã‚½ãƒ¼ã‚¹ãƒ„ãƒ¼ãƒ«**ãŒç™»å ´:

- **Filesystem MCP**: ãƒ­ãƒ¼ã‚«ãƒ«ãƒ•ã‚¡ã‚¤ãƒ«æ“ä½œ
- **GitHub MCP**: PRä½œæˆãƒ»Issueç®¡ç†
- **Slack MCP**: ãƒãƒ£ãƒ³ãƒãƒ«æŠ•ç¨¿ãƒ»ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸æ¤œç´¢
- **Postgres MCP**: SQLå®Ÿè¡Œãƒ»ã‚¹ã‚­ãƒ¼ãƒæ¤œç´¢

#### 6.3.4 Multi-Agent Frameworks

| Framework | ç‰¹å¾´ | è¨€èª |
|:----------|:-----|:-----|
| **AutoGen** | ä¼šè©±ãƒ™ãƒ¼ã‚¹ã€æŸ”è»Ÿ | Python |
| **CrewAI** | Role-basedã€ã‚·ãƒ³ãƒ—ãƒ« | Python |
| **LangGraph** | ã‚°ãƒ©ãƒ•ãƒ™ãƒ¼ã‚¹ã€å¯è¦–åŒ– | Python / JS |
| **CAMEL** | Role-playingã€ç ”ç©¶å‘ã‘ | Python |

### 6.4 å®Ÿä¸–ç•Œã¸ã®å¿œç”¨

#### 6.4.1 ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆ

| è£½å“ | æ©Ÿèƒ½ | ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆæŠ€è¡“ | è©³ç´° |
|:-----|:-----|:----------------|:-----|
| **GitHub Copilot** | ã‚³ãƒ¼ãƒ‰è£œå®Œ | Tool Use (code search) | ã‚³ãƒ¼ãƒ‰ãƒ™ãƒ¼ã‚¹æ¤œç´¢ã€APIå‚ç…§ã€ãƒ†ã‚¹ãƒˆç”Ÿæˆ |
| **Cursor** | AI-first IDE | ReAct Loop + Memory | ä¼šè©±å±¥æ­´ä¿æŒã€Multi-file editingã€Cmd+K Agent |
| **Devin** | å®Œå…¨è‡ªå¾‹é–‹ç™º | Planning + Multi-Agent | ã‚¿ã‚¹ã‚¯åˆ†è§£â†’å®Ÿè£…â†’ãƒ†ã‚¹ãƒˆâ†’ãƒ‡ãƒãƒƒã‚°â†’PRä½œæˆã‚’å®Œå…¨è‡ªå‹•åŒ– |
| **SWE-agent** | GitHub Issueè§£æ±º | ReAct + Tool Use | GitHub APIã€Code Searchã€Gitæ“ä½œã‚’çµ±åˆ |

**Devinã®å®Ÿè£…ä¾‹** (Cognition AI):

1. **Planning**: GitHub Issueã‚’èª­ã¿ã€ã‚¿ã‚¹ã‚¯ã‚’5-10ã‚¹ãƒ†ãƒƒãƒ—ã«åˆ†è§£
2. **Tool Use**: Code Editor, Terminal, Browser, GitHub APIã‚’é§†ä½¿
3. **Memory**: éå»ã®å®Ÿè£…ãƒ‘ã‚¿ãƒ¼ãƒ³ã‚’è¨˜æ†¶ã€é¡ä¼¼Issueè§£æ±ºå±¥æ­´ã‚’å‚ç…§
4. **Multi-Agent**: Planner / Coder / Tester / Reviewerã®å½¹å‰²åˆ†æ‹…
5. **Feedback Loop**: CIãƒ†ã‚¹ãƒˆå¤±æ•—ã‚’è¦³å¯Ÿâ†’ãƒ‡ãƒãƒƒã‚°â†’å†å®Ÿè£…

**æˆåŠŸç‡** (SWE-bench Verified):
- **Devin (2024å¹´)**: 13.86% (ãƒ™ãƒ¼ã‚¹ãƒ©ã‚¤ãƒ³: 1.96%)
- **Aider (2025å¹´)**: 18.8% (ReAct + Tree Search)
- **OpenHands (2025å¹´)**: 15.9% (Multi-Agent)

#### 6.4.2 ç ”ç©¶ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆ

| è£½å“ | æ©Ÿèƒ½ | ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆæŠ€è¡“ | è©³ç´° |
|:-----|:-----|:----------------|:-----|
| **Elicit** | è«–æ–‡æ¤œç´¢ãƒ»è¦ç´„ | Tool Use (arXiv API) + Memory | è‡ªç„¶è¨€èªã‚¯ã‚¨ãƒªâ†’è«–æ–‡æ¤œç´¢â†’è¦ç´„â†’æ¯”è¼ƒè¡¨ç”Ÿæˆ |
| **Consensus** | ç§‘å­¦çš„ã‚³ãƒ³ã‚»ãƒ³ã‚µã‚¹ | Multi-Agent Debate | è¤‡æ•°è«–æ–‡ã‚’ä¸¦åˆ—èª­è§£â†’åˆæ„å½¢æˆâ†’ã‚¨ãƒ“ãƒ‡ãƒ³ã‚¹ãƒ¬ãƒ™ãƒ«è©•ä¾¡ |
| **SciSpace** | è«–æ–‡ç†è§£æ”¯æ´ | RAG + Tool Use | PDFã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰â†’ã‚»ã‚¯ã‚·ãƒ§ãƒ³è§£èª¬â†’æ•°å¼ãƒ»å›³è¡¨èª¬æ˜ |
| **Semantic Scholar** | å¼•ç”¨ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯åˆ†æ | Knowledge Graph + Tool Use | Citation treeæ¢ç´¢ã€å½±éŸ¿åº¦è¨ˆç®—ã€é–¢é€£è«–æ–‡æ¨è–¦ |

**Elicitã®å‹•ä½œä¾‹**:

```
User: "What are the latest methods for long-context LLMs?"

Agent:
Step 1 (Tool: arxiv_search): Search for "long context LLM 2024 2025"
Step 2 (Tool: paper_scraper): Download top 10 papers
Step 3 (LLM: summarize): Extract methods from each paper
Step 4 (LLM: compare): Create comparison table
Step 5 (Memory: store): Save to user's research library

Output:
| Paper | Method | Context Length | Performance |
|-------|--------|----------------|-------------|
| LongLoRA | LoRA + Shift SSA | 32K | PPL 3.12 |
| StreamingLLM | Attention Sink | 4M | Stable |
| ...
```

#### 6.4.3 Customer Support

| è£½å“ | æ©Ÿèƒ½ | ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆæŠ€è¡“ | è©³ç´° |
|:-----|:-----|:----------------|:-----|
| **Intercom AI** | è‡ªå‹•å¿œç­” | Memory + Tool Use (CRM) | é¡§å®¢å±¥æ­´å‚ç…§ã€FAQæ¤œç´¢ã€ã‚¨ã‚¹ã‚«ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³åˆ¤å®š |
| **Zendesk AI** | ãƒã‚±ãƒƒãƒˆåˆ†é¡ | Planning + Memory | ãƒã‚±ãƒƒãƒˆåˆ†æâ†’å„ªå…ˆåº¦åˆ¤å®šâ†’æ‹…å½“è€…å‰²ã‚Šå½“ã¦ |
| **Ada** | ã‚«ã‚¹ã‚¿ãƒã‚¤ã‚ºå¯èƒ½Bot | ReAct Loop + Memory | å¤šè¨€èªå¯¾å¿œã€ä¼šè©±ãƒ•ãƒ­ãƒ¼è¨˜æ†¶ã€A/Bãƒ†ã‚¹ãƒˆ |

**Intercom AIã®å‹•ä½œä¾‹**:

```
Customer: "My order #12345 hasn't arrived yet."

Agent:
Step 1 (Memory: retrieve): Fetch order history for this customer
Step 2 (Tool: order_api): Check order #12345 status â†’ "Shipped 2 days ago"
Step 3 (Tool: shipping_tracker): Track package â†’ "In transit, estimated delivery tomorrow"
Step 4 (Thought): Customer is concerned, provide reassurance + tracking link
Step 5 (Action: respond): "Your order is on the way! Expected delivery: Feb 14. Track here: [link]"

No human intervention needed.
```

#### 6.4.4 æ–°èˆˆå¿œç”¨åˆ†é‡

| åˆ†é‡ | å¿œç”¨ä¾‹ | ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆæŠ€è¡“ |
|:-----|:------|:----------------|
| **åŒ»ç™‚** | è¨ºæ–­æ”¯æ´ã€æ²»ç™‚è¨ˆç”» | Multi-Agent Debate (è¤‡æ•°å°‚é–€åŒ»ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆ) + Memory (æ‚£è€…å±¥æ­´) |
| **æ³•å¾‹** | å¥‘ç´„æ›¸ãƒ¬ãƒ“ãƒ¥ãƒ¼ã€åˆ¤ä¾‹æ¤œç´¢ | Tool Use (æ³•ä»¤DB) + Planning (æ¡é …ãƒã‚§ãƒƒã‚¯ãƒªã‚¹ãƒˆ) |
| **æ•™è‚²** | å€‹åˆ¥æŒ‡å°ã€èª²é¡Œæ¡ç‚¹ | Memory (å­¦ç¿’å±¥æ­´) + Planning (ã‚«ãƒªã‚­ãƒ¥ãƒ©ãƒ é©å¿œ) |
| **é‡‘è** | ãƒãƒ¼ãƒˆãƒ•ã‚©ãƒªã‚ªç®¡ç†ã€ãƒªã‚¹ã‚¯åˆ†æ | Tool Use (å¸‚å ´ãƒ‡ãƒ¼ã‚¿API) + Multi-Agent (Bull/Bearè¦–ç‚¹) |

### 6.5 ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆè©•ä¾¡ã®é€²åŒ–

AgentBenchä»¥é™ã€è©•ä¾¡æ‰‹æ³•ãŒå¤šæ§˜åŒ–:

| ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ | è©•ä¾¡å¯¾è±¡ | ç‰¹å¾´ |
|:-----------|:---------|:-----|
| **AgentBench** | æ±ç”¨èƒ½åŠ› | 8ç’°å¢ƒ |
| **WebArena** | Webæ“ä½œ | å®Ÿãƒ–ãƒ©ã‚¦ã‚¶ |
| **SWE-bench** | ã‚½ãƒ•ãƒˆã‚¦ã‚§ã‚¢é–‹ç™º | å®ŸGitHub Issue |
| **GAIA** | ä¸€èˆ¬AIèƒ½åŠ› | äººé–“ãƒ¬ãƒ™ãƒ«è©•ä¾¡ |

### 6.6 èª²é¡Œã¨ä»Šå¾Œã®æ–¹å‘æ€§

| èª²é¡Œ | ç¾çŠ¶ | ä»Šå¾Œã®æ–¹å‘æ€§ |
|:-----|:-----|:-----------|
| **Hallucination** | å¤–éƒ¨ãƒ„ãƒ¼ãƒ«ã§è»½æ¸› | Verification Agentã€Multi-Agent Cross-check |
| **Planning Efficiency** | ReWOOã§5xæ”¹å–„ | Neural Symbolic Planningã€Tree Search |
| **Memory Scalability** | Vector DBåˆ©ç”¨ | Hierarchical Memoryã€Forgetting Mechanism |
| **Multi-Agent Coordination** | Message Passing | Protocolæ¨™æº–åŒ– (MCP)ã€Formal Verification |
| **Cost** | GPT-4ã§é«˜ã‚³ã‚¹ãƒˆ | Smaller Models (Llama 3.1 70B)ã€Model Routing |

:::message
**progress: 100%** â€” Zone 6å®Œäº†ã€‚ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆç ”ç©¶ã®æœ€æ–°å‹•å‘ã¨å®Ÿä¸–ç•Œå¿œç”¨ã‚’æŠŠæ¡ã—ãŸã€‚
:::

---

**ã‚´ãƒ¼ãƒ«**: æœ¬è¬›ç¾©ã®å…¨ä½“ã‚’æŒ¯ã‚Šè¿”ã‚Šã€æ¬¡ã®ã‚¹ãƒ†ãƒƒãƒ—ã‚’æ˜ç¢ºã«ã™ã‚‹ã€‚

### 6.6 æœ¬è¬›ç¾©ã®ã¾ã¨ã‚

æœ¬è¬›ç¾©ã§å­¦ã‚“ã 7ã¤ã®ã‚³ãƒ³ãƒãƒ¼ãƒãƒ³ãƒˆ:

| Component | æ•°å¼ãƒ»æ¦‚å¿µ | å®Ÿè£… |
|:----------|:----------|:-----|
| **1. ReAct Loop** | $\text{thought}_t \to a_t \to o_{t+1}$ | Rust State Machine |
| **2. Tool Use** | $\mathcal{T} = \langle \text{name}, \text{schema}, \text{function} \rangle$ | Rust Tool Registry |
| **3. Planning** | $\text{task} \to \{ \text{subtask}_i \}$ | Julia Planning Engine |
| **4. Memory** | $\mathcal{M} = \{ (k_i, v_i) \}$ | Rust + Qdrant |
| **5. Multi-Agent** | $\mathcal{MAS} = \{ \mathcal{A}_1, \ldots, \mathcal{A}_N \}$ | Elixir GenServer |
| **6. MCP** | JSON-RPC 2.0 over stdio/HTTP | Rust Server + Julia Client |
| **7. Production** | Rust+Elixir+Juliaçµ±åˆ | Complete Agent System |

### 6.7 åˆ°é”ç‚¹

**Before (ç¬¬29å›ã¾ã§)**:
- LLMã¯"èª­ã‚€"å­˜åœ¨
- å¤–éƒ¨çŸ¥è­˜ã¯RAGã§æ¥ç¶š
- å˜ä¸€ã®LLMå‘¼ã³å‡ºã—

**After (ç¬¬30å›)**:
- LLMã¯"è¡Œå‹•ã™ã‚‹"ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆ
- Tool Use / Planning / Memoryã§è¤‡é›‘ãªã‚¿ã‚¹ã‚¯ã‚’é‚è¡Œ
- Multi-Agentã§å”èª¿ãƒ»è¨è«–

### 6.8 FAQ

<details>
<summary><strong>Q1. ReActã¨Chain-of-Thoughtã®é•ã„ã¯ï¼Ÿ</strong></summary>

**A**: CoTã¯æ€è€ƒã®ã¿ã€ReActã¯æ€è€ƒ+è¡Œå‹•+è¦³å¯Ÿã®ãƒ«ãƒ¼ãƒ—ã€‚ReActã¯å¤–éƒ¨ãƒ„ãƒ¼ãƒ«ã§æ¤œè¨¼ã§ãã‚‹ãŸã‚ã€ãƒãƒ«ã‚·ãƒãƒ¼ã‚·ãƒ§ãƒ³ãŒå°‘ãªã„ã€‚
</details>

<details>
<summary><strong>Q2. Tool Useå®Ÿè£…ã§æœ€ã‚‚é‡è¦ãªã“ã¨ã¯ï¼Ÿ</strong></summary>

**A**: ã‚¨ãƒ©ãƒ¼ãƒãƒ³ãƒ‰ãƒªãƒ³ã‚°ã¨Retryæˆ¦ç•¥ã€‚Toolå®Ÿè¡Œã¯å¤±æ•—ã—ã†ã‚‹ (Timeout, Invalid Args, Execution Error)ã€‚Exponential Backoffã§å†è©¦è¡Œã—ã€Fallback Toolã‚’ç”¨æ„ã™ã‚‹ã€‚
</details>

<details>
<summary><strong>Q3. ReWOOã®ãƒ¡ãƒªãƒƒãƒˆãƒ»ãƒ‡ãƒ¡ãƒªãƒƒãƒˆã¯ï¼Ÿ</strong></summary>

**A**: ãƒ¡ãƒªãƒƒãƒˆ: ä¸¦åˆ—å®Ÿè¡Œã§é«˜é€Ÿã€ãƒˆãƒ¼ã‚¯ãƒ³æ¶ˆè²»5xå‰Šæ¸›ã€‚ãƒ‡ãƒ¡ãƒªãƒƒãƒˆ: å‹•çš„å†è¨ˆç”»ä¸å¯ã€è¤‡é›‘ãªä¾å­˜é–¢ä¿‚ã«å¼±ã„ã€‚
</details>

<details>
<summary><strong>Q4. Memory Systemã§æœ€ã‚‚åŠ¹æœçš„ãªã®ã¯ï¼Ÿ</strong></summary>

**A**: Vector Memory (RAG)ã€‚LLMã®ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆåˆ¶é™ã‚’è¶…ãˆã¦ã€å¤§é‡ã®éå»çµŒé¨“ã‚’æ¤œç´¢å¯èƒ½ã€‚Qdrant / Pinecone / Weaviateãªã©ã®Vector DBã‚’ä½¿ã†ã€‚
</details>

<details>
<summary><strong>Q5. Multi-Agent Debateã¯å¸¸ã«æœ‰åŠ¹ï¼Ÿ</strong></summary>

**A**: No. ã‚·ãƒ³ãƒ—ãƒ«ãªã‚¿ã‚¹ã‚¯ã§ã¯ã‚³ã‚¹ãƒˆå¢—ã®ã¿ã€‚è¤‡é›‘ãªæ¨è«–ãƒ»åˆ¤æ–­ã‚¿ã‚¹ã‚¯ (åŒ»ç™‚è¨ºæ–­ã€æ³•çš„åˆ¤æ–­) ã§æœ‰åŠ¹ã€‚3-5ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã€2-3ãƒ©ã‚¦ãƒ³ãƒ‰ãŒç›®å®‰ã€‚
</details>

<details>
<summary><strong>Q6. MCPã¯å¿…é ˆï¼Ÿ</strong></summary>

**A**: 2025å¹´æ™‚ç‚¹ã§ã¯ä»»æ„ã ãŒã€OpenAI / Google / Anthropicå…¨ã¦ãŒå¯¾å¿œäºˆå®šã€‚æ–°è¦ãƒ„ãƒ¼ãƒ«é–‹ç™ºã¯MCPå¯¾å¿œãŒæ¨™æº–ã«ãªã‚‹ã€‚
</details>

<details>
<summary><strong>Q7. ãªãœRust / Elixir / Juliaã®3è¨€èªï¼Ÿ</strong></summary>

**A**:
- **Rust**: Tool Registry / State Machineã¯å‹å®‰å…¨ãƒ»é«˜é€ŸãŒå¿…é ˆ
- **Elixir**: Multi-Agentã¯éšœå®³è€æ€§ãƒ»åˆ†æ•£ä¸¦è¡ŒãŒå¿…é ˆ
- **Julia**: Orchestrationã¯æ•°å¼â†”ã‚³ãƒ¼ãƒ‰1:1ãŒå¿…é ˆ

Pythonã ã‘ã§ã¯å…¨ã¦ã‚’æœ€é©åŒ–ã§ããªã„ã€‚
</details>

<details>
<summary><strong>Q8. ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã®æœ€å¤§ã®èª²é¡Œã¯ï¼Ÿ</strong></summary>

**A**: **Hallucination**ã¨**Cost**ã€‚å¤–éƒ¨ãƒ„ãƒ¼ãƒ«ã§Hallucinationã¯è»½æ¸›ã•ã‚Œã‚‹ãŒã€å®Œå…¨ã«ã¯æ¶ˆãˆãªã„ã€‚Multi-Agent Debateã¯ã‚³ã‚¹ãƒˆãŒNå€ã€‚Small Model (Llama 3.1 70B) + Model Routingã§å¯¾å‡¦ã€‚
</details>

### 6.9 å­¦ç¿’ã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒ« (1é€±é–“ãƒ—ãƒ©ãƒ³)

| Day | å†…å®¹ | æ™‚é–“ | æ¼”ç¿’ |
|:----|:-----|:-----|:-----|
| **Day 1** | Zone 0-2 | 30åˆ† | ReAct Loop 3è¡Œã‚³ãƒ¼ãƒ‰ |
| **Day 2** | Zone 3 Part A-B | 60åˆ† | Tool Registryå®Ÿè£… |
| **Day 3** | Zone 3 Part C-D | 60åˆ† | Planning Engineå®Ÿè£… |
| **Day 4** | Zone 3 Part E-F | 60åˆ† | Multi-Agent + MCP |
| **Day 5** | Zone 3 Part G + Zone 4 | 90åˆ† | Rust/Elixir/Juliaçµ±åˆ |
| **Day 6** | Zone 5 | 60åˆ† | AgentBenchè©•ä¾¡ |
| **Day 7** | Zone 6 + å¾©ç¿’ | 60åˆ† | æœ€æ–°è«–æ–‡èª­è§£ |

### 6.10 æ¬¡å›äºˆå‘Š: ç¬¬31å› MLOpså®Œå…¨ç‰ˆ

ç¬¬30å›ã§ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã®å…¨ä½“åƒã‚’å­¦ã‚“ã ã€‚æ¬¡ã¯ã€ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã‚’å«ã‚€æ©Ÿæ¢°å­¦ç¿’ã‚·ã‚¹ãƒ†ãƒ å…¨ä½“ã‚’**æœ¬ç•ªç’°å¢ƒã§é‹ç”¨**ã™ã‚‹ãŸã‚ã®æŠ€è¡“ â€” **MLOpså®Œå…¨ç‰ˆ**ã ã€‚

**ç¬¬31å›ã®ä¸»è¦ãƒˆãƒ”ãƒƒã‚¯**:
- **å®Ÿé¨“ç®¡ç†**: MLflow / Weights & Biases / Neptune
- **ãƒ‡ãƒ¼ã‚¿ãƒãƒ¼ã‚¸ãƒ§ãƒ‹ãƒ³ã‚°**: DVC / LakeFS
- **ãƒ¢ãƒ‡ãƒ«ãƒ¬ã‚¸ã‚¹ãƒˆãƒª**: MLflow Model Registry / BentoML
- **CI/CD for ML**: GitHub Actions + Docker + Kubernetes
- **ç›£è¦–**: Prometheus + Grafana / Evidently AI
- **A/Bãƒ†ã‚¹ãƒˆ**: Multi-Armed Bandit / Bayesian Optimization
- **Feedback Loop**: Human-in-the-Loop / RLHF

ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã‚’ã€Œå®Ÿé¨“å®¤ã®ç©å…·ã€ã‹ã‚‰ã€Œæœ¬ç•ªç¨¼åƒã‚·ã‚¹ãƒ†ãƒ ã€ã«æ˜‡è¯ã•ã›ã‚‹ã€‚

:::message
**progress: 100%** â€” ç¬¬30å›å®Œäº†ã€‚ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆå®Œå…¨ç‰ˆã‚’ç¿’å¾—ã—ãŸã€‚æ¬¡ã¯ç¬¬31å›MLOpsã§æœ¬ç•ªé‹ç”¨ã¸ã€‚
:::

---

### 6.11 ãƒ‘ãƒ©ãƒ€ã‚¤ãƒ è»¢æ›ã®å•ã„

**AIã¯"é“å…·"ã‹ã‚‰"åŒåƒš"ã«ãªã‚‹ã®ã‹ï¼Ÿ**

å¾“æ¥ã€AIã¯ã€Œãƒ„ãƒ¼ãƒ«ã€ã ã£ãŸã€‚æ¤œç´¢ã‚¨ãƒ³ã‚¸ãƒ³ã€ç¿»è¨³ã€ç”»åƒç”Ÿæˆ â€” å…¨ã¦ã€Œäººé–“ãŒæŒ‡ç¤ºã‚’å‡ºã—ã€AIãŒå®Ÿè¡Œã™ã‚‹ã€é–¢ä¿‚ã ã€‚

ã—ã‹ã—ã€ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã¯é•ã†:

- **ReAct Loop**: è‡ªå¾‹çš„ã«æ¨è«–ãƒ»è¡Œå‹•ãƒ»è¦³å¯Ÿã‚’ç¹°ã‚Šè¿”ã™
- **Planning**: ç›®æ¨™ã‹ã‚‰é€†ç®—ã—ã€ã‚¿ã‚¹ã‚¯ã‚’åˆ†è§£ã™ã‚‹
- **Memory**: éå»ã®çµŒé¨“ã‚’è¨˜æ†¶ã—ã€å­¦ç¿’ã™ã‚‹
- **Multi-Agent**: ä»–ã®ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã¨å”èª¿ãƒ»è¨è«–ã™ã‚‹

ã“ã‚Œã¯ã€Œé“å…·ã€ã§ã¯ãªãã€ã€ŒåŒåƒšã€ã®æŒ¯ã‚‹èˆã„ã ã€‚

**2ã¤ã®è¦–ç‚¹**:

1. **æ¥½è¦³çš„è¦–ç‚¹**: ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã¯äººé–“ã®èƒ½åŠ›ã‚’æ‹¡å¼µã—ã€å‰µé€ æ€§ã‚’è§£æ”¾ã™ã‚‹ã€‚åŒ»å¸«ã¯ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã¨å”åŠ›ã—ã¦è¨ºæ–­ç²¾åº¦ã‚’å‘ä¸Šã•ã›ã€ã‚¨ãƒ³ã‚¸ãƒ‹ã‚¢ã¯ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã¨å…±ã«ã‚½ãƒ•ãƒˆã‚¦ã‚§ã‚¢ã‚’é–‹ç™ºã™ã‚‹ã€‚äººé–“ã¯ã€Œç®¡ç†è€…ã€ã¨ã—ã¦ã€ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆãƒãƒ¼ãƒ ã‚’ç‡ã„ã‚‹ã€‚

2. **æ‡¸å¿µçš„è¦–ç‚¹**: ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã¯äººé–“ã®å½¹å‰²ã‚’ä¾µé£Ÿã™ã‚‹ã€‚å˜ç´”ä½œæ¥­ã ã‘ã§ãªãã€æ¨è«–ãƒ»åˆ¤æ–­ãƒ»å‰µé€ ã‚‚è‡ªå‹•åŒ–ã•ã‚Œã‚‹ã€‚ã€Œäººé–“ã«ã—ã‹ã§ããªã„ä»•äº‹ã€ã®ç¯„å›²ãŒæ€¥é€Ÿã«ç¸®å°ã™ã‚‹ã€‚

ã‚ãªãŸã¯ã©ã¡ã‚‰ã®æœªæ¥ã‚’è¦‹ã‚‹ã‹ï¼Ÿ

**è€ƒå¯Ÿã®ãƒ’ãƒ³ãƒˆ**:

- OpenAI o1ã¯ã€**æ¨è«–æ™‚ã‚¹ã‚±ãƒ¼ãƒªãƒ³ã‚°å‰‡**ã‚’å®Ÿè¨¼ã—ãŸã€‚LLMã¯ã€Œè€ƒãˆã‚‹æ™‚é–“ã€ã‚’å¢—ã‚„ã›ã°ã€ã‚ˆã‚Šè‰¯ã„ç­”ãˆã‚’å‡ºã›ã‚‹ã€‚ã“ã‚Œã¯äººé–“ã®ã€Œç†Ÿè€ƒã€ã¨åŒã˜ãƒ¡ã‚«ãƒ‹ã‚ºãƒ ã ã€‚
- MetaGPT [^8] ã¯ã€ã‚½ãƒ•ãƒˆã‚¦ã‚§ã‚¢é–‹ç™ºã‚’ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆãƒãƒ¼ãƒ ã§è‡ªå‹•åŒ–ã—ãŸã€‚Product Manager / Architect / Engineer / Testerã®å½¹å‰²ã‚’å…¨ã¦ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆãŒæ‹…ã†ã€‚
- Generative Agents [^4] ã¯ã€ç¤¾ä¼šã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ã§ã€Œè¨˜æ†¶ãƒ»åçœãƒ»è¨ˆç”»ã€ã‚’æŒã¤ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆãŒã€äººé–“ã®ã‚ˆã†ãªç¤¾ä¼šçš„æŒ¯ã‚‹èˆã„ã‚’ç¤ºã—ãŸã€‚

**å•ã„**:

1. ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆãŒã€ŒåŒåƒšã€ã«ãªã£ãŸã¨ãã€äººé–“ã®å½¹å‰²ã¯ã©ã†å¤‰ã‚ã‚‹ã‹ï¼Ÿ
2. ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆåŒå£«ãŒå”åŠ›ã™ã‚‹ç¤¾ä¼šã§ã€äººé–“ã¯ã©ã®ã‚ˆã†ã«ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã¨å”åƒã™ã¹ãã‹ï¼Ÿ
3. ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆãŒã€Œæ€è€ƒã€ã€Œè¨˜æ†¶ã€ã€Œè¨ˆç”»ã€ã‚’æŒã¤ã¨ãã€ãã‚Œã¯ã€ŒçŸ¥èƒ½ã€ã¨å‘¼ã¹ã‚‹ã‹ï¼Ÿ

<details>
<summary>ä¸€ã¤ã®è¦–ç‚¹ (æä¾›: æœ¬è¬›ç¾©è‘—è€…)</summary>

ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã¯ã€Œé“å…·ã€ã§ã‚‚ã€ŒåŒåƒšã€ã§ã‚‚ãªã„ã€‚**ã€Œæ‹¡å¼µã•ã‚ŒãŸè‡ªå·±ã€**ã ã¨è€ƒãˆã‚‹ã€‚

ã‚¹ãƒãƒ¼ãƒˆãƒ•ã‚©ãƒ³ã¯ã€è¨˜æ†¶ã®å¤–éƒ¨åŒ–ã ã€‚Google Mapsã¯ã€ç©ºé–“èªè­˜ã®æ‹¡å¼µã ã€‚ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã¯ã€**æ¨è«–ãƒ»è¨ˆç”»ãƒ»å”èª¿ã®æ‹¡å¼µ**ã ã€‚

é‡è¦ãªã®ã¯ã€ã€Œã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆãŒä½•ã‚’ã™ã‚‹ã‹ã€ã§ã¯ãªãã€ã€Œäººé–“ãŒã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã‚’ã©ã†ä½¿ã„ã“ãªã™ã‹ã€ã ã€‚ç¬¬31å›MLOpsã§å­¦ã¶ã®ã¯ã€ã¾ã•ã«ã“ã®ã€Œä½¿ã„ã“ãªã—ã€ã®æŠ€è¡“ â€” ã‚·ã‚¹ãƒ†ãƒ å…¨ä½“ã‚’è¨­è¨ˆã—ã€ç›£è¦–ã—ã€æ”¹å–„ã—ç¶šã‘ã‚‹ãƒ«ãƒ¼ãƒ—ã ã€‚

ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã¯ã€äººé–“ã®ã€Œæ€è€ƒã®ã‚¹ã‚±ãƒ¼ãƒªãƒ³ã‚°å‰‡ã€ã‚’å®Ÿç¾ã™ã‚‹é“å…·ã ã€‚1äººã®äººé–“ãŒã€100ã®ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã‚’ç‡ã„ã¦ã€1000äººåˆ†ã®ä»•äº‹ã‚’ã™ã‚‹æœªæ¥ã€‚ãã‚Œã‚’ã€Œè„…å¨ã€ã¨è¦‹ã‚‹ã‹ã€ã€Œæ©Ÿä¼šã€ã¨è¦‹ã‚‹ã‹ã¯ã€ã‚ãªãŸæ¬¡ç¬¬ã ã€‚
</details>

:::message
**é€²æ—: 100% å®Œäº†** ğŸ‰ è¬›ç¾©å®Œèµ°ï¼
:::

---

## å‚è€ƒæ–‡çŒ®

### ä¸»è¦è«–æ–‡

[^1]: Yao, S., Zhao, J., Yu, D., Du, N., Shafran, I., Narasimhan, K., & Cao, Y. (2023). "ReAct: Synergizing Reasoning and Acting in Language Models". *ICLR 2023*.
@[card](https://arxiv.org/abs/2210.03629)

[^2]: Schick, T., Dwivedi-Yu, J., Dess`Ä±, R., Raileanu, R., Lomeli, M., Zettlemoyer, L., Cancedda, N., & Scialom, T. (2023). "Toolformer: Language Models Can Teach Themselves to Use Tools". *arXiv:2302.04761*.
@[card](https://arxiv.org/abs/2302.04761)

[^3]: Xu, B., Peng, Z., Lei, B., Mukherjee, S., Liu, Y., & Xu, D. (2023). "ReWOO: Decoupling Reasoning from Observations for Efficient Augmented Language Models". *arXiv:2305.18323*.
@[card](https://arxiv.org/abs/2305.18323)

[^4]: Park, J. S., O'Brien, J. C., Cai, C. J., Morris, M. R., Liang, P., & Bernstein, M. S. (2023). "Generative Agents: Interactive Simulacra of Human Behavior". *arXiv:2304.03442*.
@[card](https://arxiv.org/abs/2304.03442)

[^5]: Guo, T., Chen, X., Wang, Y., Chang, R., Pei, S., Chawla, N. V., Wiest, O., & Zhang, X. (2024). "Large Language Model based Multi-Agents: A Survey of Progress and Challenges". *IJCAI 2024*.
@[card](https://arxiv.org/abs/2402.01680)

[^7]: Liu, X., Yu, H., Zhang, H., Xu, Y., Lei, X., Lai, H., Gu, Y., Ding, H., Men, K., Yang, K., Zhang, S., Deng, X., Zeng, A., Du, Z., Zhang, C., Shen, S., Zhang, T., Su, Y., Sun, H., Huang, M., Dong, Y., & Tang, J. (2023). "AgentBench: Evaluating LLMs as Agents". *arXiv:2308.03688*.
@[card](https://arxiv.org/abs/2308.03688)

[^8]: Hong, S., Zheng, X., Chen, J., Cheng, Y., Zhang, C., Wang, Z., Yau, S. K. S., Lin, Z., Zhou, L., Ran, C., Xiao, L., Wu, C., & Schmidhuber, J. (2023). "MetaGPT: Meta Programming for A Multi-Agent Collaborative Framework". *arXiv:2308.00352*.
@[card](https://arxiv.org/abs/2308.00352)

[^9]: Wu, Q., Bansal, G., Zhang, J., Wu, Y., Li, B., Zhu, E., Jiang, L., Zhang, X., Zhang, S., Liu, J., Awadallah, A. H., White, R. W., Burger, D., & Wang, C. (2023). "AutoGen: Enabling Next-Gen LLM Applications via Multi-Agent Conversation". *arXiv:2308.08155*.
@[card](https://arxiv.org/abs/2308.08155)

[^10]: Shen, Y., Song, K., Tan, X., Li, D., Lu, W., & Zhuang, Y. (2023). "HuggingGPT: Solving AI Tasks with ChatGPT and its Friends in Hugging Face". *NeurIPS 2023*.
@[card](https://arxiv.org/abs/2303.17580)

[^11]: Anthropic. (2024). "Model Context Protocol (MCP)".
@[card](https://modelcontextprotocol.io)

### æ•™ç§‘æ›¸ãƒ»ãƒªã‚½ãƒ¼ã‚¹

- Russell, S., & Norvig, P. (2020). *Artificial Intelligence: A Modern Approach* (4th ed.). Pearson. (å¼·åŒ–å­¦ç¿’ãƒ»Planningç« )
- Sutton, R. S., & Barto, A. G. (2018). *Reinforcement Learning: An Introduction* (2nd ed.). MIT Press. (POMDPç« )
- LangChain Documentation. "Agents". [https://python.langchain.com/docs/modules/agents/](https://python.langchain.com/docs/modules/agents/)
- LangGraph Documentation. "Agent Graphs". [https://langchain-ai.github.io/langgraph/](https://langchain-ai.github.io/langgraph/)

---

## è¨˜æ³•è¦ç´„

| è¨˜æ³• | æ„å‘³ | ä¾‹ |
|:-----|:-----|:---|
| $\mathcal{S}$ | çŠ¶æ…‹ç©ºé–“ | $s \in \mathcal{S}$ |
| $\mathcal{A}$ | è¡Œå‹•ç©ºé–“ | $a \in \mathcal{A}$ |
| $\Omega$ | è¦³æ¸¬ç©ºé–“ | $o \in \Omega$ |
| $\pi_\theta$ | ãƒãƒªã‚·ãƒ¼ (LLM) | $a_t \sim \pi_\theta(\cdot \mid o_{1:t})$ |
| $\mathcal{T}$ | Tool | $\mathcal{T} = \langle \text{name}, \text{schema}, \text{function} \rangle$ |
| $\mathcal{R}$ | Tool Registry | $\mathcal{R} = \{ \mathcal{T}_1, \ldots, \mathcal{T}_N \}$ |
| $\mathcal{M}$ | Memory | $\mathcal{M} = \{ (k_i, v_i) \}$ |
| $\mathcal{MAS}$ | Multi-Agent System | $\mathcal{MAS} = \{ \mathcal{A}_1, \ldots, \mathcal{A}_N \}$ |
| $\text{thought}_t$ | æ¨è«–ãƒˆãƒ¬ãƒ¼ã‚¹ | LLMãŒç”Ÿæˆã™ã‚‹æ€è€ƒéç¨‹ |
| $o_{1:t}$ | è¦³æ¸¬å±¥æ­´ | $(o_1, o_2, \ldots, o_t)$ |

---

## ãƒ©ã‚¤ã‚»ãƒ³ã‚¹

æœ¬è¨˜äº‹ã¯ [CC BY-NC-SA 4.0](https://creativecommons.org/licenses/by-nc-sa/4.0/deed.ja)ï¼ˆã‚¯ãƒªã‚¨ã‚¤ãƒ†ã‚£ãƒ–ãƒ»ã‚³ãƒ¢ãƒ³ã‚º è¡¨ç¤º - éå–¶åˆ© - ç¶™æ‰¿ 4.0 å›½éš›ï¼‰ã®ä¸‹ã§ãƒ©ã‚¤ã‚»ãƒ³ã‚¹ã•ã‚Œã¦ã„ã¾ã™ã€‚

### âš ï¸ åˆ©ç”¨åˆ¶é™ã«ã¤ã„ã¦

**æœ¬ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ã¯å€‹äººã®å­¦ç¿’ç›®çš„ã«é™ã‚Šåˆ©ç”¨å¯èƒ½ã§ã™ã€‚**

**ä»¥ä¸‹ã®ã‚±ãƒ¼ã‚¹ã¯äº‹å‰ã®æ˜ç¤ºçš„ãªè¨±å¯ãªãåˆ©ç”¨ã™ã‚‹ã“ã¨ã‚’å›ºãç¦ã˜ã¾ã™:**

1. **ä¼æ¥­ãƒ»çµ„ç¹”å†…ã§ã®åˆ©ç”¨ï¼ˆå–¶åˆ©ãƒ»éå–¶åˆ©å•ã‚ãšï¼‰**
   - ç¤¾å†…ç ”ä¿®ã€æ•™è‚²ã‚«ãƒªã‚­ãƒ¥ãƒ©ãƒ ã€ç¤¾å†…Wikiã¸ã®è»¢è¼‰
   - å¤§å­¦ãƒ»ç ”ç©¶æ©Ÿé–¢ã§ã®è¬›ç¾©åˆ©ç”¨
   - éå–¶åˆ©å›£ä½“ã§ã®ç ”ä¿®åˆ©ç”¨
   - **ç†ç”±**: çµ„ç¹”å†…åˆ©ç”¨ã§ã¯å¸°å±è¡¨ç¤ºãŒå‰Šé™¤ã•ã‚Œã‚„ã™ãã€ç„¡æ–­æ”¹å¤‰ã®ãƒªã‚¹ã‚¯ãŒé«˜ã„ãŸã‚

2. **æœ‰æ–™ã‚¹ã‚¯ãƒ¼ãƒ«ãƒ»æƒ…å ±å•†æãƒ»ã‚»ãƒŸãƒŠãƒ¼ã§ã®åˆ©ç”¨**
   - å—è¬›æ–™ã‚’å¾´åã™ã‚‹å ´ã§ã®é…å¸ƒã€ã‚¹ã‚¯ãƒªãƒ¼ãƒ³ã‚·ãƒ§ãƒƒãƒˆã®æ²ç¤ºã€æ´¾ç”Ÿæ•™æã®ä½œæˆ

3. **LLM/AIãƒ¢ãƒ‡ãƒ«ã®å­¦ç¿’ãƒ‡ãƒ¼ã‚¿ã¨ã—ã¦ã®åˆ©ç”¨**
   - å•†ç”¨ãƒ¢ãƒ‡ãƒ«ã®Pre-trainingã€Fine-tuningã€RAGã®çŸ¥è­˜ã‚½ãƒ¼ã‚¹ã¨ã—ã¦æœ¬ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ã‚’ã‚¹ã‚¯ãƒ¬ã‚¤ãƒ”ãƒ³ã‚°ãƒ»åˆ©ç”¨ã™ã‚‹ã“ã¨

4. **å‹æ‰‹ã«å†…å®¹ã‚’æœ‰æ–™åŒ–ã™ã‚‹è¡Œç‚ºå…¨èˆ¬**
   - æœ‰æ–™noteã€æœ‰æ–™è¨˜äº‹ã€Kindleå‡ºç‰ˆã€æœ‰æ–™å‹•ç”»ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ã€Patreoné™å®šã‚³ãƒ³ãƒ†ãƒ³ãƒ„ç­‰

**å€‹äººåˆ©ç”¨ã«å«ã¾ã‚Œã‚‹ã‚‚ã®:**
- å€‹äººã®å­¦ç¿’ãƒ»ç ”ç©¶
- å€‹äººçš„ãªãƒãƒ¼ãƒˆä½œæˆï¼ˆå€‹äººåˆ©ç”¨ã«é™ã‚‹ï¼‰
- å‹äººã¸ã®å…ƒè¨˜äº‹ãƒªãƒ³ã‚¯å…±æœ‰

**çµ„ç¹”ã§ã®å°å…¥ã‚’ã”å¸Œæœ›ã®å ´åˆ**ã¯ã€å¿…ãšè‘—è€…ã«é€£çµ¡ã‚’å–ã‚Šã€ä»¥ä¸‹ã‚’éµå®ˆã—ã¦ãã ã•ã„:
- å…¨ã¦ã®å¸°å±è¡¨ç¤ºãƒªãƒ³ã‚¯ã‚’ç¶­æŒ
- åˆ©ç”¨æ–¹æ³•ã‚’è‘—è€…ã«å ±å‘Š

**ç„¡æ–­åˆ©ç”¨ãŒç™ºè¦šã—ãŸå ´åˆ**ã€ä½¿ç”¨æ–™ã®è«‹æ±‚ãŠã‚ˆã³SNSç­‰ã§ã®å…¬è¡¨ã‚’è¡Œã†å ´åˆãŒã‚ã‚Šã¾ã™ã€‚

**ğŸ“ ç¬¬30å›å®Œäº†ï¼ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆå®Œå…¨ç‰ˆã‚’ç¿’å¾—ã—ãŸã€‚æ¬¡ã¯ç¬¬31å›ã€ŒMLOpså®Œå…¨ç‰ˆã€ã§æœ¬ç•ªé‹ç”¨ã¸ã€‚**
