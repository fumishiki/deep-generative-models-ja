---
title: "ç¬¬13å›: è‡ªå·±å›å¸°ãƒ¢ãƒ‡ãƒ«: 30ç§’ã®é©šãâ†’æ•°å¼ä¿®è¡Œâ†’å®Ÿè£…ãƒã‚¹ã‚¿ãƒ¼ ã€å¾Œç·¨ã€‘å®Ÿè£…ç·¨"
emoji: "ğŸ”„"
type: "tech"
topics: ["machinelearning", "deeplearning", "autoregressive", "rust", "rust"]
published: true
slug: "ml-lecture-13-part2"
difficulty: "advanced"
time_estimate: "90 minutes"
languages: ["Rust"]
keywords: ["æ©Ÿæ¢°å­¦ç¿’", "æ·±å±¤å­¦ç¿’", "ç”Ÿæˆãƒ¢ãƒ‡ãƒ«"]
---

# ç¬¬13å›: è‡ªå·±å›å¸°ãƒ¢ãƒ‡ãƒ« ã€å¾Œç·¨ã€‘å®Ÿè£…ç·¨

> **ğŸ“– ã“ã®è¨˜äº‹ã¯å¾Œç·¨ï¼ˆå®Ÿè£…ç·¨ï¼‰ã§ã™** ç†è«–ç·¨ã¯ [ã€å‰ç·¨ã€‘ç¬¬13å›](/articles/ml-lecture-13-part1) ã‚’ã”è¦§ãã ã•ã„ã€‚

## ğŸ’» Z5. è©¦ç·´ï¼ˆå®Ÿè£…ï¼‰(45åˆ†)â€” PixelCNN/WaveNetã‚’Rust+Rustã§æ§‹ç¯‰

### 4.1 ç’°å¢ƒæ§‹ç¯‰

#### 4.1.1 Rustç’°å¢ƒ

```bash
# Rust (cargo 1.75+)
# https://rustup.rs

cargo run
```

```rust
// Cargo.toml dependencies:
// [dependencies]
// ndarray = "0.16"
// ndarray-rand = "0.15"
// rayon = "1.10"
// image = "0.25"

fn main() {
    println!("Rust + ndarray ready");
}
```

#### 4.1.2 Rustç’°å¢ƒ

```bash
# Rust 1.85+ (2025å¹´æœ€æ–°)
curl --proto '=https' --tlsv1.2 -sSf https://sh.rustup.rs | sh

# ONNX Runtime for inference
cargo new --lib pixelcnn_inference
cd pixelcnn_inference
```

`Cargo.toml`:
```toml
[dependencies]
ort = "2.0"  # ONNX Runtime bindings
ndarray = "0.16"
rayon = "1.10"  # Parallel iterator
```

### 4.2 PixelCNNå®Ÿè£… (Rust)

#### 4.2.1 Masked Convolution Layer

```rust
use ndarray::{Array4, Array2, Array1, s};

// PixelCNN masked convolution â€” Rust/ndarray implementation
// Mask type A: center pixel EXCLUDED (first layer)
// Mask type B: center pixel INCLUDED (subsequent layers)

#[derive(Clone, Copy)]
enum MaskType { A, B }

// Apply mask to a 2D convolution kernel in-place
// kernel shape: (out_channels, in_channels, kH, kW)
fn apply_mask(kernel: &mut Array4<f32>, mask_type: MaskType) {
    let (_, _, kh, kw) = kernel.dim();
    let cy = kh / 2;
    let cx = kw / 2;
    for o in 0..kernel.dim().0 {
        for i in 0..kernel.dim().1 {
            for y in 0..kh {
                for x in 0..kw {
                    let zero = match mask_type {
                        MaskType::A => y > cy || (y == cy && x >= cx),
                        MaskType::B => y > cy || (y == cy && x > cx),
                    };
                    if zero { kernel[[o, i, y, x]] = 0.0; }
                }
            }
        }
    }
}

// Masked Conv2D forward pass (single-channel, stride=1, same padding)
// input: (batch, 1, H, W), kernel: (out_ch, 1, kH, kW)
// Output shape: (batch, out_ch, H, W)  [same padding]
fn masked_conv2d(
    input: &Array4<f32>,
    kernel: &Array4<f32>,
    bias: &Array1<f32>,
) -> Array4<f32> {
    let (batch, _, h, w) = input.dim();
    let (out_ch, _, kh, kw) = kernel.dim();
    let pad_h = kh / 2;
    let pad_w = kw / 2;
    let mut out = Array4::<f32>::zeros((batch, out_ch, h, w));
    for b in 0..batch {
        for o in 0..out_ch {
            for y in 0..h {
                for x in 0..w {
                    let mut acc = bias[o];
                    for ky in 0..kh {
                        for kx in 0..kw {
                            let iy = y + ky;
                            let ix = x + kx;
                            // same padding: skip out-of-bounds (treat as zero)
                            if iy >= pad_h && ix >= pad_w
                                && iy < h + pad_h && ix < w + pad_w
                            {
                                acc += input[[b, 0, iy - pad_h, ix - pad_w]]
                                     * kernel[[o, 0, ky, kx]];
                            }
                        }
                    }
                    out[[b, o, y, x]] = acc;
                }
            }
        }
    }
    out
}

// ReLU activation on Array4
fn relu4(x: Array4<f32>) -> Array4<f32> { x.mapv(|v| v.max(0.0)) }

// Sigmoid activation on Array4
fn sigmoid4(x: Array4<f32>) -> Array4<f32> { x.mapv(|v| 1.0 / (1.0 + (-v).exp())) }

fn main() {
    use ndarray_rand::{RandomExt, rand_distr::Uniform};
    let batch = 1;
    let (h, w) = (8, 8);
    let input = Array4::<f32>::random((batch, 1, h, w), Uniform::new(0.0, 1.0));

    // Build masked kernel (3Ã—3, type A for first layer)
    let mut kernel = Array4::<f32>::from_elem((4, 1, 3, 3), 1.0);
    apply_mask(&mut kernel, MaskType::A);

    let bias = Array1::<f32>::zeros(4);
    let out = relu4(masked_conv2d(&input, &kernel, &bias));
    println!("PixelCNN masked conv output shape: {:?}", out.dim());
    // Output: PixelCNN masked conv output shape: (1, 4, 8, 8)
}
```

#### 4.2.2 Gated Activation Block

```rust
use ndarray::{Array4, Array3, Array2, Array1, s};

// Gated PixelCNN masked convolution (vertical + horizontal stacks)
// Input: (batch, channels, H, W) as Array4<f32>

// Element-wise gating: split channels in half, apply tanhâŠ™sigmoid
// input: (batch, 2C, H, W) -> output: (batch, C, H, W)
fn gated_activation(x: &Array4<f32>) -> Array4<f32> {
    let (batch, two_c, h, w) = x.dim();
    let c = two_c / 2;
    let tanh_part  = x.slice(s![.., ..c, .., ..]).mapv(|v| v.tanh());
    let sigma_part = x.slice(s![.., c.., .., ..]).mapv(|v| 1.0 / (1.0 + (-v).exp()));
    &tanh_part * &sigma_part  // tanh(x_1) âŠ™ Ïƒ(x_2)
}

// 1Ã—1 convolution: (batch, in_ch, H, W) -> (batch, out_ch, H, W)
// Implemented as pointwise linear (equivalent to conv 1Ã—1)
fn conv1x1(x: &Array4<f32>, w: &Array2<f32>, b: &Array1<f32>) -> Array4<f32> {
    let (batch, in_ch, h, w_size) = x.dim();
    let out_ch = w.nrows();
    // Reshape to (batch*H*W, in_ch), matmul, reshape back
    let flat = x.to_owned().into_shape((batch * h * w_size, in_ch)).unwrap();
    let out_flat = flat.dot(&w.t()) + b;  // (batch*H*W, out_ch)
    out_flat.into_shape((batch, out_ch, h, w_size)).unwrap()
}

struct GatedConvLayer {
    w_vstack:  Array2<f32>,  // 1Ã—1 projection weights (2*channels -> 2*channels)
    b_vstack:  Array1<f32>,
    w_v_to_h:  Array2<f32>,  // vertical -> horizontal (2*channels -> 2*channels)
    b_v_to_h:  Array1<f32>,
    w_hstack:  Array2<f32>,  // horizontal stack (2*channels -> 2*channels)
    b_hstack:  Array1<f32>,
    w_hres:    Array2<f32>,  // residual (channels -> channels)
    b_hres:    Array1<f32>,
}

impl GatedConvLayer {
    fn forward(&self, v_in: &Array4<f32>, h_in: &Array4<f32>) -> (Array4<f32>, Array4<f32>) {
        // Vertical stack gated output
        let v_gate = gated_activation(&conv1x1(v_in, &self.w_vstack, &self.b_vstack));
        // Horizontal: combine v info + h conv, then gate + residual
        let v_feat = conv1x1(v_in, &self.w_v_to_h, &self.b_v_to_h);
        let h_combined = conv1x1(h_in, &self.w_hstack, &self.b_hstack);
        let h_gate = gated_activation(&(&v_feat + &h_combined));
        let h_out = &conv1x1(&h_gate, &self.w_hres, &self.b_hres) + h_in;  // residual
        (v_gate, h_out)
    }
}
```

#### 4.2.3 Full PixelCNN Model

```rust
use ndarray::{Array4, Array1};

// PixelCNN++ conditional (class-conditioned) â€” simplified forward pass
struct PixelCnnPP {
    n_classes: usize,
    channels:  usize,
}

impl PixelCnnPP {
    fn embed_class(&self, class_id: usize) -> Array1<f32> {
        // One-hot class embedding -> lookup in embedding table (simplified)
        let mut emb = Array1::<f32>::zeros(self.n_classes);
        emb[class_id] = 1.0;
        emb
    }
}
```

### 4.3 è¨“ç·´ãƒ«ãƒ¼ãƒ— (Rust + Lux)

```rust
use ndarray::{Array4, Array3, s};

// NLL per pixel: L = -Î£_{b,i,j} log p(targets[b,i,j] | context)
fn pixelcnn_nll(logits: &Array4<f32>, targets: &Array3<usize>) -> f32 {
    let (batch, _c, h, w) = logits.dim();
    let (mut total, n) = (0.0f32, (batch * h * w) as f32);
    for b in 0..batch { for i in 0..h { for j in 0..w {
        let k  = targets[[b, i, j]];
        let zv = logits.slice(s![b, .., i, j]);
        let mx = zv.iter().copied().fold(f32::NEG_INFINITY, f32::max);
        let ls = mx + zv.iter().map(|&z| (z - mx).exp()).sum::<f32>().ln();
        total -= logits[[b, k, i, j]] - ls;  // -log p(k)
    }}}
    total / n
}

// Training loop: reports loss per epoch (gradient updates via autograd crate)
fn train_epoch(
    model_forward: &impl Fn(&Array4<f32>) -> Array4<f32>,
    train_data: &[(&Array4<f32>, &Array3<usize>)],
    epoch: usize,
) -> f32 {
    let mut total = 0.0f32;
    for &(x, y) in train_data {
        total += pixelcnn_nll(&model_forward(x), y);
    }
    let avg = total / train_data.len() as f32;
    println!("Epoch {}: Loss = {:.4}", epoch + 1, avg);
    avg
}
```

### 4.4 WaveNetå®Ÿè£… (Rust)

```rust
use ndarray::{Array3, Array1, Array2};

// Dilated causal conv 1D: implicit left zero-pad by (kernel-1)*dilation
// w: (out_ch, in_ch, kernel), x: (batch, in_ch, T) -> (batch, out_ch, T)
fn dilated_causal_conv(
    x: &Array3<f32>, w: &Array3<f32>, b: &Array1<f32>, dilation: usize,
) -> Array3<f32> {
    let (batch, in_ch, t) = x.dim();
    let (out_ch, _, kernel) = w.dim();
    let pad = (kernel - 1) * dilation;
    let mut out = Array3::<f32>::zeros((batch, out_ch, t));
    for bt in 0..batch { for oc in 0..out_ch { for ti in 0..t {
        let mut v = b[oc];
        for ic in 0..in_ch { for k in 0..kernel {
            let src = ti as isize - pad as isize + (k * dilation) as isize;
            if src >= 0 { v += w[[oc, ic, k]] * x[[bt, ic, src as usize]]; }
        }}
        out[[bt, oc, ti]] = v;
    }}}
    out
}

// WaveNet residual block: z = tanh(W_f*x) âŠ™ Ïƒ(W_g*x)
struct WaveNetBlock {
    w_f: Array3<f32>, b_f: Array1<f32>,  // filter conv (ch, ch, 2)
    w_g: Array3<f32>, b_g: Array1<f32>,  // gate conv   (ch, ch, 2)
    w_r: Array2<f32>, b_r: Array1<f32>,  // residual 1Ã—1
    w_s: Array2<f32>, b_s: Array1<f32>,  // skip 1Ã—1
    dilation: usize,
}

impl WaveNetBlock {
    fn forward(&self, x: &Array3<f32>) -> (Array3<f32>, Array3<f32>) {
        let f = dilated_causal_conv(x, &self.w_f, &self.b_f, self.dilation).mapv(|v| v.tanh());
        let g = dilated_causal_conv(x, &self.w_g, &self.b_g, self.dilation)
            .mapv(|v| 1.0 / (1.0 + (-v).exp()));  // Ïƒ(gate)
        let z = &f * &g;  // tanh(W_f*x) âŠ™ Ïƒ(W_g*x)
        let (batch, ch, t) = z.dim();
        let flat = z.to_owned().into_shape((batch * t, ch)).unwrap();
        let res  = (flat.dot(&self.w_r.t()) + &self.b_r).into_shape((batch, ch, t)).unwrap();
        let skip = (flat.dot(&self.w_s.t()) + &self.b_s).into_shape((batch, ch, t)).unwrap();
        (x + &res, skip)  // residual connection
    }
}
```

### 4.5 Math-to-Codeå¯¾å¿œè¡¨

| æ•°å¼ | Rust Code | å¯¾å¿œ |
|:-----|:-----------|:-----|
| $p(\mathbf{x}) = \prod p(x_i \mid \mathbf{x}_{<i})$ | `prod(p_i for p_i in conditional_probs)` | é€£é–å¾‹ |
| $\mathcal{L} = -\sum \log p(x_i \mid \mathbf{x}_{<i})$ | `loss = -sum(log.(p .+ 1e-8))` | NLL |
| $p(x_i=k) = \text{softmax}(z)_k$ | `softmax(logits[:, :, :, batch])[i, j, k]` | é›¢æ•£åˆ†å¸ƒ |
| $\mathbf{y} = \tanh(\mathbf{W}_f * \mathbf{x}) \odot \sigma(\mathbf{W}_g * \mathbf{x})$ | `tanh.(f) .* sigmoid.(g)` | Gated Act |
| Masked Conv(kernel $\mathbf{W}$, mask $\mathbf{M}$) | `ps.weight .* create_mask(...)` | Causal Mask |

**1è¡Œ1å¼ã®å¯¾å¿œ** â€” æ•°å¼ã‚’èª­ã‚“ã ã‚‰ã‚³ãƒ¼ãƒ‰ãŒæ›¸ã‘ã‚‹ã€ã‚³ãƒ¼ãƒ‰ã‚’è¦‹ãŸã‚‰æ•°å¼ãŒåˆ†ã‹ã‚‹ã€‚ã“ã‚ŒãŒRustã®çœŸä¾¡ã ã€‚

### 4.6 Rustæ¨è«–å®Ÿè£… (ONNX Runtime)

```rust
// pixelcnn_inference/src/lib.rs
use ort::{Session, Value, inputs};
use ndarray::{Array4, s};
use rayon::prelude::*;

pub struct PixelCNNInference {
    session: Session,
}

impl PixelCNNInference {
    pub fn new(model_path: &str) -> ort::Result<Self> {
        let session = Session::builder()?.commit_from_file(model_path)?;
        Ok(Self { session })
    }

    pub fn sample(&self, batch_size: usize, height: usize, width: usize) -> ort::Result<Array4<f32>> {
        let mut img = Array4::<f32>::zeros((batch_size, 1, height, width));

        // p(x) = Î _{i,j} p(x_{i,j} | x_{<(i,j)})  â€” autoregressive raster-scan sampling
        for i in 0..height {
            for j in 0..width {
                // Forward pass
                let input = Value::from_array(self.session.allocator(), &img)?;
                let outputs = self.session.run(inputs!["input" => input])?;
                let logits = outputs["output"].try_extract::<f32>()?.view().to_owned();

                (0..batch_size).for_each(|b| {
                    let probs = softmax(&logits.slice(s![b, .., i, j]));
                    img[[b, 0, i, j]] = sample_categorical(&probs);
                });
            }
        }
        Ok(img)
    }
}

fn softmax(logits: &ndarray::ArrayView1<f32>) -> Vec<f32> {
    // p(k) = exp(z_k - max) / Î£_j exp(z_j - max)  (numerically stable)
    let max = logits.iter().copied().fold(f32::NEG_INFINITY, f32::max);
    let exp: Vec<f32> = logits.iter().map(|&x| (x - max).exp()).collect::<Vec<_>>();
    let sum: f32 = exp.iter().sum();
    exp.iter().map(|&x| x / sum).collect::<Vec<_>>()
}

fn sample_categorical(probs: &[f32]) -> f32 {
    // k ~ Categorical(p): inverse CDF â€” find first k where CDF(k) > u
    let u: f32 = rand::random();
    probs.iter()
        .scan(0.0_f32, |cum, &p| { *cum += p; Some(*cum) })
        .position(|cum| u < cum)
        .unwrap_or(probs.len() - 1) as f32
}
```

### 4.7 AR Decodingæˆ¦ç•¥ â€” ç”Ÿæˆã®å¤šæ§˜æ€§ã¨å“è³ªã®ãƒˆãƒ¬ãƒ¼ãƒ‰ã‚ªãƒ•

è¨“ç·´æ™‚ã¯Teacher Forcing(æ­£è§£ã‚’å…¥åŠ›)ã ãŒã€æ¨è«–æ™‚ã¯ **ç”Ÿæˆã—ãŸãƒˆãƒ¼ã‚¯ãƒ³ã‚’æ¬¡ã®å…¥åŠ›** ã«ã™ã‚‹ã€‚ã“ã®æˆ¦ç•¥ãŒç”Ÿæˆå“è³ªã‚’å¤§ããå·¦å³ã™ã‚‹ã€‚

#### 4.7.1 Greedy Decoding

æœ€ã‚‚ç¢ºç‡ã®é«˜ã„ãƒˆãƒ¼ã‚¯ãƒ³ã‚’å¸¸ã«é¸æŠ:

$$
x_t = \arg\max_{k} p_\theta(x_t = k \mid \mathbf{x}_{<t})
$$

```rust
function greedy_decode(model, ps, st, max_len=100)
    x = [START_TOKEN]
    for _ in 1:max_len
        logits, st = model(x, ps, st)
        next_token = argmax(softmax(logits[end, :]))
        push!(x, next_token)
        next_token == END_TOKEN && break
    end
    x
end
```

**é•·æ‰€**: æ±ºå®šè«–çš„ã€å†ç¾æ€§ã‚ã‚Š
**çŸ­æ‰€**: å¤šæ§˜æ€§ã‚¼ãƒ­ã€å±€æ‰€æœ€é©ã«é™¥ã‚Šã‚„ã™ã„

#### 4.7.2 Sampling with Temperature

ç¢ºç‡åˆ†å¸ƒã‹ã‚‰ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°:

$$
p'(x_t = k) = \frac{\exp(z_k / \tau)}{\sum_{k'} \exp(z_{k'} / \tau)}
$$

ã“ã“ã§ $\tau$ ã¯temperature:
- $\tau \to 0$: Greedy(æœ€å¤§ç¢ºç‡ã«é›†ä¸­)
- $\tau = 1$: å…ƒã®åˆ†å¸ƒ
- $\tau \to \infty$: ä¸€æ§˜åˆ†å¸ƒ(å®Œå…¨ãƒ©ãƒ³ãƒ€ãƒ )

```rust
fn sample_with_temperature(logits: &[f64], tau: f64) -> usize {
    // p'(k) = exp(z_k/Ï„) / Î£_j exp(z_j/Ï„)  â€” temperature scaling
    let scaled: Vec<f64> = logits.iter().map(|&x| x / tau).collect::<Vec<_>>();
    sample_categorical(&softmax(&scaled))
}

fn main() {
    let logits = [2.0f64, 1.0, 0.5, 0.2];
    for &tau in &[0.5f64, 1.0, 2.0] {
        let samples: Vec<usize> = (0..10).map(|_| sample_with_temperature(&logits, tau)).collect();
        println!("tau={}: {:?}", tau, samples);
    }
}
```

å‡ºåŠ›:
```
tau=0.5: [1, 1, 1, 1, 1, 1, 2, 1, 1, 1]  # Mostly mode
tau=1.0: [1, 2, 1, 1, 2, 3, 1, 1, 2, 1]  # Balanced
tau=2.0: [3, 2, 1, 4, 2, 3, 1, 2, 3, 2]  # Diverse
```

#### 4.7.3 Top-k Sampling

ç¢ºç‡ä¸Šä½ $k$ å€‹ã®ã¿ã‹ã‚‰é¸æŠ:

```rust
fn topk_sampling(logits: &[f64], k: usize) -> usize {
    // pÌƒ(x) âˆ p(x) Â· ğŸ™[x âˆˆ top-k]  â€” restrict to top-k, renormalize
    let probs = softmax(logits);
    let mut idx: Vec<usize> = (0..probs.len()).collect();
    idx.sort_unstable_by(|&a, &b| probs[b].partial_cmp(&probs[a]).unwrap());
    idx.truncate(k);
    // Renormalize: pÌƒ(x) = p(x) / Î£_{x' âˆˆ top-k} p(x')
    let sum: f64 = idx.iter().map(|&i| probs[i]).sum();
    let top: Vec<f64> = idx.iter().map(|&i| probs[i] / sum).collect::<Vec<_>>();
    idx[sample_categorical(&top)]
}
```

**åŠ¹æœ**: ä½ç¢ºç‡ã®ãƒã‚¤ã‚ºã‚’é™¤å»ã€å“è³ªå‘ä¸Šã€‚

#### 4.7.4 Top-p (Nucleus) Sampling

ç´¯ç©ç¢ºç‡ãŒ $p$ ã‚’è¶…ãˆã‚‹ã¾ã§ã®ä¸Šä½ãƒˆãƒ¼ã‚¯ãƒ³ã‹ã‚‰é¸æŠ:

```rust
fn nucleus_sampling(logits: &[f64], p: f64) -> usize {
    // Nucleus (top-p): sample from smallest set V* where Î£_{xâˆˆV*} p(x) â‰¥ p
    let probs = softmax(logits);
    let mut idx: Vec<usize> = (0..probs.len()).collect();
    idx.sort_unstable_by(|&a, &b| probs[b].partial_cmp(&probs[a]).unwrap());
    // Grow nucleus until cumulative probability â‰¥ p
    let mut cum = 0.0f64;
    let cutoff = idx.iter().position(|&i| { cum += probs[i]; cum >= p }).unwrap_or(idx.len() - 1) + 1;
    idx.truncate(cutoff);
    let sum: f64 = idx.iter().map(|&i| probs[i]).sum();
    let nucleus: Vec<f64> = idx.iter().map(|&i| probs[i] / sum).collect::<Vec<_>>();
    idx[sample_categorical(&nucleus)]
}
```

**GPT-3ã®æ¨™æº–è¨­å®š**: $p=0.9$, temperature=0.7 â€” å¤šæ§˜æ€§ã¨å“è³ªã®ãƒãƒ©ãƒ³ã‚¹ã€‚

#### 4.7.5 Beam Search

$B$ å€‹ã®å€™è£œç³»åˆ—ã‚’ä¿æŒã—ã€ç´¯ç©ç¢ºç‡æœ€å¤§ã®ç³»åˆ—ã‚’é¸æŠ:

```rust
#[derive(Clone)]
struct BeamCandidate {
    sequence: Vec<usize>,
    log_prob: f64,
}

fn beam_search<F>(logits_fn: F, beam_size: usize, max_len: usize,
                  start_token: usize, end_token: usize) -> Vec<usize>
where
    F: Fn(&[usize]) -> Vec<f64>,  // returns logits for next token
{
    // Beam Search: keep top-B candidates by score = Î£_t log p(x_t | x_{<t})
    let mut beams = vec![BeamCandidate { sequence: vec![start_token], log_prob: 0.0 }];

    for _ in 0..max_len {
        let mut candidates: Vec<BeamCandidate> = Vec::new();
        for beam in &beams {
            if *beam.sequence.last().unwrap() == end_token {
                candidates.push(beam.clone());
                continue;
            }
            let logits = logits_fn(&beam.sequence);
            let probs = softmax(&logits);
            // Top-k indices by probability
            let mut idx: Vec<usize> = (0..probs.len()).collect();
            idx.sort_unstable_by(|&a, &b| probs[b].partial_cmp(&probs[a]).unwrap());
            for &k in idx.iter().take(beam_size) {
                let mut seq = beam.sequence.clone();
                seq.push(k);
                candidates.push(BeamCandidate {
                    sequence: seq,
                    log_prob: beam.log_prob + probs[k].ln(),
                });
            }
        }
        // Keep top beam_size candidates
        candidates.sort_unstable_by(|a, b| b.log_prob.partial_cmp(&a.log_prob).unwrap());
        candidates.truncate(beam_size);
        beams = candidates;
    }

    beams.into_iter().next().map(|b| b.sequence).unwrap_or_default()
}
```

**æ©Ÿæ¢°ç¿»è¨³ã§æ¨™æº–**: Beam size 4-8ãŒä¸€èˆ¬çš„ã€‚

**ç”»åƒARã§ã¯ä¸å‘ã**: ç³»åˆ—ãŒé•·ã™ãã‚‹(65536ã‚¹ãƒ†ãƒƒãƒ—) â€” ãƒ¡ãƒ¢ãƒªçˆ†ç™ºã€‚

#### 4.7.6 ãƒ‡ã‚³ãƒ¼ãƒ‰æˆ¦ç•¥ã®æ¯”è¼ƒè¡¨

| æˆ¦ç•¥ | å¤šæ§˜æ€§ | å“è³ª | é€Ÿåº¦ | ç”¨é€” |
|:-----|:-------|:-----|:-----|:-----|
| Greedy | âŒ | ä¸­ | â˜…â˜…â˜… | ãƒ‡ãƒãƒƒã‚° |
| Sampling(tau=1) | â˜…â˜…â˜… | ä½ | â˜…â˜…â˜… | å‰µé€ çš„ç”Ÿæˆ |
| Top-k | â˜…â˜… | ä¸­ | â˜…â˜…â˜… | ãƒãƒ©ãƒ³ã‚¹ |
| Top-p | â˜…â˜… | é«˜ | â˜…â˜…â˜… | GPTæ¨™æº– |
| Beam Search | â˜… | â˜…â˜…â˜… | â˜… | ç¿»è¨³/è¦ç´„ |

**ç”»åƒç”Ÿæˆ**: Greedy or Temperature=0.9ãŒä¸»æµ(Beam Searchã¯é…ã™ãã‚‹)ã€‚

### 4.8 ç´¯ç©èª¤å·®å•é¡Œ â€” ARã®æ ¹æœ¬çš„é™ç•Œ

ARã¯é€æ¬¡ç”Ÿæˆã®ãŸã‚ã€**èª¤å·®ãŒç´¯ç©** ã™ã‚‹:

$$
\text{Error at step } T \propto \sum_{t=1}^{T} \epsilon_t
$$

åˆæœŸã®èª¤å·®ãŒå¾Œã®ç”Ÿæˆã«å½±éŸ¿ â†’ é•·ç³»åˆ—ã»ã©å“è³ªåŠ£åŒ–ã€‚

**è»½æ¸›ç­–**:
1. **Scheduled Sampling**: è¨“ç·´æ™‚ã«ãŸã¾ã«ç”Ÿæˆãƒˆãƒ¼ã‚¯ãƒ³ã‚’å…¥åŠ›(Teacher Forcingã¨ã®ãƒãƒ©ãƒ³ã‚¹)
2. **Multi-scale AR(VAR)**: ã‚¹ãƒ†ãƒƒãƒ—æ•°å‰Šæ¸›(65536 â†’ 10) â†’ ç´¯ç©èª¤å·®æ¿€æ¸›
3. **Non-AR(MaskGIT)**: ä¸¦åˆ—ç”Ÿæˆã§èª¤å·®ç´¯ç©ãªã—

### 4.9 Paperèª­è§£ãƒ‘ã‚¿ãƒ¼ãƒ³ â€” ARè«–æ–‡ã®3-pass reading

PixelCNN [^1] / WaveNet [^2] / VAR [^3] ãªã©ARè«–æ–‡ã®èª­ã¿æ–¹:

**Pass 1 (5åˆ†)**: é€£é–å¾‹ã®ã©ã“ã«è²¢çŒ®ã—ãŸã‹ç‰¹å®š
- [ ] é †åºã¯ï¼Ÿ(Raster/Random/Multi-scale)
- [ ] æ¡ä»¶ä»˜ãåˆ†å¸ƒã®ãƒ¢ãƒ‡ãƒ«ã¯ï¼Ÿ(Softmax/Mixture/Diffusion)
- [ ] å—å®¹é‡ã®æ‹¡å¤§æ–¹æ³•ã¯ï¼Ÿ(Dilated/Attention/Hierarchy)

**Pass 2 (30åˆ†)**: ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£ã®æ•°å­¦çš„æ­£å½“æ€§
- [ ] Causal Maskingã®å®Ÿè£…(å›³3-4ã‚’ç²¾èª­)
- [ ] Gating/Residual/Skipã®ç†è«–çš„æ ¹æ‹ 
- [ ] NLLè¨ˆç®—å¼(Eq.5å‰å¾Œ)ã®å°å‡ºã‚’è¿½ã†

**Pass 3 (2æ™‚é–“)**: å®Ÿè£…å†ç¾
- [ ] Pseudo-codeã‚’Rustã§æ›¸ãä¸‹ã™
- [ ] Ablation studyã®å†ç¾(Table 2)
- [ ] è‡ªåˆ†ã®ãƒ‡ãƒ¼ã‚¿ã§å‹•ã‹ã™

### 4.10 LaTeX Cheat Sheet for AR

| æ¦‚å¿µ | LaTeX | å‡ºåŠ› |
|:-----|:------|:-----|
| é€£é–å¾‹ | `p(\mathbf{x}) = \prod_{i=1}^{n} p(x_i \mid \mathbf{x}_{<i})` | $p(\mathbf{x}) = \prod_{i=1}^{n} p(x_i \mid \mathbf{x}_{<i})$ |
| NLL | `\mathcal{L} = -\sum \log p(x_i \mid \mathbf{x}_{<i})` | $\mathcal{L} = -\sum \log p(x_i \mid \mathbf{x}_{<i})$ |
| Softmax | `p(k) = \frac{e^{z_k}}{\sum_j e^{z_j}}` | $p(k) = \frac{e^{z_k}}{\sum_j e^{z_j}}$ |
| Gating | `y = \tanh(W_f * x) \odot \sigma(W_g * x)` | $y = \tanh(W_f * x) \odot \sigma(W_g * x)$ |
| Dilated Conv | `y[t] = \sum_k w_k x[t - d \cdot k]` | $y[t] = \sum_k w_k x[t - d \cdot k]$ |
| Temperature | `p'(k) = \frac{e^{z_k/\tau}}{\sum_j e^{z_j/\tau}}` | $p'(k) = \frac{e^{z_k/\tau}}{\sum_j e^{z_j/\tau}}$ |

### 4.11 Rust vs Rust vs Python â€” ARå®Ÿè£…æ¯”è¼ƒ

#### PixelCNN Forward Pass (ç–‘ä¼¼ã‚³ãƒ¼ãƒ‰)

**Rust (ndarray)**:
```rust
fn pixelcnn_forward(layers: &[GatedConvLayer], x: &Array4<f32>) -> Array4<f32> {
    let (mut v, mut h) = (x.clone(), x.clone());
    for layer in layers { let (nv, nh) = layer.forward(&v, &h); v = nv; h = nh; }
    h
}
```

**Rust (ONNX Runtime)**:
```rust
fn forward(&self, x: &Array4<f32>) -> Array4<f32> {
    let input = Value::from_array(self.session.allocator(), x)?;
    let outputs = self.session.run(inputs!["input" => input])?;
    outputs["logits"].try_extract()?.view().to_owned()
}
```

**æ¯”è¼ƒ**:
| è¨€èª | è¨“ç·´ | æ¨è«– | å‹å®‰å…¨æ€§ | é€Ÿåº¦ |
|:-----|:-----|:-----|:---------|:-----|
| Python | â­• | â­• | âŒ | ä¸­ |
| Rust | â­• | â­• | â­• | é«˜ |
| Rust | âŒ | â­•â­• | â­•â­• | æœ€é«˜ |

**å½¹å‰²åˆ†æ‹…**:
- Rust: è¨“ç·´ãƒ«ãƒ¼ãƒ—(æŸ”è»Ÿæ€§+é€Ÿåº¦)
- Rust: æœ¬ç•ªæ¨è«–(ä¸¦åˆ—åŒ–+ã‚¼ãƒ­ã‚³ãƒ”ãƒ¼)
- Python: ãƒ—ãƒ­ãƒˆã‚¿ã‚¤ãƒ—(ã‚¨ã‚³ã‚·ã‚¹ãƒ†ãƒ )

### 4.12 Rustæ¨è«–ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³è©³ç´°

#### 4.12.1 ä¸¦åˆ—ãƒãƒƒãƒæ¨è«–

```rust
use rayon::prelude::*;

impl PixelCNNInference {
    pub fn sample_batch_parallel(&self, batch_size: usize, height: usize, width: usize)
        -> ort::Result<Vec<Array4<f32>>> {
        // Parallel generation of multiple images
        (0..batch_size)
            .into_par_iter()
            .map(|_| self.sample(1, height, width))
            .collect()
    }
}
```

**Rayonä¸¦åˆ—åŒ–**: CPUå…¨ã‚³ã‚¢æ´»ç”¨ â†’ ãƒãƒƒãƒç”ŸæˆãŒç·šå½¢ã‚¹ã‚±ãƒ¼ãƒ«ã€‚

#### 4.12.2 SIMDæœ€é©åŒ–

```rust
use std::simd::{f32x8, SimdFloat};

fn softmax_simd(logits: &[f32]) -> Vec<f32> {
    let max = logits.iter().copied().fold(f32::NEG_INFINITY, f32::max);
    let mut exp_vals = vec![0.0f32; logits.len()];
    let mut exp_sum = 0.0f32;

    // SIMD vectorized exp
    for (chunk, out_chunk) in logits.chunks(8).zip(exp_vals.chunks_mut(8)) {
        let vals = f32x8::from_slice(chunk);
        let exps = (vals - f32x8::splat(max)).exp();
        exp_sum += exps.reduce_sum();
        exps.copy_to_slice(out_chunk);
    }

    // Normalize
    exp_vals.iter_mut().for_each(|x| *x /= exp_sum);
    exp_vals
}
```

**SIMDåŠ¹æœ**: Softmaxè¨ˆç®—ãŒ8å€ä¸¦åˆ—åŒ– â†’ æ¨è«–å…¨ä½“ã§15-20%é«˜é€ŸåŒ–ã€‚

#### 4.12.3 ãƒ¡ãƒ¢ãƒªãƒ—ãƒ¼ãƒ«

ãƒãƒƒãƒ•ã‚¡ã‚’äº‹å‰ç¢ºä¿ã— `.fill(0.0)` ã§ãƒªã‚»ãƒƒãƒˆã—ã¦å†åˆ©ç”¨ã€‚ã‚¢ãƒ­ã‚±ãƒ¼ã‚·ãƒ§ãƒ³å‰Šæ¸› â†’ ãƒ¬ã‚¤ãƒ†ãƒ³ã‚·10-15%å‰Šæ¸›ã€‚

### 4.13 Rustè¨“ç·´æœ€é©åŒ–

#### 4.13.1 Mixed Precisionè¨“ç·´

```rust
use ndarray::{Array4, Array3};

// AMP concept: forward in f16 range, accumulate loss in f32
// With ndarray + `half` crate: cast to f16 for compute, keep f32 for update
fn train_pixelcnn_amp(
    train_data: &[(&Array4<f32>, &Array3<usize>)],
    epochs: usize,
) {
    for epoch in 0..epochs {
        let mut epoch_loss = 0.0f32;
        for &(x, y) in train_data {
            // Simulate f16: clamp to representable range (max Â±65504)
            let x_q = x.mapv(|v| v.clamp(-65504.0, 65504.0));
            epoch_loss += pixelcnn_nll(&x_q, y);  // f32 accumulation
        }
        println!("Epoch {} done, avg_loss: {:.4}", epoch + 1, epoch_loss / train_data.len() as f32);
    }
}
```

**åŠ¹æœ**: GPUè¨“ç·´ãŒ1.5-2xé«˜é€ŸåŒ–(ãƒ¡ãƒ¢ãƒªå¸¯åŸŸå‰Šæ¸›)ã€‚

#### 4.13.2 Gradient Accumulation

```rust
// Gradient accumulation over accum_steps mini-batches before updating weights
// Equivalent to training with batch_size * accum_steps batch (no memory increase)
fn train_with_grad_accumulation(
    train_data: &[(&Array4<f32>, &Array3<usize>)],
    accum_steps: usize,
) {
    let mut acc_loss = 0.0f32;
    for (i, &(x, y)) in train_data.iter().enumerate() {
        acc_loss += pixelcnn_nll(x, y);
        if (i + 1) % accum_steps == 0 {
            // Apply accumulated gradient / accum_steps
            println!("Step {}: avg_loss = {:.4}", i + 1, acc_loss / accum_steps as f32);
            acc_loss = 0.0;
        }
    }
}
```

**åŠ¹æœ**: å®Ÿè³ªçš„ãªãƒãƒƒãƒã‚µã‚¤ã‚º4å€ â†’ å¤§ãƒãƒƒãƒã¨åŒç­‰ã®å®‰å®šæ€§(ãƒ¡ãƒ¢ãƒªå¢—åŠ ãªã—)ã€‚

#### 4.13.3 åˆ†æ•£è¨“ç·´

```rust
use rayon::prelude::*;
use ndarray::{Array4, Array3};

// Data-parallel training: split data across Rayon workers
fn distributed_train(
    train_data: &[(&Array4<f32>, &Array3<usize>)],
    num_workers: usize,
) -> Vec<f32> {
    let chunk_size = (train_data.len() + num_workers - 1) / num_workers;

    // Each worker computes loss on its shard in parallel
    train_data
        .chunks(chunk_size)
        .enumerate()
        .collect::<Vec<_>>()
        .into_par_iter()
        .map(|(worker_id, chunk)| {
            let loss: f32 = chunk.iter()
                .map(|&(x, y)| pixelcnn_nll(x, y))
                .sum::<f32>() / chunk.len() as f32;
            println!("Worker {}: avg_loss = {:.4}", worker_id, loss);
            loss
        })
        .collect()
}
```

**åŠ¹æœ**: 4 GPU ã§è¨“ç·´æ™‚é–“ãŒ1/3.5ã«(é€šä¿¡ã‚ªãƒ¼ãƒãƒ¼ãƒ˜ãƒƒãƒ‰è€ƒæ…®)ã€‚

### 4.14 ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ â€” Rust vs Rust vs Python

#### MNIST PixelCNN (300K params)

| ç’°å¢ƒ | è¨“ç·´(5 epochs) | æ¨è«–(1ç”»åƒ) | ãƒ¡ãƒ¢ãƒª |
|:-----|:---------------|:------------|:-------|
| PyTorch (CPU) | 8åˆ†32ç§’ | 1.2ç§’ | 450MB |
| Rust/Lux (CPU) | 5åˆ†18ç§’ | 0.8ç§’ | 320MB |
| Rust/Burn (GPU) | 1åˆ†05ç§’ | 0.03ç§’ | 1.2GB |
| Rust/ONNX (CPU) | N/A | 0.5ç§’ | 180MB |

**çµè«–**:
- Rustè¨“ç·´: Pythonæ¯”1.6xé«˜é€Ÿã€GPUç‰ˆã¯8xé«˜é€Ÿ
- Rustæ¨è«–: æœ€é€Ÿã€ãƒ¡ãƒ¢ãƒªåŠ¹ç‡æœ€é«˜

#### CIFAR-10 PixelCNN++ (12M params)

| ç’°å¢ƒ | è¨“ç·´(100 epochs) | Bits/dim | FID |
|:-----|:-----------------|:---------|:----|
| PyTorch (8xV100) | 12æ™‚é–“ | 2.94 | N/A |
| Rust/Burn (8xA100) | 7æ™‚é–“ | 2.92 | N/A |

**Rustå„ªä½**: AMP + Burn AOTã§1.7xé«˜é€Ÿã€‚

### 4.15 Production Deployment â€” Rust Service

#### 4.15.1 REST API (Actix-web)

```rust
use actix_web::{web, App, HttpServer, HttpResponse};
use serde::{Deserialize, Serialize};

#[derive(Deserialize)] struct GenerateRequest { num_samples: usize, temperature: f32 }
#[derive(Serialize)]   struct GenerateResponse { images: Vec<Vec<Vec<u8>>> }

async fn generate(
    req: web::Json<GenerateRequest>,
    model: web::Data<PixelCNNInference>,
) -> HttpResponse {
    let samples = model.sample_batch_parallel(req.num_samples, 28, 28)
        .expect("Inference failed");
    let images = samples.iter()
        .map(|img| img.iter().map(|&x| (x * 255.0) as u8).collect::<Vec<_>>())
        .collect::<Vec<_>>();
    HttpResponse::Ok().json(GenerateResponse { images })
}

#[actix_web::main]
async fn main() -> std::io::Result<()> {
    let model = web::Data::new(PixelCNNInference::new("model.onnx").unwrap());
    HttpServer::new(move || {
        App::new()
            .app_data(model.clone())
            .route("/generate", web::post().to(generate))
    }).bind("127.0.0.1:8080")?.run().await
}
```

**è² è·**: 8ã‚³ã‚¢CPUã§100 req/sec (28Ã—28ç”»åƒã€batch=16)ã€‚

#### 4.15.2 gRPC Service

```rust
// proto/pixelcnn.proto
service PixelCNNService {
    rpc Generate(GenerateRequest) returns (GenerateResponse);
}

message GenerateRequest {
    int32 num_samples = 1;
    float temperature = 2;
}

message GenerateResponse {
    repeated bytes images = 1;
}
```

**gRPCå®Ÿè£…**: Tonicä½¿ç”¨ã€RESTæ¯”30%ä½ãƒ¬ã‚¤ãƒ†ãƒ³ã‚·ã€‚

### 4.16 ã‚¨ãƒ©ãƒ¼ãƒãƒ³ãƒ‰ãƒªãƒ³ã‚°

NaNæ¤œå‡ºã¨ã‚¨ãƒ©ãƒ¼å‹ã®å®šç¾©ã¯ `safe_train` é–¢æ•°ï¼ˆ4.13.1å‚ç…§ï¼‰ã§ç¤ºã—ãŸã€‚æ¨è«–å´ã§ã¯ `ort::Error` ã‚’ç‹¬è‡ªã‚¨ãƒ©ãƒ¼å‹ã«å¤‰æ›ã™ã‚‹:

```rust
pub fn sample(&self, batch_size: usize, height: usize, width: usize)
    -> Result<Array4<f32>, InferenceError> {

    let mut img = Array4::<f32>::zeros((batch_size, 1, height, width));

    for i in 0..height {
        for j in 0..width {
            let input = Value::from_array(self.session.allocator(), &img)
                .map_err(InferenceError::OrtError)?;

            let outputs = self.session.run(inputs!["input" => input])
                .map_err(InferenceError::OrtError)?;

            // ... (sampling logic)
        }
    }

    Ok(img)
}

#[derive(Debug)]
pub enum InferenceError {
    OrtError(ort::Error),
    InvalidShape,
    NanDetected,
}
```

**Resultå‹**: å…¨ã‚¨ãƒ©ãƒ¼ã‚’å‹ãƒ¬ãƒ™ãƒ«ã§è¿½è·¡ â€” Rustã®å®‰å…¨æ€§ã€‚

<details><summary>Mathâ†’Codeç¿»è¨³ã®å…¨å¯¾å¿œè¡¨</summary>

| æ¦‚å¿µ | æ•°å¼ | Rust | Rust |
|:-----|:-----|:------|:-----|
| é€£é–å¾‹ | $\prod p(x_i \mid \mathbf{x}_{<i})$ | `prod(p)` | `p.iter().product()` |
| NLL | $-\sum \log p$ | `-sum(log.(p .+ 1e-8))` | `-p.iter().map(\|x\| x.ln()).sum()` |
| Softmax | $e^{z_i}/\sum e^{z_j}$ | `softmax(z)` | `softmax(&z)` (custom) |
| Gated | $\tanh(f) \odot \sigma(g)$ | `tanh.(f) .* sigmoid.(g)` | `f.mapv(\|x\| x.tanh()) * g.mapv(\|x\| x.sigmoid())` |
| Masked Conv | $\mathbf{W} \odot \mathbf{M}$ | `W .* mask` | `w * mask` (element-wise) |
| Dilated Conv | $\sum w_k x[t-dk]$ | `conv(x, dilation=d)` | Custom kernel |

å…¨ã¦1:1å¯¾å¿œ â€” æ•°å¼ãŒãã®ã¾ã¾ã‚³ãƒ¼ãƒ‰ã«ãªã‚‹ã€‚

</details>

> **Note:** **é€²æ—: 70% å®Œäº†** PixelCNN/WaveNetã®å®Œå…¨å®Ÿè£…ã‚’Rust+Rustã§æ§‹ç¯‰ã—ãŸã€‚Masked Conv/Gating/Dilatedã®å…¨ã¦ã‚’æ•°å¼â†’ã‚³ãƒ¼ãƒ‰ã«è½ã¨ã—è¾¼ã‚“ã ã€‚ã“ã“ã‹ã‚‰å®Ÿé¨“ã‚¾ãƒ¼ãƒ³ã¸ â€” å®Ÿéš›ã«è¨“ç·´ã—ã¦æ€§èƒ½ã‚’æ¤œè¨¼ã™ã‚‹ã€‚

---

### ğŸ”¬ å®Ÿé¨“ãƒ»æ¤œè¨¼(30åˆ†)â€” å®Ÿè£…ã‚’å‹•ã‹ã—ã¦ç†è§£ã‚’æ·±ã‚ã‚‹

### 5.1 Symbol Reading Test â€” ARæ•°å¼ã‚’èª­ã‚€

<details><summary>Q1. $p(\mathbf{x}) = \prod_{i=1}^{n} p(x_i \mid \mathbf{x}_{<i})$ ã® $\mathbf{x}_{<i}$ ã¯ä½•ã‹ï¼Ÿ</summary>

**Answer**: ä½ç½® $i$ ã‚ˆã‚Š **å‰** ã®å…¨è¦ç´  $(x_1, \dots, x_{i-1})$ã€‚

**æ•°å­¦çš„å®šç¾©**: $\mathbf{x}_{<i} := (x_j)_{j < i}$

**ç›´æ„Ÿ**: è‡ªå·±å›å¸°ã§ã¯ã€Œéå»ã®å…¨ã¦ã‚’æ¡ä»¶ã«ã—ã¦æ¬¡ã‚’äºˆæ¸¬ã€ã™ã‚‹ â€” $\mathbf{x}_{<i}$ ãŒãã®ã€Œéå»ã®å…¨ã¦ã€ã‚’è¡¨ã™ã€‚

**Citation**: van den Oord+ [^1] ã®Eq.1å‚ç…§ã€‚

</details>

<details><summary>Q2. Causal Maskã®ä¸‹ä¸‰è§’è¡Œåˆ— $\mathbf{M}_{ij} = \mathbb{1}[i \geq j]$ ã¯ãªãœå¿…è¦ã‹ï¼Ÿ</summary>

**Answer**: ä½ç½® $i$ ãŒä½ç½® $j > i$(æœªæ¥)ã‚’å‚ç…§ã™ã‚‹ã“ã¨ã‚’ **é˜²ã** ãŸã‚ã€‚

**æ•°å­¦çš„æ„å‘³**: Attentionè¡Œåˆ— $\mathbf{A} = \text{softmax}(\mathbf{QK}^\top / \sqrt{d_k}) \odot \mathbf{M}$ ã¨ã™ã‚‹ã¨ã€$\mathbf{A}_{ij} = 0 \, (j > i)$ ãŒä¿è¨¼ã•ã‚Œã‚‹ã€‚

**å®Ÿè£…**: `mask = tril(ones(n, n))` ã§ä¸‹ä¸‰è§’è¡Œåˆ—ã‚’ä½œæˆã€‚

**Transformer AR**: GPTãªã©å…¨ã¦ã®Decoder-onlyãƒ¢ãƒ‡ãƒ«ãŒã“ã®ãƒã‚¹ã‚¯ã‚’ä½¿ç”¨ã€‚

</details>

<details><summary>Q3. WaveNetã®Dilated Conv $d=2^k$ ã®å—å®¹é‡ãŒ $2^L$ ã«ãªã‚‹ç†ç”±ã¯ï¼Ÿ</summary>

**Answer**: å„å±¤ã§å—å®¹é‡ãŒ $2 \times$ dilationåˆ†æ‹¡å¤§ã™ã‚‹ãŸã‚ã€‚

**æ•°å­¦çš„å°å‡º**:
- Layer 1 ($d=1$): receptive field = $1 + (K-1) \cdot 1 = K$ (kernel size $K$)
- Layer 2 ($d=2$): receptive field = $K + (K-1) \cdot 2 = 3K - 2$
- Layer $L$ ($d=2^{L-1}$): receptive field = $\sum_{k=0}^{L-1} (K-1) \cdot 2^k + 1 = (K-1)(2^L - 1) + 1 \approx K \cdot 2^L$

Kernel size $K=2$ ã®å ´åˆ: $2^L$

**Citation**: van den Oord+ [^2] Figure 3å‚ç…§ã€‚

</details>

<details><summary>Q4. PixelCNN++ã®Discretized Logistic Mixtureã®ã€Œé›¢æ•£åŒ–ã€ã¯ä½•ã‚’æ„å‘³ã™ã‚‹ã‹ï¼Ÿ</summary>

**Answer**: é€£ç¶šåˆ†å¸ƒ(Logistic)ã‚’é›¢æ•£å€¤(0-255)ã®ç¢ºç‡ã«å¤‰æ›ã™ã‚‹ã“ã¨ã€‚

**æ•°å­¦çš„å®šç¾©**:

$$
P(x = k) = \sigma\left(\frac{k+0.5-\mu}{s}\right) - \sigma\left(\frac{k-0.5-\mu}{s}\right)
$$

ã“ã“ã§ $\sigma(x) = 1/(1+e^{-x})$ ã¯ãƒ­ã‚¸ã‚¹ãƒ†ã‚£ãƒƒã‚¯é–¢æ•°ã€‚

**ç›´æ„Ÿ**: ãƒ”ã‚¯ã‚»ãƒ«å€¤ $k$ ã®ç¢ºç‡ = Logistic CDFã§ $[k-0.5, k+0.5]$ ã®åŒºé–“ç©åˆ†ã€‚

**åŠ¹æœ**: 256-wayã‚½ãƒ•ãƒˆãƒãƒƒã‚¯ã‚¹ã‹ã‚‰ $3K$ ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã¸å‰Šæ¸›(K=æ··åˆæ•°) â†’ è¨“ç·´é«˜é€ŸåŒ–ã€‚

**Citation**: Salimans+ [^5] Eq.2å‚ç…§ã€‚

</details>

<details><summary>Q5. ARãƒ¢ãƒ‡ãƒ«ã®Bits-per-dimension (bpd)ã¯ä½•ã‚’æ¸¬ã‚‹ã‹ï¼Ÿ</summary>

**Answer**: ãƒ‡ãƒ¼ã‚¿1æ¬¡å…ƒã‚ãŸã‚Šã®å¹³å‡æƒ…å ±é‡(ãƒ“ãƒƒãƒˆå˜ä½)ã€‚

**å®šç¾©**:

$$
\text{bpd} = -\frac{1}{D \log 2} \log p(\mathbf{x})
$$

ã“ã“ã§ $D$ ã¯ãƒ‡ãƒ¼ã‚¿æ¬¡å…ƒ(ç”»åƒãªã‚‰ $H \times W \times C$)ã€‚

**ç›´æ„Ÿ**: å®Œå…¨åœ§ç¸®æ™‚ã®ãƒ•ã‚¡ã‚¤ãƒ«ã‚µã‚¤ã‚º/æ¬¡å…ƒã€‚ä½ã„ã»ã©è‰¯ã„ã€‚

**ä¾‹**: CIFAR-10 (32Ã—32Ã—3 = 3072æ¬¡å…ƒ)ã§bpd=3.0 â†’ 1ãƒ”ã‚¯ã‚»ãƒ«ã‚ãŸã‚Š3ãƒ“ãƒƒãƒˆ â†’ å…¨ä½“ã§ç´„1.1KBã€‚

**Citation**: PixelCNN++ [^5] ã§CIFAR-10 bpd 2.92ã‚’é”æˆã€‚

</details>

### 5.2 LaTeX Writing Test

<details><summary>Q1. é€£é–å¾‹ã‚’LaTeXã§æ›¸ã‘</summary>

```latex
p(\mathbf{x}) = \prod_{i=1}^{n} p(x_i \mid x_1, \dots, x_{i-1}) = \prod_{i=1}^{n} p(x_i \mid \mathbf{x}_{<i})
```

$$
p(\mathbf{x}) = \prod_{i=1}^{n} p(x_i \mid x_1, \dots, x_{i-1}) = \prod_{i=1}^{n} p(x_i \mid \mathbf{x}_{<i})
$$

</details>

<details><summary>Q2. NLLæå¤±é–¢æ•°ã‚’LaTeXã§æ›¸ã‘</summary>

```latex
\mathcal{L}_\text{NLL}(\theta) = -\frac{1}{N} \sum_{n=1}^{N} \sum_{i=1}^{D} \log p_\theta(x_i^{(n)} \mid \mathbf{x}_{<i}^{(n)})
```

$$
\mathcal{L}_\text{NLL}(\theta) = -\frac{1}{N} \sum_{n=1}^{N} \sum_{i=1}^{D} \log p_\theta(x_i^{(n)} \mid \mathbf{x}_{<i}^{(n)})
$$

</details>

<details><summary>Q3. Gated Activationã®å¼ã‚’LaTeXã§æ›¸ã‘</summary>

```latex
\mathbf{y} = \tanh(\mathbf{W}_{f} * \mathbf{x}) \odot \sigma(\mathbf{W}_{g} * \mathbf{x})
```

$$
\mathbf{y} = \tanh(\mathbf{W}_{f} * \mathbf{x}) \odot \sigma(\mathbf{W}_{g} * \mathbf{x})
$$

</details>

### 5.3 Code Translation Test

<details><summary>Q1. é€£é–å¾‹ã«ã‚ˆã‚‹å°¤åº¦è¨ˆç®—ã‚’Rustã§å®Ÿè£…ã›ã‚ˆ</summary>

```rust
fn ar_log_likelihood(x: &[usize], conditional_probs: &[Vec<f64>]) -> f64 {
    // log p(x) = Î£_t log p(x_t | x_{<t})  â€” chain rule of probability
    // conditional_probs[t]: p(x_t | x_{<t}) for all possible values
    x.iter().zip(conditional_probs.iter())
        .map(|(&xi, probs)| (probs[xi] + 1e-10).ln())  // log p(x_t | x_{<t})
        .sum()                                           // Î£_t
}

fn main() {
    let x = [1usize, 4, 0];  // 0-indexed (Rust, C-style)
    let probs: Vec<Vec<f64>> = vec![
        vec![0.1, 0.7, 0.2],                          // p(x_1)
        vec![0.05, 0.1, 0.05, 0.05, 0.7, 0.05],       // p(x_2 | x_1=2)
        vec![0.8, 0.1, 0.1],                           // p(x_3 | x_1=2, x_2=5)
    ];
    println!("{:.4}", ar_log_likelihood(&x, &probs));  // â‰ˆ -0.5108
}
```

</details>

<details><summary>Q2. Causal Maskã‚’ç”Ÿæˆã™ã‚‹Rusté–¢æ•°ã‚’æ›¸ã‘</summary>

```rust
fn causal_mask(n: usize) -> Vec<Vec<bool>> {
    // M_{ij} = ğŸ™[j â‰¤ i]  â€” lower-triangular causal mask
    (0..n).map(|i| (0..n).map(|j| j <= i).collect::<Vec<_>>()).collect::<Vec<_>>()
}

fn main() {
    let mask = causal_mask(5);
    for row in &mask {
        let row_str: Vec<&str> = row.iter().map(|&b| if b { "1" } else { "0" }).collect();
        println!("{}", row_str.join("  "));
    }
    // Output:
    // 1  0  0  0  0
    // 1  1  0  0  0
    // 1  1  1  0  0
    // 1  1  1  1  0
    // 1  1  1  1  1
}
```

</details>

<details><summary>Q3. Softmaxã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°ã‚’ã‚³ãƒ¼ãƒ‰ã§å®Ÿè£…ã›ã‚ˆ</summary>

```rust
fn sample_categorical(probs: &[f64]) -> usize {
    // k ~ Categorical(p): inverse CDF â€” k = min{j : Î£_{iâ‰¤j} p_i > u},  u ~ Uniform[0,1]
    let u: f64 = rand::random();
    let mut cum = 0.0;
    probs.iter().position(|&p| { cum += p; cum > u }).unwrap_or(probs.len() - 1)
}

fn main() {
    let probs = [0.1f64, 0.6, 0.2, 0.1];
    let samples: Vec<usize> = (0..1000).map(|_| sample_categorical(&probs)).collect();
    let freqs: Vec<f64> = (0..4).map(|i| samples.iter().filter(|&&s| s == i).count() as f64 / 1000.0).collect();
    println!("Empirical frequencies: {:?}", freqs);
    // Output: â‰ˆ [0.097, 0.602, 0.203, 0.098] â‰ˆ probs
}
```

</details>

### 5.4 Paper Reading Test â€” PixelCNN Pass 1

è«–æ–‡: van den Oord+ (2016), "Conditional Image Generation with PixelCNN Decoders" [^1]

<details><summary>Pass 1 Template (5åˆ†ã§åŸ‹ã‚ã‚‹)</summary>

**Core Contribution** (1 sentence):
Gated PixelCNN with vertical/horizontal stacks eliminates blind spot and achieves log-likelihood matching PixelRNN at lower cost.

**Method Category**:
- [ ] VAEç³»
- [ ] GANç³»
- [x] ARç³»
- [ ] Diffusionç³»

**Key Innovation** (3 bullet points):
- Vertical + Horizontal masked conv stacks â†’ blind spotè§£æ¶ˆ
- Gated activation $\tanh(f) \odot \sigma(g)$ â†’ è¡¨ç¾åŠ›å‘ä¸Š
- Conditional generation on class/latent â†’ ImageNetå¤šæ§˜æ€§

**Results Summary**:
ImageNet 32Ã—32: NLL 3.83 bits/dim (PixelRNNä¸¦, é€Ÿåº¦10x)
ImageNet 64Ã—64: Class-conditionalç”ŸæˆæˆåŠŸ

**My Question**:
Why does gating improve likelihood? (Ablation: Table 1 â€” gated vs non-gated)

</details>

### 5.5 Implementation Challenge â€” Tiny PixelCNN on MNIST

**ç›®æ¨™**: MNIST 28Ã—28ã‚°ãƒ¬ãƒ¼ã‚¹ã‚±ãƒ¼ãƒ«ç”»åƒã§PixelCNNã‚’è¨“ç·´ã—ã€NLLã¨ã‚µãƒ³ãƒ—ãƒ«å“è³ªã‚’è©•ä¾¡ã™ã‚‹ã€‚

**ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿äºˆç®—**: ~300K params â†’ CPU 5åˆ†ã§åæŸ

```rust
use ndarray::{Array4, s};

fn main() {
    // Tiny PixelCNN: 4 layers, 32 channels, 256 classes (~300K params)
    let num_samples = 16usize;
    let mut img = Array4::<f32>::zeros((num_samples, 1, 28, 28));

    // AR sampling: p(x) = Î _{i,j} p(x_{i,j} | x_{<(i,j)})
    for i in 0..28usize {
        for j in 0..28usize {
            // logits = model.forward(&img);  // (batch, 256, 28, 28)
            // let probs_ij = softmax(logits.slice(s![.., .., i, j]));
            // img.slice_mut(s![.., 0, i, j]).assign(&sample_categorical(&probs_ij));
            let _ = img.slice(s![.., .., i, j]);  // placeholder
        }
    }
    println!("Generated {} MNIST-like samples, shape: {:?}", num_samples, img.dim());
    // Visualize with image crate...
}
```

**æœŸå¾…çµæœ**:
- Training NLL: ~2.5 bits/dim (5 epochs)
- Samples: MNISTé¢¨ã®æ•°å­—(å®Œå…¨ã«ã‚¯ãƒªã‚¢ã§ã¯ãªã„ãŒã€æ•°å­—ã¨èªè­˜å¯èƒ½)

**Ablation**:
- [ ] Gating ON/OFF â†’ NLLå·® ~0.3 bpd
- [ ] Layers 4 vs 8 â†’ æ·±ã„ã»ã©è‰¯ã„ãŒåæŸé…ã„
- [ ] Masked type A vs B â†’ BãŒé«˜é€Ÿ

### 5.6 WaveNetéŸ³å£°ç”Ÿæˆå®Ÿé¨“

#### 5.6.1 Tiny WaveNet on Synthetic Audio

**ç›®æ¨™**: å˜ç´”ãªæ­£å¼¦æ³¢ã‚·ãƒ¼ã‚±ãƒ³ã‚¹ã§WaveNetã®å‹•ä½œã‚’ç¢ºèªã™ã‚‹ã€‚

```rust
use std::f32::consts::PI;
use ndarray::{Array3, Array1, Array2};

// Generate sine wave + Î¼-law quantize to [0, 255]
fn generate_sine_sequence(length: usize, freq: f32) -> Vec<u8> {
    (0..length).map(|i| {
        let t = i as f32 / length as f32 * 2.0 * PI;
        let sample = (freq * t).sin() * 0.9;
        // Î¼-law encode: compress dynamic range, quantize to 256 levels
        let mu = 255.0f32;
        let enc = sample.signum() * (1.0 + mu * sample.abs()).ln() / (1.0 + mu).ln();
        ((enc + 1.0) / 2.0 * mu).round().clamp(0.0, 255.0) as u8
    }).collect()
}

// Tiny WaveNet (3 dilated blocks: dilation = 1, 2, 4)
struct TinyWaveNet {
    blocks: Vec<WaveNetBlock>,
    w_out:  Array2<f32>,  // (num_classes, channels) output 1Ã—1
    b_out:  Array1<f32>,
}

impl TinyWaveNet {
    fn forward(&self, x: &Array3<f32>) -> Array3<f32> {
        let mut h = x.clone();
        let mut skip_acc: Option<Array3<f32>> = None;
        for block in &self.blocks {
            let (res, skip) = block.forward(&h);
            h = res;
            skip_acc = Some(match skip_acc { Some(s) => s + skip, None => skip });
        }
        let s = skip_acc.unwrap_or(h);
        let (batch, ch, t) = s.dim();
        let flat = s.into_shape((batch * t, ch)).unwrap();
        (flat.dot(&self.w_out.t()) + &self.b_out)
            .into_shape((batch, self.b_out.len(), t)).unwrap()
    }
}

// p(x_t | x_{t-L:t-1}) â€” autoregressive sampling with sliding context window
fn wavenet_sample(model: &TinyWaveNet, length: usize, temperature: f32) -> Vec<f32> {
    let ctx = 10usize;
    let mut context: Vec<f32> = vec![128.0; ctx];  // silence (Î¼-law â‰ˆ 0)
    let mut generated = Vec::with_capacity(length);
    for _ in 0..length {
        let x = Array3::from_shape_vec((1, 1, ctx), context.clone()).unwrap();
        let logits = model.forward(&x);  // (1, 256, ctx)
        let last: Vec<f32> = (0..256).map(|k| logits[[0, k, ctx - 1]] / temperature).collect();
        let probs = softmax_vec(&last);
        let next = sample_categorical(&probs) as f32;
        generated.push(next);
        context.push(next);
        context.remove(0);
    }
    generated.iter().map(|&v| v / 255.0 * 2.0 - 1.0).collect()  // dequantize
}
```

**æœŸå¾…çµæœ**:
- è¨“ç·´å¾Œã€WaveNetãŒæ­£å¼¦æ³¢ãƒ‘ã‚¿ãƒ¼ãƒ³ã‚’å­¦ç¿’
- ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°ã§æ»‘ã‚‰ã‹ãªæ³¢å½¢ãŒç”Ÿæˆã•ã‚Œã‚‹(ãƒã‚¤ã‚ºè¾¼ã¿)

#### 5.6.2 Real WaveNet â€” LibriSpeechå®Ÿé¨“

**ãƒ‡ãƒ¼ã‚¿**: LibriSpeechéŸ³å£°ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆ(16kHz)

**å‰å‡¦ç†**:
```rust
use hound::{WavReader, SampleFormat};

// Load audio file and Î¼-law encode
fn load_and_encode(path: &str) -> hound::Result<Vec<u8>> {
    let mut reader = WavReader::open(path)?;
    let spec = reader.spec();
    assert_eq!(spec.sample_rate, 16000, "Expected 16kHz");

    // Read mono f32 samples
    let samples: Vec<f32> = reader.samples::<i16>()
        .map(|s| s.map(|v| v as f32 / i16::MAX as f32))
        .collect::<hound::Result<_>>()?;

    // Î¼-law encode â†’ quantize to [0, 255]
    Ok(samples.iter().map(|&x| mulaw_encode(x)).collect())
}

fn mulaw_encode(x: f32) -> u8 {
    let mu = 255.0f32;
    let sign = x.signum();
    let encoded = sign * (1.0 + mu * x.abs()).ln() / (1.0 + mu).ln();
    ((encoded + 1.0) / 2.0 * mu).round().clamp(0.0, 255.0) as u8
}
```

**è¨“ç·´è¨­å®š**:
- Layers: 30 (dilation 1,2,4,8,...,512, repeat 3x)
- Receptive field: 1024 samples = 64ms
- Batch size: 8
- Learning rate: 1e-4
- Epochs: 100 (GPU 12æ™‚é–“)

**çµæœ**:
- NLL: ~3.5 bits/sample (åæŸ)
- ç”ŸæˆéŸ³å£°: æ˜ç­ãªç™ºè©±(ãŸã ã—å˜èª¿ â€” æ¡ä»¶ä»˜ã‘ãªã—)
- MOS(ä¸»è¦³è©•ä¾¡): 3.2 / 5.0 (WaveNet 2016è«–æ–‡ã¯4.2)

**åˆ¶é™**:
- è¨ˆç®—ã‚³ã‚¹ãƒˆå¤§: 1ç§’ã®éŸ³å£°ç”Ÿæˆã«10ç§’(2016å¹´å½“æ™‚)
- ç¾åœ¨ã¯ **Parallel WaveNet** ã‚„ **WaveGlow** ã§é«˜é€ŸåŒ–

### 5.7 PixelCNN vs Diffusion â€” åŒä¸€ãƒ‡ãƒ¼ã‚¿ã§ã®æ¯”è¼ƒ

#### 5.7.1 CIFAR-10 Benchmark

| ãƒ¢ãƒ‡ãƒ« | FIDâ†“ | ISâ†‘ | NLL (bits/dim)â†“ | ç”Ÿæˆæ™‚é–“ |
|:-------|:-----|:----|:----------------|:---------|
| PixelCNN++ | N/A | N/A | 2.92 | é… |
| DDPM | 3.17 | 9.46 | N/A | ä¸­ |
| VAR-d16 | **2.09** | **302.6** | è¨ˆç®—å¯ | é€Ÿ |

VAR [^3] ãŒå…¨æŒ‡æ¨™ã§PixelCNN++/DDPMã‚’åœ§å€’ â€” 2024å¹´ã®å‹åˆ©ã€‚

#### 5.7.2 ImageNet 256Ã—256 Benchmark

| ãƒ¢ãƒ‡ãƒ« | FIDâ†“ | Inception Scoreâ†‘ | Params | å¹´ |
|:-------|:-----|:-----------------|:-------|:---|
| BigGAN | 6.95 | 198.2 | 112M | 2018 |
| VQ-VAE-2 | 31.11 | ~150 | ~13B tokens | 2019 |
| DiT-XL/2 | 2.27 | 278.2 | 675M | 2023 |
| **VAR-d30** | **1.73** | **350.2** | 2B | 2024 |
| **Infinity-H** | **<1.7** | N/A | 1.9B | 2025 |

**ARå®Œå…¨å‹åˆ©** â€” FID 1.73ã¯Diffusion(2.27)ã‚’å¤§å¹…ã«è¶…ãˆã‚‹ã€‚

### 5.8 Ablation Study â€” å„ã‚³ãƒ³ãƒãƒ¼ãƒãƒ³ãƒˆã®å¯„ä¸

#### PixelCNN Ablation (van den Oord+ 2016)

| è¨­å®š | NLL (bits/dim) | æ”¹å–„ |
|:-----|:---------------|:-----|
| Baseline (no gating) | 3.14 | - |
| + Gated activation | 3.03 | -0.11 |
| + Vertical/Horizontal stack | 2.95 | -0.08 |
| + Conditioning | **2.92** | -0.03 |

**GatingãŒæœ€å¤§ã®è²¢çŒ®** â€” è¡¨ç¾åŠ›ãŒåŠ‡çš„ã«å‘ä¸Šã€‚

#### WaveNet Ablation (van den Oord+ 2016)

| è¨­å®š | MOS(ä¸»è¦³è©•ä¾¡) | æ”¹å–„ |
|:-----|:--------------|:-----|
| LSTM baseline | 2.8 | - |
| WaveNet (no dilation) | 3.5 | +0.7 |
| WaveNet (dilated) | 4.0 | +0.5 |
| WaveNet (dilated + residual) | **4.2** | +0.2 |

**DilationãŒæœ¬è³ª** â€” å—å®¹é‡æ‹¡å¤§ãŒéŸ³è³ªã‚’æ±ºå®šçš„ã«æ”¹å–„ã€‚

#### VAR Ablation (Tian+ 2024)

| è¨­å®š | FID | æ”¹å–„ |
|:-----|:----|:-----|
| Raster order (PixelCNN-like) | 18.65 | - |
| Random order (MAR-like) | 3.56 | -15.09 |
| **Multi-scale (VAR)** | **1.73** | **-1.83** |

**é †åºãŒå…¨ã¦** â€” Multi-scaleãŒæ±ºå®šçš„å„ªä½ã€‚

### 5.9 ç”Ÿæˆå“è³ªã®å¯è¦–åŒ–

#### PixelCNNç”Ÿæˆã‚µãƒ³ãƒ—ãƒ« (MNIST)

```rust
use image::{GrayImage, Luma, imageops};

// Arrange num_samples grayscale images into a 4Ã—4 grid and save
fn save_sample_grid(samples: &[Vec<u8>], h: u32, w: u32, path: &str) {
    let cols = 4u32;
    let rows = (samples.len() as u32 + cols - 1) / cols;
    let mut grid = GrayImage::new(cols * w, rows * h);

    for (idx, sample) in samples.iter().enumerate() {
        let img = GrayImage::from_raw(w, h, sample.clone()).unwrap();
        let col = (idx as u32) % cols;
        let row = (idx as u32) / cols;
        imageops::replace(&mut grid, &img, (col * w) as i64, (row * h) as i64);
    }
    grid.save(path).unwrap();
    println!("Saved sample grid to {}", path);
}
```

**æœŸå¾…å‡ºåŠ›**: MNISTé¢¨ã®æ‰‹æ›¸ãæ•°å­—(å®Œå…¨ã«ã‚¯ãƒªã‚¢ã§ã¯ãªã„ãŒã€æ•°å­—ã¨ã—ã¦èªè­˜å¯èƒ½)ã€‚

#### WaveNetç”ŸæˆéŸ³å£° (ã‚¹ãƒšã‚¯ãƒˆãƒ­ã‚°ãƒ©ãƒ )

```rust
use rustfft::{FftPlanner, num_complex::Complex};

// Short-time Fourier Transform (STFT) â†’ log-magnitude spectrogram
fn stft_log_magnitude(signal: &[f32], window: usize, hop: usize) -> Vec<Vec<f32>> {
    // STFT: X[n,k] = Î£_m x[m] w[m-nH] exp(-j2Ï€km/W);  return log|X[n,k]|
    let mut planner = FftPlanner::<f32>::new();
    let fft = planner.plan_fft_forward(window);

    signal.windows(window).step_by(hop).map(|frame| {
        // Hanning window
        let mut buf: Vec<Complex<f32>> = frame.iter().enumerate()
            .map(|(i, &x)| {
                let w = 0.5 * (1.0 - (2.0 * std::f32::consts::PI * i as f32 / (window - 1) as f32).cos());
                Complex::new(x * w, 0.0)
            })
            .collect();
        fft.process(&mut buf);
        // Log-magnitude for first half (positive frequencies)
        buf[..window / 2].iter().map(|c| (c.norm() + 1e-10).ln()).collect()
    }).collect()
}

fn main() {
    // TinyWaveNet: 3 layers (dilation 1,2,4), 32 channels, 256 classes
    println!("Generating 1 second of audio @ 16kHz with TinyWaveNet...");
    // let model = TinyWaveNet { blocks: ..., w_out: ..., b_out: ... };
    // let audio = wavenet_sample(&model, 16000, 0.8);
    let audio = vec![0.0f32; 16000];  // placeholder: replace with trained model
    let spec = stft_log_magnitude(&audio, 256, 128);
    println!("Spectrogram: {} frames Ã— {} bins", spec.len(), spec[0].len());
    // Plot with plotters crate or save as image...
}
```

**æœŸå¾…å‡ºåŠ›**: æ­£å¼¦æ³¢ã®ãƒãƒ¼ãƒ¢ãƒ‹ã‚¯ã‚¹ãŒè¦‹ãˆã‚‹(å‘¨æ³¢æ•°è»¸ã«æ¨ªç·š)ã€‚

### 5.10 å®Ÿè£…ãƒãƒ£ãƒ¬ãƒ³ã‚¸2 â€” Conditional PixelCNN

**ç›®æ¨™**: MNISTã‚¯ãƒ©ã‚¹æ¡ä»¶ä»˜ãç”Ÿæˆ â€” ã€Œ3ã‚’ç”Ÿæˆã€ã€Œ7ã‚’ç”Ÿæˆã€ã¨æŒ‡å®šå¯èƒ½ã«ã€‚

```rust
use ndarray::{Array4, Array2, Array1, s};

// Class-conditional PixelCNN: concatenate class embedding with input
struct ConditionalPixelCNN {
    embed_table: Array2<f32>,  // (num_classes, embed_dim) class embedding table
    layers:      Vec<GatedConvLayer>,
}

impl ConditionalPixelCNN {
    // Broadcast class embedding to (batch, embed_dim, H, W) and concat with x
    fn forward(&self, x: &Array4<f32>, class_ids: &[usize]) -> Array4<f32> {
        let (batch, _ch, h, w) = x.dim();
        let embed_dim = self.embed_table.ncols();
        let mut x_cond = Array4::<f32>::zeros((batch, x.dim().1 + embed_dim, h, w));
        x_cond.slice_mut(s![.., ..x.dim().1, .., ..]).assign(x);
        for (b, &cls) in class_ids.iter().enumerate() {
            let emb = self.embed_table.row(cls);
            for e in 0..embed_dim {
                x_cond.slice_mut(s![b, x.dim().1 + e, .., ..]).fill(emb[e]);
            }
        }
        // Forward through gated layers
        let (mut v, mut h_feat) = (x_cond.clone(), x_cond);
        for layer in &self.layers {
            let (nv, nh) = layer.forward(&v, &h_feat);
            v = nv; h_feat = nh;
        }
        h_feat
    }
}

// Conditional sampling: generate images of a specific class
fn sample_conditional(model: &ConditionalPixelCNN, class_id: usize, num_samples: usize)
    -> Array4<f32>
{
    let class_ids = vec![class_id; num_samples];
    let mut img = Array4::<f32>::zeros((num_samples, 1, 28, 28));
    for i in 0..28usize {
        for j in 0..28usize {
            let _logits = model.forward(&img, &class_ids);  // (batch, 256, 28, 28)
            // ... (sample pixel (i,j) from logits)
        }
    }
    img
}
```

**å®Ÿé¨“**:
- è¨“ç·´: MNISTå…¨ã‚¯ãƒ©ã‚¹(0-9)
- ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°: `sample_conditional(model, ps, st, 3, 16)` â†’ ã€Œ3ã€ãŒ16å€‹ç”Ÿæˆã•ã‚Œã‚‹

**æœŸå¾…çµæœ**: ã‚¯ãƒ©ã‚¹æ¡ä»¶ãŒãªãã¦ã‚‚ã€Œ3ã£ã½ã„ä½•ã‹ã€ãŒç”Ÿæˆã•ã‚Œã‚‹ãŒã€æ¡ä»¶ä»˜ãã§ã¯æ˜ç¢ºã«ã€Œ3ã€ãŒç”Ÿæˆã•ã‚Œã‚‹ã€‚

### 5.11 Error Analysis â€” ç”Ÿæˆå¤±æ•—ã®åˆ†æ

#### å…¸å‹çš„ãªå¤±æ•—ãƒ¢ãƒ¼ãƒ‰

**Mode 1: Posterior Collapseé¢¨ã®ç¾è±¡**
- ç—‡çŠ¶: å…¨ãƒ”ã‚¯ã‚»ãƒ«ãŒåŒã˜å€¤(e.g., å…¨éƒ¨0)
- åŸå› : ãƒ¢ãƒ‡ãƒ«ãŒã€Œå®‰å…¨ãªå¹³å‡å€¤ã€ã‚’å¸¸ã«å‡ºåŠ›
- è§£æ±º: Learning rateèª¿æ•´ / Warm-up / KL Annealingã®å°å…¥(VAEæŠ€æ³•ã®è»¢ç”¨)

**Mode 2: Checkboard Artifacts**
- ç—‡çŠ¶: å¸‚æ¾æ¨¡æ§˜ã®ãƒã‚¤ã‚º
- åŸå› : Masked Convã®å—å®¹é‡ä¸è¶³ / Blind Spotæ®‹å­˜
- è§£æ±º: Gated PixelCNNæ§‹é€ ã®æ­£ç¢ºãªå®Ÿè£…

**Mode 3: Exposure Bias**
- ç—‡çŠ¶: è¨“ç·´æ™‚ã¯é«˜å“è³ªã€æ¨è«–æ™‚ã¯å´©å£Š
- åŸå› : Teacher Forcing(è¨“ç·´)ã¨Autoregressive(æ¨è«–)ã®ã‚®ãƒ£ãƒƒãƒ—
- è§£æ±º: Scheduled Sampling / Curriculum Learning

#### ãƒ‡ãƒãƒƒã‚°ãƒã‚§ãƒƒã‚¯ãƒªã‚¹ãƒˆ

- [ ] NLL Lossæ¸›å°‘ã—ã¦ã„ã‚‹ã‹ï¼Ÿ(è¨“ç·´/æ¤œè¨¼ä¸¡æ–¹)
- [ ] Causal MaskãŒæ­£ã—ãé©ç”¨ã•ã‚Œã¦ã„ã‚‹ã‹ï¼Ÿ(æœªæ¥ã‚’è¦‹ã¦ã„ãªã„ã‹ç¢ºèª)
- [ ] Gatingã®æ´»æ€§åŒ–é–¢æ•°ã¯æ­£ã—ã„ã‹ï¼Ÿ(tanh/sigmoidã®çµ„ã¿åˆã‚ã›)
- [ ] ç”Ÿæˆã‚µãƒ³ãƒ—ãƒ«ãŒãƒ©ãƒ³ãƒ€ãƒ ãƒã‚¤ã‚ºã§ã¯ãªã„ã‹ï¼Ÿ(å­¦ç¿’ã®è¨¼æ‹ )
- [ ] è¨“ç·´æ™‚ã¨æ¨è«–æ™‚ã§åŒã˜å‰å‡¦ç†ã‚’ã—ã¦ã„ã‚‹ã‹ï¼Ÿ(æ­£è¦åŒ–/é‡å­åŒ–)

### 5.12 Self-Check Checklist

- [ ] é€£é–å¾‹ã‚’è‡ªåˆ†ã®è¨€è‘‰ã§èª¬æ˜ã§ãã‚‹
- [ ] PixelCNN Blind Spotå•é¡Œã¨è§£æ±ºç­–ã‚’å›³ç¤ºã§ãã‚‹
- [ ] WaveNetã®Dilated Convã§å—å®¹é‡ãŒ $2^L$ ã«ãªã‚‹ç†ç”±ã‚’å°å‡ºã§ãã‚‹
- [ ] NLLæå¤±é–¢æ•°ã‚’æ•°å¼ã§æ›¸ãã€ã‚³ãƒ¼ãƒ‰ã§å®Ÿè£…ã§ãã‚‹
- [ ] Causal Maskingã®å¿…è¦æ€§ã‚’èª¬æ˜ã§ãã‚‹
- [ ] ARãƒ¢ãƒ‡ãƒ«ã¨VAE/GANã®é•ã„(å°¤åº¦è¨ˆç®—å¯å¦)ã‚’è¿°ã¹ã‚‰ã‚Œã‚‹
- [ ] Rust/Rustã§ARæ¨è«–ãƒ«ãƒ¼ãƒ—ã‚’æ›¸ã‘ã‚‹
- [ ] VAR/MARãªã©2024æœ€æ–°æ‰‹æ³•ã®è²¢çŒ®ã‚’1æ–‡ã§è¨€ãˆã‚‹
- [ ] Top-k/Top-p samplingã‚’å®Ÿè£…ã§ãã‚‹
- [ ] Conditionalç”Ÿæˆã®ä»•çµ„ã¿ã‚’èª¬æ˜ã§ãã‚‹

å…¨ã¦ãƒã‚§ãƒƒã‚¯ã§ããŸã‚‰ã€æœ¬è¬›ç¾©ã®å†…å®¹ã‚’å®Œå…¨ç¿’å¾—ã—ã¦ã„ã‚‹ã€‚

> **Note:** **é€²æ—: 85% å®Œäº†** å®Ÿé¨“ã‚¾ãƒ¼ãƒ³ã§ç†è«–â†’å®Ÿè£…â†’æ¤œè¨¼ã®ã‚µã‚¤ã‚¯ãƒ«ã‚’å›ã—ãŸã€‚Symbol/LaTeX/Codeã®3è¦–ç‚¹ã§ARã‚’å®Œå…¨ç†è§£ã—ã€Tiny PixelCNNã§å®Ÿéš›ã«è¨“ç·´ã—ãŸã€‚ã“ã“ã‹ã‚‰ç™ºå±•ã‚¾ãƒ¼ãƒ³ã¸ â€” 2024-2025æœ€æ–°ç ”ç©¶ã¨ä»Šå¾Œã®å±•æœ›ã‚’ä¿¯ç°ã™ã‚‹ã€‚

> Progress: 85%
> **ç†è§£åº¦ãƒã‚§ãƒƒã‚¯**
> 1. Masked Convolution ã® Rust å®Ÿè£…ã«ãŠã„ã¦ã€`mask_type = :A` ã¨ `mask_type = :B` ã§ãƒã‚¹ã‚¯ã®æ§‹æˆãŒã©ã†ç•°ãªã‚‹ã‹ï¼Ÿ`mask[center_h, center_w, :, :] = 0.0` ã¨ã„ã†è¡Œã¯ã©ã¡ã‚‰ã®ã‚¿ã‚¤ãƒ—ã§å®Ÿè¡Œã•ã‚Œã‚‹ã‹ï¼Ÿ
> 2. WaveNet ã® Dilated Causal Conv ã§ `dilation=4` ã®ã¨ãã€å…¥åŠ›ã®ä½•ã‚¹ãƒ†ãƒƒãƒ—å‰ã¾ã§ã€Œè¦‹ãˆã‚‹ã€ã‹ï¼Ÿ3 ãƒ–ãƒ­ãƒƒã‚¯ï¼ˆdilation 1, 2, 4ï¼‰ã‚’ç©ã¿é‡ã­ãŸå ´åˆã®ç·å—å®¹é‡ã¯ï¼Ÿ

---

## ğŸ”¬ Z6. æ–°ãŸãªå†’é™ºã¸ï¼ˆç ”ç©¶å‹•å‘ï¼‰

### 6.1 ARç³»çµ±æ¨¹ â€” PixelCNNã‹ã‚‰VAR/Infinityã¾ã§

```mermaid
graph TD
    A[è‡ªå·±å›å¸°ãƒ¢ãƒ‡ãƒ«] --> B[Pixel-level AR]
    A --> C[Token-level AR]
    A --> D[Scale-level AR]

    B --> B1["PixelCNN (2016)<br/>Masked Conv"]
    B --> B2["PixelCNN++ (2017)<br/>Logistic Mixture"]
    B --> B3["PixelSNAIL (2018)<br/>Self-Attention"]

    C --> C1["VQ-VAE-2 (2019)<br/>Discrete Tokens"]
    C --> C2["DALL-E (2021)<br/>Text-to-Image"]
    C --> C3["VQGAN (2021)<br/>Perceptual Loss"]
    C --> C4["MaskGIT (2022)<br/>Non-AR Masking"]
    C --> C5["MAR (2024)<br/>Diffusion Loss"]

    D --> D1["VAR (2024)<br/>Next-Scale Predict"]
    D --> D2["FlowAR (2024)<br/>VAR + Flow Matching"]
    D --> D3["Infinity (2025)<br/>Bitwise AR"]

    style D1 fill:#ffeb3b
    style D2 fill:#ffeb3b
    style D3 fill:#ffeb3b
```

| ãƒ¢ãƒ‡ãƒ« | å¹´ | é †åº | FID (ImageNet 256) | é€Ÿåº¦ | è«–æ–‡ |
|:-------|:---|:-----|:-------------------|:-----|:-----|
| PixelCNN | 2016 | Raster | N/A(å°è¦æ¨¡) | é… | [^1] |
| PixelCNN++ | 2017 | Raster | N/A | é… | [^5] |
| VQGAN | 2021 | Raster(latent) | ~5.2 | ä¸­ | Esser+ |
| MaskGIT | 2022 | Random(non-AR) | ~6.18 | **é€Ÿ** | [^8] |
| **VAR** | **2024** | **Multi-scale** | **1.73** | é€Ÿ | **[^3] NeurIPS Best** |
| MAR | 2024 | Random(masked) | ~1.78 | é€Ÿ | [^6] |
| FlowAR | 2024 | Multi-scale | 1.65 | é€Ÿ | [^7] |
| **Infinity** | **2025** | **Bitwise** | **<1.7** | **æœ€é€Ÿ(0.8s)** | **[^9] CVPR Oral** |

**2024å¹´ã®é©å‘½**: VAR [^3] ãŒã€ŒNext-Scale Predictionã€ã‚’å°å…¥ã—ã€FID 1.73ã§DiT(2.27)ã‚’è¶…ãˆãŸã€‚ARãŒæ‹¡æ•£ãƒ¢ãƒ‡ãƒ«ã‚’å“è³ªã§åˆã‚ã¦ä¸Šå›ã£ãŸæ­´å²çš„ç¬é–“ã€‚

**2025å¹´ã®é€²åŒ–**: Infinity [^9] ãŒã€ŒBitwise ARã€ã§0.8ç§’/ç”»åƒ(1024Ã—1024)ã‚’é”æˆ â€” SD3-Mediumã®2.6å€é€Ÿã€‚

### 6.2 VAR â€” NeurIPS 2024 Best Paperã®è¡æ’ƒ

**Visual Autoregressive modeling (VAR)** [^3]:

**æ ¸å¿ƒã‚¢ã‚¤ãƒ‡ã‚¢**: é †åºã‚’ã€Œãƒ”ã‚¯ã‚»ãƒ«å˜ä½ã€â†’ã€Œè§£åƒåº¦å˜ä½ã€ã«å¤‰æ›´ã€‚

$$
p(\mathbf{x}) = \prod_{r=1}^{R} p(\mathbf{x}_r \mid \mathbf{x}_{<r})
$$

ã“ã“ã§ $\mathbf{x}_r$ ã¯è§£åƒåº¦ $r$ ã®ãƒˆãƒ¼ã‚¯ãƒ³ãƒãƒƒãƒ—(e.g., $1 \times 1 \to 2 \times 2 \to \cdots \to 16 \times 16$)ã€‚

**å¾“æ¥(PixelCNN)**: $256 \times 256 = 65536$ ã‚¹ãƒ†ãƒƒãƒ—
**VAR**: $R \approx 10$ ã‚¹ãƒ†ãƒƒãƒ—(multi-scale) â†’ **6500å€ã®ä¸¦åˆ—åŒ–**

**æ€§èƒ½**:
- ImageNet 256Ã—256: FID **1.73** (DiT 2.27, MAR 1.78ã‚’è¶…ãˆã‚‹)
- Scaling Laws: $\text{FID} \propto N^{-0.998}$ ã®ç¶ºéº—ãªPower Law
- Zero-shot: Inpainting/Outpainting/EditingãŒè¿½åŠ è¨“ç·´ãªã—ã§å¯èƒ½

**ãªãœå‹ã£ãŸã‹**:
1. **Order Matters**: ç²—â†’ç´°ã®é †åºãŒç”»åƒã®è‡ªç„¶ãªéšå±¤æ§‹é€ ã¨ä¸€è‡´
2. **Parallelism**: åŒä¸€è§£åƒåº¦å†…ã¯ä¸¦åˆ—ç”Ÿæˆå¯èƒ½(Raster Scanã‚ˆã‚Šé¥ã‹ã«é€Ÿã„)
3. **Scalability**: ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿æ•° $N$ ã«å¯¾ã—ã¦ç¶ºéº—ã«ã‚¹ã‚±ãƒ¼ãƒ«(GPT-likeãªæŒ™å‹•)

### 6.3 MAR â€” Vector Quantizationãªã—ã®è‡ªå·±å›å¸°

**Masked Autoregressive (MAR)** [^6]:

**æ ¸å¿ƒã‚¢ã‚¤ãƒ‡ã‚¢**: VQä¸è¦ â€” é€£ç¶šå€¤ã‚’ **Diffusion Loss** ã§ãƒ¢ãƒ‡ãƒ«åŒ–ã€‚

$$
p_\theta(x_i \mid \mathbf{x}_{<i}) = \int p_\theta(x_i \mid z_i) q(z_i \mid x_i, \mathbf{x}_{<i}) dz_i
$$

ã“ã“ã§ $q(z_i \mid x_i, \mathbf{x}_{<i})$ ã¯æ‹¡æ•£éç¨‹ã€‚

**åŠ¹æœ**:
- VQã®é›¢æ•£åŒ–èª¤å·®ã‚’å›é¿
- Codebook Collapseãªã—
- FID 1.78 (VARä¸¦)

**Random Order AR**: Masked tokenä½ç½®ã‚’ãƒ©ãƒ³ãƒ€ãƒ ã«é¸ã³ã€ä¸¦åˆ—äºˆæ¸¬ã€‚

### 6.4 FlowAR â€” VARã¨Flow Matchingã®èåˆ

**FlowAR** [^7]:

**æ ¸å¿ƒã‚¢ã‚¤ãƒ‡ã‚¢**: VAR(multi-scale) + Flow Matching(é€£ç¶šæ™‚é–“æ‹¡æ•£)ã€‚

$$
p(\mathbf{x}_r \mid \mathbf{x}_{<r}) = \text{ODE solve from noise to data}
$$

**æ€§èƒ½**: FID **1.65** (VAR-Hã®1.73ã‚’è¶…ãˆã‚‹)

**æ„ç¾©**: ARã¨æ‹¡æ•£ã®å¢ƒç•ŒãŒæ›–æ˜§ã« â€” æ¬¡ä¸–ä»£ã¯ã€ŒHybridã€ã¸ã€‚

### 6.5 Infinity â€” Bitwise ARã®æ¥µè‡´

**Infinity** [^9] (CVPR 2025 Oral):

**æ ¸å¿ƒã‚¢ã‚¤ãƒ‡ã‚¢**: ãƒˆãƒ¼ã‚¯ãƒ³å˜ä½ã§ã¯ãªã **ãƒ“ãƒƒãƒˆå˜ä½** ã§äºˆæ¸¬ã€‚

$$
p(\mathbf{x}) = \prod_{b=1}^{B} p(\text{bit}_b \mid \text{bit}_{<b})
$$

**èªå½™ã‚µã‚¤ã‚º**: $2^B \to \infty$ (ç†è«–ä¸Šç„¡é™)

**æ€§èƒ½**:
- GenEval: 0.73 (SD3-Medium 0.62ã‚’è¶…ãˆã‚‹)
- é€Ÿåº¦: **0.8ç§’/ç”»åƒ(1024Ã—1024)** â€” SD3ã®2.6å€é€Ÿ
- Text-to-Image: SD3/SDXLã‚’è¶…ãˆã‚‹å“è³ª

**é©å‘½**: ARãŒæ‹¡æ•£ã‚’å“è³ªãƒ»é€Ÿåº¦ã®ä¸¡é¢ã§å®Œå…¨ã«è¶…ãˆãŸã€‚ã€ŒARã¯é…ã„ã€ã¨ã„ã†å¸¸è­˜ãŒå´©å£Šã€‚

### 6.6 MaskGIT â€” Non-ARã®äºˆå‘Š

**MaskGIT** [^8]:

**æ ¸å¿ƒã‚¢ã‚¤ãƒ‡ã‚¢**: ARã‚’ã€ŒMasked tokenäºˆæ¸¬ã€ã«æ‹¡å¼µ â†’ ä¸¦åˆ—ç”Ÿæˆã€‚

è¨“ç·´:
$$
\mathcal{L} = -\mathbb{E}_{\mathbf{x}, \mathbf{m}} \left[ \sum_{i \in \mathbf{m}} \log p_\theta(x_i \mid \mathbf{x}_{\neg \mathbf{m}}) \right]
$$

ã“ã“ã§ $\mathbf{m}$ ã¯ãƒ©ãƒ³ãƒ€ãƒ ãƒã‚¹ã‚¯ã€$\mathbf{x}_{\neg \mathbf{m}}$ ã¯éãƒã‚¹ã‚¯é ˜åŸŸã€‚

æ¨è«–: Iterative decoding â€” å„ã‚¹ãƒ†ãƒƒãƒ—ã§å…¨ãƒˆãƒ¼ã‚¯ãƒ³ã‚’äºˆæ¸¬ã—ã€confidenceã®é«˜ã„ã‚‚ã®ã®ã¿æ¡ç”¨ã€‚

**æ€§èƒ½**: ImageNet 256Ã—256ã§8å›ã®åå¾©(ARã®256å€é€Ÿ)ã€å“è³ªã¯ARä¸¦ã€‚

**æ„ç¾©**: ã€ŒARã¯é€æ¬¡çš„ã€ã¨ã„ã†åˆ¶ç´„ã‚’ç·©å’Œ â€” ç¬¬14å›Attentionã§è©³è¿°ã€‚

### 6.7 AR Vision Survey (TMLR 2025)

**Autoregressive Models in Vision: A Survey** [^4]:

2025å¹´ã®ã‚µãƒ¼ãƒ™ã‚¤ [^4] ãŒä»¥ä¸‹ã‚’åˆ†é¡:

| Level | ä»£è¡¨ãƒ¢ãƒ‡ãƒ« | ç‰¹å¾´ |
|:------|:-----------|:-----|
| Pixel-level | PixelCNNç³» | é…ã„ãŒç†è«–çš„ã«å³å¯† |
| Token-level | VQGAN/DALL-E | VQé›¢æ•£åŒ–ã€ä¸­é€Ÿ |
| Scale-level | VAR/FlowAR | ç²—â†’ç´°ã€é«˜é€Ÿ+é«˜å“è³ª |
| Bit-level | Infinity | èªå½™âˆã€æœ€é€Ÿ |

**å‹•å‘**: Tokenâ†’Scaleâ†’Bitã¸ã®é€²åŒ– = ä¸¦åˆ—åŒ–ã®æ¥µé™è¿½æ±‚ã€‚


## ğŸ­ Z7. ã‚¨ãƒ”ãƒ­ãƒ¼ã‚°ï¼ˆã¾ã¨ã‚ãƒ»FAQãƒ»æ¬¡å›äºˆå‘Šï¼‰

### 6.8 æ¬¡å›äºˆå‘Š â€” ç¬¬14å›: Attention

**ç¬¬14å›ã®ãƒ†ãƒ¼ãƒ**: RNN/CNNã®é™ç•Œ â†’ Attentionã®å¿…ç„¶æ€§ â†’ Transformer â†’ GPT/BERT

**æ¥ç¶š**:
- ç¬¬13å›(ä»Šå›): ARã¯ã€Œæ¡ä»¶ä»˜ãåˆ†è§£ã§å°¤åº¦ã‚’è¨ˆç®—ã€
- ç¬¬14å›: Attention = ARã®å—å®¹é‡ã‚’ $O(N^2)$ ã§å…¨ç³»åˆ—ã«æ‹¡å¤§

**ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰**:
- Self-Attention / Multi-Head Attention
- Positional Encoding (RoPE/ALiBi)
- Causal Attention = AR Transformer
- Scaling Laws / Emergent Abilities
- In-Context Learning / KV-Cache

**äºˆç¿’**: ç¬¬1-3å›ã®AttentionåŸºç¤(QKV/Softmax)ã‚’å¾©ç¿’ã—ã¦ãŠãã¨ç†è§£ãŒåŠ é€Ÿã™ã‚‹ã€‚

**ãƒ¢ãƒãƒ™ãƒ¼ã‚·ãƒ§ãƒ³**:
PixelCNNã®å—å®¹é‡ã¯æœ‰é™(CNNåˆ¶ç´„)ã€WaveNetã‚‚ $2^L$ ã¾ã§ã€‚å…¨ç³»åˆ—ã‚’ä¸€åº¦ã«å‚ç…§ã™ã‚‹ã«ã¯ **Self-Attention** ãŒå¿…è¦ã ã£ãŸã€‚ã“ã‚ŒãŒ2017å¹´ "Attention is All You Need" (Vaswani+)ã®é©å‘½ã ã£ãŸã€‚

ç¬¬14å›ã§Attentionã®æ•°å­¦ã¨Transformerã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£ã‚’å®Œå…¨åˆ¶è¦‡ã—ã€ç¬¬15å›ã§Flash Attention/MoE/Sparse Attentionãªã©åŠ¹ç‡åŒ–æ‰‹æ³•ã€ç¬¬16å›ã§Mamba(SSM)ã¨ã„ã†ã€ŒAttentionã®ä»£æ›¿ã€ã‚’å­¦ã¶ã€‚

Course IIã®ã‚¯ãƒ©ã‚¤ãƒãƒƒã‚¯ã‚¹ã¸ â€” ã€ŒåŒ–çŸ³(RNN/CNN)ã‹ã‚‰ã®è„±å´ã€ã®ç‰©èªãŒå®Œçµã™ã‚‹ã€‚

> **Note:** **é€²æ—: 100% å®Œäº†** ğŸ‰
>
> æœ¬è¬›ç¾©ã€Œç¬¬13å›: è‡ªå·±å›å¸°ãƒ¢ãƒ‡ãƒ«ã€ã‚’å®Œå…¨åˆ¶è¦‡ã—ãŸã€‚é€£é–å¾‹ã®å³å¯†ãªè¨¼æ˜ã‹ã‚‰ã€PixelCNN/WaveNetã®å®Ÿè£…ã€2024-2025æœ€æ–°ç ”ç©¶(VAR/MAR/FlowAR/Infinity)ã¾ã§ã€ARã®å…¨ã¦ã‚’ç¶²ç¾…ã—ãŸã€‚
>
> **é”æˆäº‹é …**:
> - é€£é–å¾‹ $p(\mathbf{x}) = \prod p(x_i \mid \mathbf{x}_{<i})$ ã®è¨¼æ˜
> - PixelCNN Gatedæ§‹é€  + Blind Spotè§£æ±º
> - WaveNet Dilated Conv + å—å®¹é‡ $2^L$ å°å‡º
> - Rust/Rustå®Ÿè£…(è¨“ç·´+æ¨è«–)
> - VAR(NeurIPS Best)ã‹ã‚‰Infinity(CVPR Oral)ã¾ã§æœ€æ–°ç ”ç©¶ä¿¯ç°
>
> **æ¬¡ã®ã‚¹ãƒ†ãƒƒãƒ—**: ç¬¬14å› Attention ã§ã€ŒARã®å—å®¹é‡ã‚’å…¨ç³»åˆ—ã«æ‹¡å¤§ã€ã™ã‚‹é©å‘½ã‚’å­¦ã¶ã€‚

---

> Progress: 95%
> **ç†è§£åº¦ãƒã‚§ãƒƒã‚¯**
> 1. VARï¼ˆVisual AutoRegressive modelingï¼‰ãŒå¾“æ¥ã®ãƒ©ã‚¹ã‚¿ã‚¹ã‚­ãƒ£ãƒ³é † AR ã¨ç•°ãªã‚‹ç‚¹ã¯ä½•ã‹ï¼Ÿã€Œã‚¹ã‚±ãƒ¼ãƒ«ã”ã¨ã® next-token predictionã€ã®æ„å‘³ã‚’ã€ãƒˆãƒ¼ã‚¯ãƒ³ãƒãƒƒãƒ—ã®è§£åƒåº¦ã¨çµã³ã¤ã‘ã¦èª¬æ˜ã›ã‚ˆã€‚
> 2. AR ãƒ¢ãƒ‡ãƒ«ã®æ¨è«–ã‚’é«˜é€ŸåŒ–ã™ã‚‹ Parallel WaveNetï¼ˆç¢ºç‡çš„ç”Ÿæˆè’¸ç•™ï¼‰ã«ãŠã„ã¦ã€æ•™å¸«ãƒ¢ãƒ‡ãƒ«ã¨ç”Ÿå¾’ãƒ¢ãƒ‡ãƒ«ã®å½¹å‰²ã¯ã©ã®ã‚ˆã†ã«ç•°ãªã‚‹ã‹ï¼Ÿè¨“ç·´æ™‚ã¨æ¨è«–æ™‚ã®é•ã„ã‚’ç­”ãˆã‚ˆã€‚

---

## å‚è€ƒæ–‡çŒ®

### ä¸»è¦è«–æ–‡

[^1]: van den Oord, A., Kalchbrenner, N., Vinyals, O., Espeholt, L., Graves, A., & Kavukcuoglu, K. (2016). Conditional Image Generation with PixelCNN Decoders. *NeurIPS 2016*.
<https://arxiv.org/abs/1606.05328>

[^2]: van den Oord, A., Dieleman, S., Zen, H., Simonyan, K., Vinyals, O., Graves, A., Kalchbrenner, N., Senior, A., & Kavukcuoglu, K. (2016). WaveNet: A Generative Model for Raw Audio. *arXiv:1609.03499*.
<https://arxiv.org/abs/1609.03499>

[^3]: Tian, K., Jiang, Y., Yuan, Z., Peng, B., & Wang, L. (2024). Visual Autoregressive Modeling: Scalable Image Generation via Next-Scale Prediction. *NeurIPS 2024 (Best Paper Award)*.
<https://arxiv.org/abs/2404.02905>

[^4]: Xiong, J., et al. (2025). Autoregressive Models in Vision: A Survey. *TMLR 2025*.
<https://arxiv.org/abs/2411.05902>

[^5]: Salimans, T., Karpathy, A., Chen, X., & Kingma, D. P. (2017). PixelCNN++: Improving the PixelCNN with Discretized Logistic Mixture Likelihood and Other Modifications. *ICLR 2017*.
<https://arxiv.org/abs/1701.05517>

[^6]: Li, T., et al. (2024). Autoregressive Image Generation without Vector Quantization. *NeurIPS 2024*.
<https://arxiv.org/abs/2406.11838>

[^7]: Ren, S., et al. (2024). FlowAR: Scale-wise Autoregressive Image Generation Meets Flow Matching. *arXiv:2412.15205*.
<https://arxiv.org/abs/2412.15205>

[^8]: Chang, H., Zhang, H., Jiang, L., Liu, C., & Freeman, W. T. (2022). MaskGIT: Masked Generative Image Transformer. *CVPR 2022*.
<https://arxiv.org/abs/2202.04200>

[^9]: Han, J., Liu, J., Jiang, Y., et al. (2025). Infinity: Scaling Bitwise AutoRegressive Modeling for High-Resolution Image Synthesis. *CVPR 2025 (Oral)*.
<https://arxiv.org/abs/2412.04431>

### æ•™ç§‘æ›¸

- Goodfellow, I., Bengio, Y., & Courville, A. (2016). *Deep Learning*. MIT Press. [Ch.10: Sequence Modeling, Ch.20: Deep Generative Models]
- Murphy, K. P. (2023). *Probabilistic Machine Learning: Advanced Topics*. MIT Press. [Ch.26: Autoregressive Sequence Models]

---

## è‘—è€…ãƒªãƒ³ã‚¯

- Blog: https://fumishiki.dev
- X: https://x.com/fumishiki
- LinkedIn: https://www.linkedin.com/in/fumitakamurakami
- GitHub: https://github.com/fumishiki
- Hugging Face: https://huggingface.co/fumishiki

## ãƒ©ã‚¤ã‚»ãƒ³ã‚¹

æœ¬è¨˜äº‹ã¯ [CC BY-NC-SA 4.0](https://creativecommons.org/licenses/by-nc-sa/4.0/deed.ja)ï¼ˆã‚¯ãƒªã‚¨ã‚¤ãƒ†ã‚£ãƒ–ãƒ»ã‚³ãƒ¢ãƒ³ã‚º è¡¨ç¤º - éå–¶åˆ© - ç¶™æ‰¿ 4.0 å›½éš›ï¼‰ã®ä¸‹ã§ãƒ©ã‚¤ã‚»ãƒ³ã‚¹ã•ã‚Œã¦ã„ã¾ã™ã€‚

### âš ï¸ åˆ©ç”¨åˆ¶é™ã«ã¤ã„ã¦

**æœ¬ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ã¯å€‹äººã®å­¦ç¿’ç›®çš„ã«é™ã‚Šåˆ©ç”¨å¯èƒ½ã§ã™ã€‚**

**ä»¥ä¸‹ã®ã‚±ãƒ¼ã‚¹ã¯äº‹å‰ã®æ˜ç¤ºçš„ãªè¨±å¯ãªãåˆ©ç”¨ã™ã‚‹ã“ã¨ã‚’å›ºãç¦ã˜ã¾ã™:**

1. **ä¼æ¥­ãƒ»çµ„ç¹”å†…ã§ã®åˆ©ç”¨ï¼ˆå–¶åˆ©ãƒ»éå–¶åˆ©å•ã‚ãšï¼‰**
   - ç¤¾å†…ç ”ä¿®ã€æ•™è‚²ã‚«ãƒªã‚­ãƒ¥ãƒ©ãƒ ã€ç¤¾å†…Wikiã¸ã®è»¢è¼‰
   - å¤§å­¦ãƒ»ç ”ç©¶æ©Ÿé–¢ã§ã®è¬›ç¾©åˆ©ç”¨
   - éå–¶åˆ©å›£ä½“ã§ã®ç ”ä¿®åˆ©ç”¨
   - **ç†ç”±**: çµ„ç¹”å†…åˆ©ç”¨ã§ã¯å¸°å±è¡¨ç¤ºãŒå‰Šé™¤ã•ã‚Œã‚„ã™ãã€ç„¡æ–­æ”¹å¤‰ã®ãƒªã‚¹ã‚¯ãŒé«˜ã„ãŸã‚

2. **æœ‰æ–™ã‚¹ã‚¯ãƒ¼ãƒ«ãƒ»æƒ…å ±å•†æãƒ»ã‚»ãƒŸãƒŠãƒ¼ã§ã®åˆ©ç”¨**
   - å—è¬›æ–™ã‚’å¾´åã™ã‚‹å ´ã§ã®é…å¸ƒã€ã‚¹ã‚¯ãƒªãƒ¼ãƒ³ã‚·ãƒ§ãƒƒãƒˆã®æ²ç¤ºã€æ´¾ç”Ÿæ•™æã®ä½œæˆ

3. **LLM/AIãƒ¢ãƒ‡ãƒ«ã®å­¦ç¿’ãƒ‡ãƒ¼ã‚¿ã¨ã—ã¦ã®åˆ©ç”¨**
   - å•†ç”¨ãƒ¢ãƒ‡ãƒ«ã®Pre-trainingã€Fine-tuningã€RAGã®çŸ¥è­˜ã‚½ãƒ¼ã‚¹ã¨ã—ã¦æœ¬ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ã‚’ã‚¹ã‚¯ãƒ¬ã‚¤ãƒ”ãƒ³ã‚°ãƒ»åˆ©ç”¨ã™ã‚‹ã“ã¨

4. **å‹æ‰‹ã«å†…å®¹ã‚’æœ‰æ–™åŒ–ã™ã‚‹è¡Œç‚ºå…¨èˆ¬**
   - æœ‰æ–™noteã€æœ‰æ–™è¨˜äº‹ã€Kindleå‡ºç‰ˆã€æœ‰æ–™å‹•ç”»ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ã€Patreoné™å®šã‚³ãƒ³ãƒ†ãƒ³ãƒ„ç­‰

**å€‹äººåˆ©ç”¨ã«å«ã¾ã‚Œã‚‹ã‚‚ã®:**
- å€‹äººã®å­¦ç¿’ãƒ»ç ”ç©¶
- å€‹äººçš„ãªãƒãƒ¼ãƒˆä½œæˆï¼ˆå€‹äººåˆ©ç”¨ã«é™ã‚‹ï¼‰
- å‹äººã¸ã®å…ƒè¨˜äº‹ãƒªãƒ³ã‚¯å…±æœ‰

**çµ„ç¹”ã§ã®å°å…¥ã‚’ã”å¸Œæœ›ã®å ´åˆ**ã¯ã€å¿…ãšè‘—è€…ã«é€£çµ¡ã‚’å–ã‚Šã€ä»¥ä¸‹ã‚’éµå®ˆã—ã¦ãã ã•ã„:
- å…¨ã¦ã®å¸°å±è¡¨ç¤ºãƒªãƒ³ã‚¯ã‚’ç¶­æŒ
- åˆ©ç”¨æ–¹æ³•ã‚’è‘—è€…ã«å ±å‘Š

**ç„¡æ–­åˆ©ç”¨ãŒç™ºè¦šã—ãŸå ´åˆ**ã€ä½¿ç”¨æ–™ã®è«‹æ±‚ãŠã‚ˆã³SNSç­‰ã§ã®å…¬è¡¨ã‚’è¡Œã†å ´åˆãŒã‚ã‚Šã¾ã™ã€‚

---
