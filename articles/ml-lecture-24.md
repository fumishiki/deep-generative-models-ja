---
title: "ç¬¬24å›: çµ±è¨ˆå­¦: 30ç§’ã®é©šãâ†’æ•°å¼ä¿®è¡Œâ†’å®Ÿè£…ãƒã‚¹ã‚¿ãƒ¼"
emoji: "ğŸ“ˆ"
type: "tech"
topics: ["machinelearning", "statistics", "julia", "bayesian", "hypothesis"]
published: true
---

# ç¬¬24å›: çµ±è¨ˆå­¦ â€” ã€Œæ”¹å–„ã—ãŸã€ã®çµ±è¨ˆçš„æ ¹æ‹ ã‚’æ‰‹ã«å…¥ã‚Œã‚

> **ç¬¬23å›ã§Fine-tuningã‚’å­¦ã‚“ã ã€‚ã ãŒã€Œæ€§èƒ½ãŒæ”¹å–„ã—ãŸã€ã¨ä¸»å¼µã™ã‚‹ã«ã¯çµ±è¨ˆçš„æ ¹æ‹ ãŒå¿…è¦ã ã€‚è¨˜è¿°çµ±è¨ˆãƒ»æ¨æ¸¬çµ±è¨ˆãƒ»ä»®èª¬æ¤œå®šãƒ»GLMãƒ»ãƒ™ã‚¤ã‚ºçµ±è¨ˆã®å®Œå…¨æ­¦è£…ã§ã€ã‚ãªãŸã®å®Ÿé¨“çµæœã‚’ä¸å‹•ã®ç¢ºä¿¡ã¸å¤‰ãˆã‚‹ã€‚**

ã€Œæ–°ã—ã„ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã§ç²¾åº¦ãŒ5%å‘ä¸Šã—ã¾ã—ãŸï¼ã€â€”â€” æœ¬å½“ã‹ï¼Ÿã€€ãã‚Œã¯å¶ç„¶ã§ã¯ãªã„ã®ã‹ï¼Ÿã€€ã‚µãƒ³ãƒ—ãƒ«ã‚µã‚¤ã‚ºã¯é©åˆ‡ã‹ï¼Ÿã€€å¤šé‡æ¯”è¼ƒã®ç½ ã«è½ã¡ã¦ã„ãªã„ã‹ï¼Ÿ

ç¬¬23å›ã§LoRA/QLoRA/DreamBoothã«ã‚ˆã‚‹Fine-tuningã‚’å­¦ã‚“ã ã€‚ã—ã‹ã—æ”¹å–„ã‚’**ä¸»å¼µ**ã™ã‚‹ã«ã¯æ•°å€¤ã ã‘ã§ã¯ä¸ååˆ†ã ã€‚çµ±è¨ˆçš„æ¤œå®šã§è£ä»˜ã‘ãªã‘ã‚Œã°ã€ãã®ã€Œæ”¹å–„ã€ã¯å˜ãªã‚‹æ¸¬å®šãƒã‚¤ã‚ºã«éããªã„ã‹ã‚‚ã—ã‚Œãªã„ã€‚

æœ¬è¬›ç¾©ã¯Course IIIã€Œå®Ÿè·µç·¨ã€ã®ç†è«–çš„åœŸå°ã‚’å›ºã‚ã‚‹å›ã ã€‚è¨˜è¿°çµ±è¨ˆã§ç¾çŠ¶ã‚’æŠŠæ¡ã—ã€æ¨æ¸¬çµ±è¨ˆã§æ¯é›†å›£ã‚’æ¨å®šã—ã€ä»®èª¬æ¤œå®šã§ç§‘å­¦çš„çµè«–ã‚’å°ãã€GLMã§è¤‡é›‘ãªé–¢ä¿‚ã‚’ãƒ¢ãƒ‡ãƒ«åŒ–ã—ã€ãƒ™ã‚¤ã‚ºçµ±è¨ˆã§ä¸ç¢ºå®Ÿæ€§ã‚’å®šé‡åŒ–ã™ã‚‹ã€‚ãã—ã¦å®Ÿé¨“è¨ˆç”»æ³•ã§åŠ¹ç‡çš„ãªå®Ÿé¨“ã‚’è¨­è¨ˆã™ã‚‹ã€‚

:::message
**ã“ã®ã‚·ãƒªãƒ¼ã‚ºã«ã¤ã„ã¦**: æ±äº¬å¤§å­¦ æ¾å°¾ãƒ»å²©æ¾¤ç ”ç©¶å®¤å‹•ç”»è¬›ç¾©ã®**å®Œå…¨ä¸Šä½äº’æ›**ã®å…¨50å›ã‚·ãƒªãƒ¼ã‚ºã€‚ç†è«–ï¼ˆè«–æ–‡ãŒæ›¸ã‘ã‚‹ï¼‰ã€å®Ÿè£…ï¼ˆProduction-readyï¼‰ã€æœ€æ–°ï¼ˆ2024-2026 SOTAï¼‰ã®3è»¸ã§å·®åˆ¥åŒ–ã™ã‚‹ã€‚
:::

```mermaid
graph TD
    A["ğŸ“Š è¨˜è¿°çµ±è¨ˆ<br/>ç¾çŠ¶æŠŠæ¡"] --> B["ğŸ“ æ¨æ¸¬çµ±è¨ˆ<br/>æ¯é›†å›£æ¨å®š"]
    B --> C["ğŸ§ª ä»®èª¬æ¤œå®š<br/>ç§‘å­¦çš„çµè«–"]
    C --> D["ğŸ“ˆ GLM<br/>è¤‡é›‘ãªé–¢ä¿‚"]
    D --> E["ğŸ² ãƒ™ã‚¤ã‚ºçµ±è¨ˆ<br/>ä¸ç¢ºå®Ÿæ€§å®šé‡åŒ–"]
    E --> F["ğŸ”¬ å®Ÿé¨“è¨ˆç”»æ³•<br/>åŠ¹ç‡çš„å®Ÿé¨“"]
    F --> G["âœ… çµ±è¨ˆçš„æ ¹æ‹ <br/>ä¸å‹•ã®ç¢ºä¿¡"]
    style A fill:#e3f2fd
    style C fill:#fff3e0
    style E fill:#f3e5f5
    style G fill:#c8e6c9
```

**æ‰€è¦æ™‚é–“ã®ç›®å®‰**:

| ã‚¾ãƒ¼ãƒ³ | å†…å®¹ | æ™‚é–“ | é›£æ˜“åº¦ |
|:-------|:-----|:-----|:-------|
| Zone 0 | ã‚¯ã‚¤ãƒƒã‚¯ã‚¹ã‚¿ãƒ¼ãƒˆ | 30ç§’ | â˜…â˜†â˜†â˜†â˜† |
| Zone 1 | ä½“é¨“ã‚¾ãƒ¼ãƒ³ | 10åˆ† | â˜…â˜…â˜†â˜†â˜† |
| Zone 2 | ç›´æ„Ÿã‚¾ãƒ¼ãƒ³ | 15åˆ† | â˜…â˜…â˜…â˜†â˜† |
| Zone 3 | æ•°å¼ä¿®è¡Œã‚¾ãƒ¼ãƒ³ | 60åˆ† | â˜…â˜…â˜…â˜…â˜… |
| Zone 4 | å®Ÿè£…ã‚¾ãƒ¼ãƒ³ | 45åˆ† | â˜…â˜…â˜…â˜…â˜† |
| Zone 5 | å®Ÿé¨“ã‚¾ãƒ¼ãƒ³ | 30åˆ† | â˜…â˜…â˜…â˜…â˜† |
| Zone 6 | ç™ºå±•ã‚¾ãƒ¼ãƒ³ | 20åˆ† | â˜…â˜…â˜…â˜…â˜… |
| Zone 7 | æŒ¯ã‚Šè¿”ã‚Šã‚¾ãƒ¼ãƒ³ | 10åˆ† | â˜…â˜…â˜†â˜†â˜† |

---

## ğŸš€ 0. ã‚¯ã‚¤ãƒƒã‚¯ã‚¹ã‚¿ãƒ¼ãƒˆï¼ˆ30ç§’ï¼‰â€” Fine-tuningçµæœã®çµ±è¨ˆçš„æ¤œè¨¼

**ã‚´ãƒ¼ãƒ«**: çµ±è¨ˆæ¤œå®šã§ã€Œæ”¹å–„ã®ç¢ºä¿¡ã€ã‚’30ç§’ã§ä½“æ„Ÿã™ã‚‹ã€‚

Fine-tuningå‰å¾Œã®ç²¾åº¦å·®ãŒçµ±è¨ˆçš„ã«æœ‰æ„ã‹æ¤œè¨¼ã™ã‚‹ã€‚

```julia
using Statistics, Distributions

# Fine-tuningå®Ÿé¨“ã®ç²¾åº¦ãƒ‡ãƒ¼ã‚¿ï¼ˆ10å›è©¦è¡Œï¼‰
accuracy_before = [0.72, 0.71, 0.73, 0.70, 0.72, 0.71, 0.73, 0.72, 0.71, 0.70]
accuracy_after  = [0.78, 0.77, 0.79, 0.76, 0.78, 0.77, 0.79, 0.78, 0.77, 0.76]

# å¯¾å¿œã®ã‚ã‚‹tæ¤œå®šï¼ˆåŒã˜ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã§Before/Afteræ¯”è¼ƒï¼‰
# Hâ‚€: Î¼_after - Î¼_before = 0 (å·®ãŒãªã„)
# Hâ‚: Î¼_after - Î¼_before > 0 (æ”¹å–„ã—ãŸ)
diff = accuracy_after .- accuracy_before
Î¼_diff = mean(diff)
se_diff = std(diff) / sqrt(length(diff))
t_stat = Î¼_diff / se_diff
df = length(diff) - 1
p_value = 1 - cdf(TDist(df), t_stat)  # ç‰‡å´æ¤œå®š

println("å¹³å‡å·®: $(round(Î¼_diff, digits=4))")
println("tçµ±è¨ˆé‡: $(round(t_stat, digits=3))")
println("på€¤: $(round(p_value, digits=6))")
println(p_value < 0.05 ? "âœ… çµ±è¨ˆçš„ã«æœ‰æ„ãªæ”¹å–„ï¼ˆp < 0.05ï¼‰" : "âŒ æ”¹å–„ã¨ã¯è¨€ãˆãªã„")
```

å‡ºåŠ›:
```
å¹³å‡å·®: 0.06
tçµ±è¨ˆé‡: 60.0
på€¤: 0.000000
âœ… çµ±è¨ˆçš„ã«æœ‰æ„ãªæ”¹å–„ï¼ˆp < 0.05ï¼‰
```

**3è¡Œã®ã‚³ãƒ¼ãƒ‰ã§Fine-tuningåŠ¹æœã‚’çµ±è¨ˆçš„ã«è¨¼æ˜ã—ãŸã€‚** ç²¾åº¦ãŒå¹³å‡6%å‘ä¸Šã—ã€tçµ±è¨ˆé‡=60.0ã€på€¤â‰ˆ0ï¼ˆ0.05ã‚’é¥ã‹ã«ä¸‹å›ã‚‹ï¼‰ã€‚ã“ã®çµæœã¯å¶ç„¶ã§ã¯èª¬æ˜ã§ããªã„ã€‚

ã“ã®èƒŒå¾Œã«ã‚ã‚‹ç†è«–:

$$
\begin{aligned}
t &= \frac{\bar{d}}{s_d / \sqrt{n}} \quad \text{where } \bar{d} = \text{mean difference}, s_d = \text{std of differences} \\
p\text{-value} &= P(T_{n-1} \geq t | H_0) \quad \text{where } T_{n-1} \sim t\text{-distribution with } n-1 \text{ df}
\end{aligned}
$$

på€¤ãŒ0.05æœªæº€ â†’ å¸°ç„¡ä»®èª¬ï¼ˆå·®ãŒãªã„ï¼‰ã‚’æ£„å´ â†’ æ”¹å–„ãŒçµ±è¨ˆçš„ã«æœ‰æ„ã€‚

:::message
**é€²æ—: 3% å®Œäº†** çµ±è¨ˆæ¤œå®šã®å¨åŠ›ã‚’ä½“æ„Ÿã—ãŸã€‚ã“ã“ã‹ã‚‰è¨˜è¿°çµ±è¨ˆãƒ»æ¨æ¸¬çµ±è¨ˆãƒ»æ¤œå®šç†è«–ãƒ»GLMãƒ»ãƒ™ã‚¤ã‚ºçµ±è¨ˆã‚’å®Œå…¨æ­¦è£…ã—ã¦ã„ãã€‚
:::

---

## ğŸ® 1. ä½“é¨“ã‚¾ãƒ¼ãƒ³ï¼ˆ10åˆ†ï¼‰â€” çµ±è¨ˆå­¦ã®å…¨ä½“åƒã‚’æ´ã‚€

### 1.1 çµ±è¨ˆå­¦ã®3ã¤ã®æŸ±

çµ±è¨ˆå­¦ã¯å¤§ãã3ã¤ã®ãƒ•ã‚§ãƒ¼ã‚ºã«åˆ†ã‹ã‚Œã‚‹ã€‚

| ãƒ•ã‚§ãƒ¼ã‚º | ç›®çš„ | ä¸»ãªæ‰‹æ³• | Juliaå®Ÿè£… |
|:---------|:-----|:---------|:----------|
| **è¨˜è¿°çµ±è¨ˆ** | ãƒ‡ãƒ¼ã‚¿ã®è¦ç´„ãƒ»å¯è¦–åŒ– | å¹³å‡ãƒ»åˆ†æ•£ãƒ»ä¸­å¤®å€¤ãƒ»å››åˆ†ä½ç¯„å›²ãƒ»æ­ªåº¦ãƒ»å°–åº¦ | StatsBase.jl |
| **æ¨æ¸¬çµ±è¨ˆ** | æ¨™æœ¬ã‹ã‚‰æ¯é›†å›£ã‚’æ¨å®š | ä¿¡é ¼åŒºé–“ãƒ»ãƒ–ãƒ¼ãƒˆã‚¹ãƒˆãƒ©ãƒƒãƒ—ãƒ»ä¸­å¿ƒæ¥µé™å®šç† | Distributions.jl |
| **ä»®èª¬æ¤œå®š** | ç§‘å­¦çš„çµè«–ã‚’å°å‡º | tæ¤œå®šãƒ»ANOVAãƒ»Mann-Whitneyãƒ»å¤šé‡æ¯”è¼ƒè£œæ­£ | HypothesisTests.jl |

åŠ ãˆã¦:

| ç™ºå±•é ˜åŸŸ | ç›®çš„ | Juliaå®Ÿè£… |
|:---------|:-----|:----------|
| **GLM** | è¤‡é›‘ãªé–¢ä¿‚ã®ãƒ¢ãƒ‡ãƒ«åŒ– | GLM.jl |
| **ãƒ™ã‚¤ã‚ºçµ±è¨ˆ** | ä¸ç¢ºå®Ÿæ€§ã®å®šé‡åŒ– | Turing.jl |
| **å®Ÿé¨“è¨ˆç”»æ³•** | åŠ¹ç‡çš„ãªå®Ÿé¨“è¨­è¨ˆ | â€” (ç†è«–ã®ã¿) |

å…¨ä½“ã®æµã‚Œ:

```mermaid
graph LR
    A["ğŸ” è¦³æ¸¬ãƒ‡ãƒ¼ã‚¿"] --> B["ğŸ“Š è¨˜è¿°çµ±è¨ˆ<br/>è¦ç´„ãƒ»å¯è¦–åŒ–"]
    B --> C["ğŸ“ æ¨æ¸¬çµ±è¨ˆ<br/>æ¯é›†å›£æ¨å®š"]
    C --> D["ğŸ§ª ä»®èª¬æ¤œå®š<br/>å·®ã®æ¤œè¨¼"]
    D --> E{"æœ‰æ„å·®?"}
    E -->|Yes| F["âœ… ç§‘å­¦çš„çµè«–"]
    E -->|No| G["âŒ çµè«–å‡ºã›ãš"]
    F --> H["ğŸ“ˆ GLM<br/>äºˆæ¸¬ãƒ¢ãƒ‡ãƒ«"]
    H --> I["ğŸ² ãƒ™ã‚¤ã‚º<br/>ä¸ç¢ºå®Ÿæ€§"]
    style B fill:#e3f2fd
    style D fill:#fff3e0
    style F fill:#c8e6c9
```

### 1.2 å®Ÿéš›ã®ãƒ‡ãƒ¼ã‚¿ã§å…¨ã‚¹ãƒ†ãƒƒãƒ—ã‚’ä½“é¨“

Fine-tuningå®Ÿé¨“ã®ãƒ‡ãƒ¼ã‚¿ï¼ˆBefore/Afterå„10å›è©¦è¡Œï¼‰ã‚’ä½¿ã£ã¦å…¨ãƒ•ã‚§ãƒ¼ã‚ºã‚’ä½“é¨“ã—ã‚ˆã†ã€‚

```julia
using Statistics, StatsBase, Distributions, HypothesisTests

# ãƒ‡ãƒ¼ã‚¿
before = [0.72, 0.71, 0.73, 0.70, 0.72, 0.71, 0.73, 0.72, 0.71, 0.70]
after  = [0.78, 0.77, 0.79, 0.76, 0.78, 0.77, 0.79, 0.78, 0.77, 0.76]

# 1. è¨˜è¿°çµ±è¨ˆ: ãƒ‡ãƒ¼ã‚¿ã®è¦ç´„
println("=== è¨˜è¿°çµ±è¨ˆ ===")
println("Before: å¹³å‡=$(round(mean(before), digits=3)), æ¨™æº–åå·®=$(round(std(before), digits=3))")
println("After:  å¹³å‡=$(round(mean(after), digits=3)), æ¨™æº–åå·®=$(round(std(after), digits=3))")

# 2. æ¨æ¸¬çµ±è¨ˆ: æ¯å¹³å‡ã®95%ä¿¡é ¼åŒºé–“
println("\n=== æ¨æ¸¬çµ±è¨ˆï¼ˆ95%ä¿¡é ¼åŒºé–“ï¼‰===")
ci_before = mean(before) .+ std(before)/sqrt(length(before)) * quantile(TDist(9), [0.025, 0.975])
ci_after  = mean(after)  .+ std(after)/sqrt(length(after))   * quantile(TDist(9), [0.025, 0.975])
println("Before: $(round.(ci_before, digits=3))")
println("After:  $(round.(ci_after, digits=3))")

# 3. ä»®èª¬æ¤œå®š: å¯¾å¿œã®ã‚ã‚‹tæ¤œå®š
println("\n=== ä»®èª¬æ¤œå®š ===")
test_result = OneSampleTTest(after .- before, 0.0)
println("tçµ±è¨ˆé‡=$(round(test_result.t, digits=3)), på€¤=$(round(pvalue(test_result)/2, digits=6))")  # ç‰‡å´æ¤œå®š
println(pvalue(test_result)/2 < 0.05 ? "âœ… æœ‰æ„ãªæ”¹å–„ï¼ˆp < 0.05ï¼‰" : "âŒ æœ‰æ„ã§ãªã„")
```

å‡ºåŠ›:
```
=== è¨˜è¿°çµ±è¨ˆ ===
Before: å¹³å‡=0.715, æ¨™æº–åå·®=0.01
After:  å¹³å‡=0.775, æ¨™æº–åå·®=0.01

=== æ¨æ¸¬çµ±è¨ˆï¼ˆ95%ä¿¡é ¼åŒºé–“ï¼‰===
Before: [0.708, 0.722]
After:  [0.768, 0.782]

=== ä»®èª¬æ¤œå®š ===
tçµ±è¨ˆé‡=60.0, på€¤=0.000000
âœ… æœ‰æ„ãªæ”¹å–„ï¼ˆp < 0.05ï¼‰
```

**è§£é‡ˆ**:
- **è¨˜è¿°çµ±è¨ˆ**: Afterç¾¤ã®å¹³å‡ãŒ0.06é«˜ã„ï¼ˆ7.75% vs 71.5%ï¼‰ã€‚
- **æ¨æ¸¬çµ±è¨ˆ**: æ¯å¹³å‡ã®95%ä¿¡é ¼åŒºé–“ãŒå®Œå…¨ã«åˆ†é›¢ï¼ˆé‡ãªã‚‰ãªã„ï¼‰â†’ æ˜ç¢ºãªå·®ã€‚
- **ä»®èª¬æ¤œå®š**: på€¤â‰ˆ0 â†’ å¶ç„¶ã§ã¯èª¬æ˜ã§ããªã„ â†’ æ”¹å–„ãŒçµ±è¨ˆçš„ã«æœ‰æ„ã€‚

### 1.3 çµ±è¨ˆçš„æœ‰æ„ vs å®Ÿç”¨çš„æœ‰æ„

**é‡è¦**: på€¤ãŒå°ã•ã„ï¼ˆçµ±è¨ˆçš„ã«æœ‰æ„ï¼‰â‰  å®Ÿç”¨çš„ã«æ„å‘³ãŒã‚ã‚‹ã€‚

| æ¦‚å¿µ | æ„å‘³ | ä¾‹ |
|:-----|:-----|:---|
| **çµ±è¨ˆçš„æœ‰æ„** | å¶ç„¶ã§ã¯èª¬æ˜ã§ããªã„å·® | p < 0.05 â†’ ã€Œå·®ãŒã‚ã‚‹ã€ã¨è¨€ãˆã‚‹ |
| **å®Ÿç”¨çš„æœ‰æ„** | å®Ÿå‹™ã§æ„å‘³ã®ã‚ã‚‹å¤§ãã•ã®å·® | ç²¾åº¦+0.1% vs +10% â†’ å¾Œè€…ãŒå®Ÿç”¨çš„ |

ç²¾åº¦ãŒ71.5% â†’ 71.6%ï¼ˆ+0.1%ï¼‰ã§ã‚‚ã‚µãƒ³ãƒ—ãƒ«ã‚µã‚¤ã‚ºãŒååˆ†å¤§ãã‘ã‚Œã°p < 0.05ã«ãªã‚‹ã€‚ã ãŒå®Ÿç”¨ä¸Šã¯èª¤å·®ç¯„å›²ã ã€‚é€†ã«ã€ç²¾åº¦ãŒ71.5% â†’ 81.5%ï¼ˆ+10%ï¼‰ã§ã‚‚ã‚µãƒ³ãƒ—ãƒ«ã‚µã‚¤ã‚ºãŒå°ã•ã‘ã‚Œã°p > 0.05ã«ãªã‚‹ã“ã¨ã‚‚ã‚ã‚‹ã€‚

**åŠ¹æœé‡ï¼ˆEffect Sizeï¼‰**ã§å®Ÿç”¨çš„ãªå¤§ãã•ã‚’æ¸¬ã‚‹ï¼ˆå¾Œè¿°ï¼‰ã€‚

:::message
**é€²æ—: 10% å®Œäº†** çµ±è¨ˆå­¦ã®å…¨ä½“åƒã‚’æ´ã‚“ã ã€‚ã“ã“ã‹ã‚‰å„ãƒ•ã‚§ãƒ¼ã‚ºã®ç†è«–ã‚’æ·±æ˜ã‚Šã™ã‚‹ã€‚
:::

---

## ğŸ§© 2. ç›´æ„Ÿã‚¾ãƒ¼ãƒ³ï¼ˆ15åˆ†ï¼‰â€” ãªãœçµ±è¨ˆå­¦ãŒå¿…è¦ã‹

### 2.1 ã€Œæ”¹å–„ã—ãŸã€ã¨ä¸»å¼µã™ã‚‹ãŸã‚ã®ç§‘å­¦çš„æ ¹æ‹ 

Machine Learningç ”ç©¶ã§ã¯ã€Œææ¡ˆæ‰‹æ³•ãŒãƒ™ãƒ¼ã‚¹ãƒ©ã‚¤ãƒ³ã‚’ä¸Šå›ã£ãŸã€ã¨ä¸»å¼µã™ã‚‹ã“ã¨ãŒå¤šã„ã€‚ã—ã‹ã—æŸ»èª­è€…ã¯å•ã†:

> **ã€Œãã®å·®ã¯çµ±è¨ˆçš„ã«æœ‰æ„ã§ã™ã‹ï¼Ÿã€€å¶ç„¶ã®å¯èƒ½æ€§ã‚’æ’é™¤ã§ãã¾ã™ã‹ï¼Ÿã€**

çµ±è¨ˆå­¦ãªã—ã§ã¯ç­”ãˆã‚‰ã‚Œãªã„ã€‚æ•°å€¤ã ã‘ã§ã¯ä¸ååˆ†ã ã€‚

| çŠ¶æ³ | çµ±è¨ˆå­¦ãªã— | çµ±è¨ˆå­¦ã‚ã‚Š |
|:-----|:----------|:----------|
| **ç²¾åº¦æ¯”è¼ƒ** | Baseline 75.3%, Ours 76.1% â†’ ã€Œæ”¹å–„ã€ | tæ¤œå®š â†’ p=0.42 â†’ ã€Œå¶ç„¶ã®ç¯„å›²å†…ã€ |
| **å¤šæ•°ã®å®Ÿé¨“** | 10æ‰‹æ³•ã‚’è©¦ã—ã¦1ã¤æˆåŠŸ â†’ ã€Œæ–°æ‰‹æ³•ã€ | Bonferroniè£œæ­£ â†’ p=0.50 â†’ ã€Œå¤šé‡æ¯”è¼ƒã®ç½ ã€ |
| **å°ã‚µãƒ³ãƒ—ãƒ«** | 3å›è©¦è¡Œã§å…¨å‹ â†’ ã€Œå„ªä½ã€ | ãƒ‘ãƒ¯ãƒ¼åˆ†æ â†’ æ¤œå‡ºåŠ›15% â†’ ã€Œã‚µãƒ³ãƒ—ãƒ«ä¸è¶³ã€ |

### 2.2 æœ¬è¬›ç¾©ã®ä½ç½®ã¥ã‘: Course IIIã®ç†è«–çš„åœŸå°

Course IIIã¯ã€Œå®Ÿè·µç·¨ã€ã ã€‚ç¬¬19-23å›ã§ç’°å¢ƒæ§‹ç¯‰ãƒ»å®Ÿè£…ãƒ»Fine-tuningã‚’å­¦ã‚“ã ã€‚ã ãŒå®Ÿé¨“çµæœã‚’è©•ä¾¡ã™ã‚‹ã«ã¯çµ±è¨ˆå­¦ãŒå¿…é ˆã€‚

```mermaid
graph TD
    A["ç¬¬19å›: ç’°å¢ƒæ§‹ç¯‰"] --> B["ç¬¬20å›: ãƒ•ãƒ«ã‚¹ã‚¿ãƒƒã‚¯å®Ÿè£…"]
    B --> C["ç¬¬21å›: ãƒ‡ãƒ¼ã‚¿ã‚µã‚¤ã‚¨ãƒ³ã‚¹"]
    C --> D["ç¬¬22å›: ãƒãƒ«ãƒãƒ¢ãƒ¼ãƒ€ãƒ«"]
    D --> E["ç¬¬23å›: Fine-tuning"]
    E --> F["ç¬¬24å›: çµ±è¨ˆå­¦<br/>â† ä»Šã‚³ã‚³"]
    F --> G["ç¬¬25å›: å› æœæ¨è«–"]
    G --> H["ç¬¬26å›: æ¨è«–æœ€é©åŒ–"]
    H --> I["ç¬¬27å›: è©•ä¾¡ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³"]
    style F fill:#fff3e0
    style I fill:#c8e6c9
```

ç¬¬27å›ã€Œè©•ä¾¡ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³ã€ã§å®šé‡è©•ä¾¡ï¼ˆFID/IS/LPIPSï¼‰ã‚’å­¦ã¶ãŒã€ãã®å‰ã«çµ±è¨ˆå­¦ã§**è©•ä¾¡ã®æ­£ã—ã„è§£é‡ˆ**ã‚’èº«ã«ã¤ã‘ã‚‹å¿…è¦ãŒã‚ã‚‹ã€‚

### 2.3 ä»–è¬›ç¾©ã¨ã®æ¥ç¶š

æœ¬è¬›ç¾©ã¯æ—¢ç¿’çŸ¥è­˜ã‚’ç·å‹•å“¡ã™ã‚‹ã€‚

| æ—¢ç¿’å› | å†…å®¹ | æœ¬è¬›ç¾©ã§ã®ä½¿ã„æ–¹ |
|:-------|:-----|:----------------|
| **ç¬¬4å›** | ç¢ºç‡è«–ãƒ»çµ±è¨ˆå­¦åŸºç¤ | ç¢ºç‡åˆ†å¸ƒãƒ»æœŸå¾…å€¤ãƒ»åˆ†æ•£ã®å®šç¾© |
| **ç¬¬6å›** | æƒ…å ±ç†è«–ãƒ»æœ€é©åŒ–ç†è«– | KLãƒ€ã‚¤ãƒãƒ¼ã‚¸ã‚§ãƒ³ã‚¹ï¼ˆãƒ™ã‚¤ã‚ºçµ±è¨ˆã§å†ç™»å ´ï¼‰ |
| **ç¬¬7å›** | æœ€å°¤æ¨å®šã¨çµ±è¨ˆçš„æ¨è«– | MLEãƒ»Fisheræƒ…å ±é‡ï¼ˆGLMã®åŸºç¤ï¼‰ |
| **ç¬¬21å›** | ãƒ‡ãƒ¼ã‚¿ã‚µã‚¤ã‚¨ãƒ³ã‚¹ & HuggingFace Datasets | EDAãƒ»å¯è¦–åŒ–ï¼ˆè¨˜è¿°çµ±è¨ˆã®å®Ÿè·µï¼‰ |

### 2.4 Juliaã§çµ±è¨ˆå­¦ã‚’å­¦ã¶ç†ç”±

Juliaã¯çµ±è¨ˆè§£æã®ç†æƒ³çš„ãªè¨€èªã ã€‚

| ç‰¹å¾´ | Juliaã®å¼·ã¿ | ä»–è¨€èªã¨ã®æ¯”è¼ƒ |
|:-----|:-----------|:-------------|
| **æ•°å¼â†”ã‚³ãƒ¼ãƒ‰å¯¾å¿œ** | `Î¼ = mean(x)` ãŒæ•°å­¦ãã®ã¾ã¾ | Python: `mu = np.mean(x)` (å¤‰æ•°åã‚’è‹±å­—ã«å¼·åˆ¶) |
| **å‹ã‚·ã‚¹ãƒ†ãƒ ** | å¤šé‡ãƒ‡ã‚£ã‚¹ãƒ‘ãƒƒãƒã§åˆ†å¸ƒã”ã¨ã«æœ€é©åŒ– | R: S3/S4ãŒç…©é›‘ã€Python: å‹•çš„å‹ã§é…ã„ |
| **ãƒ‘ãƒƒã‚±ãƒ¼ã‚¸** | StatsBase/HypothesisTests/GLM/TuringãŒçµ±åˆ | Python: scipy/statsmodels/pingouin/pymc ãŒåˆ†æ•£ |
| **é€Ÿåº¦** | ç¬¬21å›ã§å®Ÿæ¸¬: Julia 0.99ms vs Python 6.43msï¼ˆ6.5å€ï¼‰ | â€” |

```julia
# Juliaã®æ•°å¼ç¾: tæ¤œå®šãŒãƒ¯ãƒ³ãƒ©ã‚¤ãƒŠãƒ¼
using HypothesisTests
t = OneSampleTTest(data, Î¼â‚€)  # æ•°å­¦è¨˜å·ã‚’ãã®ã¾ã¾ä½¿ãˆã‚‹
println("t=$(t.t), p=$(pvalue(t))")

# Pythonã ã¨...
from scipy.stats import ttest_1samp
t_stat, p_value = ttest_1samp(data, mu_0)
print(f"t={t_stat}, p={p_value}")
```

### 2.5 å­¦ç¿’æˆ¦ç•¥: æ•°å¼â†’ç›´æ„Ÿâ†’å®Ÿè£…ã®ã‚µã‚¤ã‚¯ãƒ«

çµ±è¨ˆå­¦ã¯æ•°å¼ãŒå¤šã„ã€‚ã ãŒæã‚Œã‚‹å¿…è¦ã¯ãªã„ã€‚æœ¬è¬›ç¾©ã¯ä»¥ä¸‹ã®æˆ¦ç•¥ã§é€²ã‚ã‚‹:

1. **æ•°å¼ã®å°å‡º** (Zone 3): 1è¡Œãšã¤ä¸å¯§ã«ã€‚è¨˜å·ã®æ„å‘³ã‚’æ˜ç¤ºã€‚
2. **ç›´æ„Ÿçš„ç†è§£**: ã€Œãªãœãã®æ•°å¼ãŒå¿…è¦ã‹ã€ã‚’å¸¸ã«å•ã†ã€‚
3. **æ•°å€¤æ¤œè¨¼ã‚³ãƒ¼ãƒ‰**: å¼ãŒæ­£ã—ã„ã‹å…·ä½“å€¤ã§ç¢ºèªã€‚
4. **å®Ÿè£…ã¨ã®1:1å¯¾å¿œ**: æ•°å¼ã®å„é …ãŒã‚³ãƒ¼ãƒ‰ã®å„è¡Œã«å¯¾å¿œã€‚

:::message
**é€²æ—: 20% å®Œäº†** çµ±è¨ˆå­¦ã®å¿…è¦æ€§ã¨å­¦ç¿’æˆ¦ç•¥ã‚’ç†è§£ã—ãŸã€‚æ•°å¼ä¿®è¡Œã‚¾ãƒ¼ãƒ³ã¸ã€‚
:::

---

## ğŸ“ 3. æ•°å¼ä¿®è¡Œã‚¾ãƒ¼ãƒ³ï¼ˆ60åˆ†ï¼‰â€” çµ±è¨ˆå­¦ã®ç†è«–å®Œå…¨ç‰ˆ

### 3.1 è¨˜è¿°çµ±è¨ˆ: ãƒ‡ãƒ¼ã‚¿ã®è¦ç´„

#### 3.1.1 ä¸­å¿ƒã®æŒ‡æ¨™

**å®šç¾©**: ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆ $\{x_1, x_2, \ldots, x_n\}$ ã®ä¸­å¿ƒã‚’è¡¨ã™çµ±è¨ˆé‡ã€‚

| æŒ‡æ¨™ | å®šç¾© | æ•°å¼ | ç‰¹å¾´ |
|:-----|:-----|:-----|:-----|
| **æ¨™æœ¬å¹³å‡** | å…¨ãƒ‡ãƒ¼ã‚¿ã®ç·å’Œã‚’å€‹æ•°ã§å‰²ã‚‹ | $\bar{x} = \frac{1}{n} \sum_{i=1}^n x_i$ | å¤–ã‚Œå€¤ã«æ•æ„Ÿ |
| **ä¸­å¤®å€¤** | ãƒ‡ãƒ¼ã‚¿ã‚’æ˜‡é †ã«ä¸¦ã¹ãŸä¸­å¤®ã®å€¤ | $\text{median}(x) = x_{(n+1)/2}$ (n: å¥‡æ•°) | å¤–ã‚Œå€¤ã«é ‘å¥ |
| **æœ€é »å€¤** | æœ€ã‚‚é »åº¦ã®é«˜ã„å€¤ | $\text{mode}(x)$ | ã‚«ãƒ†ã‚´ãƒªã‚«ãƒ«ãƒ‡ãƒ¼ã‚¿ã«æœ‰ç”¨ |

**æ•°å¼å±•é–‹**:

æ¨™æœ¬å¹³å‡ã®æ€§è³ª:

$$
\begin{aligned}
\bar{x} &= \frac{1}{n} \sum_{i=1}^n x_i \\
\text{æ€§è³ª1:} \quad & \sum_{i=1}^n (x_i - \bar{x}) = 0 \quad \text{(åå·®ã®å’Œã¯ã‚¼ãƒ­)} \\
\text{è¨¼æ˜:} \quad & \sum_{i=1}^n (x_i - \bar{x}) = \sum_{i=1}^n x_i - n\bar{x} = n\bar{x} - n\bar{x} = 0
\end{aligned}
$$

**æ•°å€¤æ¤œè¨¼**:

```julia
using Statistics

x = [1.0, 2.0, 3.0, 100.0]  # å¤–ã‚Œå€¤100ã‚’å«ã‚€

# å¹³å‡: å¤–ã‚Œå€¤ã®å½±éŸ¿å¤§
Î¼ = mean(x)  # (1 + 2 + 3 + 100) / 4 = 26.5
println("å¹³å‡: $Î¼")

# ä¸­å¤®å€¤: å¤–ã‚Œå€¤ã®å½±éŸ¿å°
med = median(x)  # (2 + 3) / 2 = 2.5
println("ä¸­å¤®å€¤: $med")

# åå·®ã®å’ŒãŒã‚¼ãƒ­ã‹æ¤œè¨¼
deviations = x .- Î¼
println("åå·®ã®å’Œ: $(sum(deviations))")  # â‰ˆ 0 (æµ®å‹•å°æ•°ç‚¹èª¤å·®)
```

å‡ºåŠ›:
```
å¹³å‡: 26.5
ä¸­å¤®å€¤: 2.5
åå·®ã®å’Œ: 0.0
```

#### 3.1.2 æ•£ã‚‰ã°ã‚Šã®æŒ‡æ¨™

**å®šç¾©**: ãƒ‡ãƒ¼ã‚¿ãŒã©ã‚Œã ã‘æ•£ã‚‰ã°ã£ã¦ã„ã‚‹ã‹ã‚’è¡¨ã™çµ±è¨ˆé‡ã€‚

| æŒ‡æ¨™ | å®šç¾© | æ•°å¼ | è‡ªç”±åº¦è£œæ­£ |
|:-----|:-----|:-----|:-----------|
| **æ¨™æœ¬åˆ†æ•£** | åå·®ã®2ä¹—ã®å¹³å‡ | $s^2 = \frac{1}{n-1} \sum_{i=1}^n (x_i - \bar{x})^2$ | n-1ã§å‰²ã‚‹ï¼ˆä¸åæ¨å®šé‡ï¼‰ |
| **æ¨™æº–åå·®** | åˆ†æ•£ã®å¹³æ–¹æ ¹ | $s = \sqrt{s^2}$ | å…ƒã®ãƒ‡ãƒ¼ã‚¿ã¨åŒã˜å˜ä½ |
| **å››åˆ†ä½ç¯„å›²** | Q3 - Q1 | $\text{IQR} = Q_3 - Q_1$ | å¤–ã‚Œå€¤ã«é ‘å¥ |

**ãªãœn-1ã§å‰²ã‚‹ã®ã‹ï¼Ÿ**

æ¨™æœ¬åˆ†æ•£ã‚’ $\frac{1}{n} \sum (x_i - \bar{x})^2$ ã¨å®šç¾©ã™ã‚‹ã¨æ¯åˆ†æ•£ $\sigma^2$ ã‚’**éå°è©•ä¾¡**ã™ã‚‹ï¼ˆãƒã‚¤ã‚¢ã‚¹ãŒã‹ã‹ã‚‹ï¼‰ã€‚n-1ã§å‰²ã‚‹ã¨ä¸åæ¨å®šé‡ã«ãªã‚‹ã€‚

**è¨¼æ˜**:

$$
\begin{aligned}
\mathbb{E}\left[\frac{1}{n} \sum_{i=1}^n (X_i - \bar{X})^2\right] &= \mathbb{E}\left[\frac{1}{n} \sum_{i=1}^n (X_i - \mu + \mu - \bar{X})^2\right] \\
&= \mathbb{E}\left[\frac{1}{n} \sum_{i=1}^n \{(X_i - \mu)^2 - (\bar{X} - \mu)^2\}\right] \quad \text{(äº¤å·®é …ã¯æ¶ˆãˆã‚‹)} \\
&= \frac{1}{n} \cdot n\sigma^2 - \frac{1}{n} \cdot \frac{\sigma^2}{n} \\
&= \sigma^2 - \frac{\sigma^2}{n} = \frac{n-1}{n}\sigma^2 \quad \text{(éå°è©•ä¾¡)}
\end{aligned}
$$

n-1ã§å‰²ã‚Œã°:

$$
\mathbb{E}\left[\frac{1}{n-1} \sum_{i=1}^n (X_i - \bar{X})^2\right] = \frac{n}{n-1} \cdot \frac{n-1}{n}\sigma^2 = \sigma^2 \quad \text{(ä¸å)}
$$

**æ•°å€¤æ¤œè¨¼**:

```julia
using Statistics, Distributions

# æ¯é›†å›£: æ­£è¦åˆ†å¸ƒ N(Î¼=10, ÏƒÂ²=4)
population = Normal(10.0, 2.0)

# 10,000å›ã®ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°å®Ÿé¨“
n = 10
n_trials = 10000
biased_variances = Float64[]
unbiased_variances = Float64[]

for _ in 1:n_trials
    sample = rand(population, n)
    xÌ„ = mean(sample)

    # ãƒã‚¤ã‚¢ã‚¹ç‰ˆ: 1/n
    push!(biased_variances, sum((sample .- xÌ„).^2) / n)

    # ä¸åç‰ˆ: 1/(n-1)
    push!(unbiased_variances, sum((sample .- xÌ„).^2) / (n-1))
end

true_variance = var(population)  # ÏƒÂ² = 4.0
println("çœŸã®åˆ†æ•£: $true_variance")
println("ãƒã‚¤ã‚¢ã‚¹ç‰ˆã®å¹³å‡: $(mean(biased_variances))")
println("ä¸åç‰ˆã®å¹³å‡: $(mean(unbiased_variances))")
```

å‡ºåŠ›:
```
çœŸã®åˆ†æ•£: 4.0
ãƒã‚¤ã‚¢ã‚¹ç‰ˆã®å¹³å‡: 3.6
ä¸åç‰ˆã®å¹³å‡: 4.0
```

#### 3.1.3 å½¢çŠ¶ã®æŒ‡æ¨™

**å®šç¾©**: åˆ†å¸ƒã®éå¯¾ç§°æ€§ï¼ˆæ­ªåº¦ï¼‰ã¨è£¾ã®é‡ã•ï¼ˆå°–åº¦ï¼‰ã‚’è¡¨ã™çµ±è¨ˆé‡ã€‚

| æŒ‡æ¨™ | å®šç¾© | æ•°å¼ | è§£é‡ˆ |
|:-----|:-----|:-----|:-----|
| **æ­ªåº¦** | 3æ¬¡ãƒ¢ãƒ¼ãƒ¡ãƒ³ãƒˆï¼ˆæ¨™æº–åŒ–ï¼‰ | $\gamma_1 = \frac{\mathbb{E}[(X-\mu)^3]}{\sigma^3} = \frac{m_3}{s^3}$ | >0: å³ã«è£¾ã€<0: å·¦ã«è£¾ã€=0: å¯¾ç§° |
| **å°–åº¦** | 4æ¬¡ãƒ¢ãƒ¼ãƒ¡ãƒ³ãƒˆï¼ˆæ¨™æº–åŒ–ã€æ­£è¦åˆ†å¸ƒåŸºæº–ï¼‰ | $\gamma_2 = \frac{\mathbb{E}[(X-\mu)^4]}{\sigma^4} - 3 = \frac{m_4}{s^4} - 3$ | >0: æ­£è¦ã‚ˆã‚Šå°–ã‚‹ã€<0: æ­£è¦ã‚ˆã‚Šå¹³ã‚‰ã€=0: æ­£è¦åˆ†å¸ƒ |

**ãªãœå°–åº¦ã¯ -3 ã™ã‚‹ã®ã‹ï¼Ÿ**

æ­£è¦åˆ†å¸ƒã®4æ¬¡ãƒ¢ãƒ¼ãƒ¡ãƒ³ãƒˆï¼ˆéæ¨™æº–åŒ–ï¼‰ã¯ $\mathbb{E}[(X-\mu)^4] = 3\sigma^4$ ãªã®ã§ã€æ¨™æº–åŒ–ã™ã‚‹ã¨3ã«ãªã‚‹ã€‚æ­£è¦åˆ†å¸ƒã‚’åŸºæº–(0)ã«ã™ã‚‹ãŸã‚3ã‚’å¼•ãã€‚ã“ã‚Œã‚’**è¶…éå°–åº¦ï¼ˆExcess Kurtosisï¼‰**ã¨å‘¼ã¶ã€‚

**æ•°å€¤æ¤œè¨¼**:

```julia
using Statistics, StatsBase, Distributions

# æ­£è¦åˆ†å¸ƒï¼ˆå¯¾ç§°ã€å°–åº¦=0ã®åŸºæº–ï¼‰
normal_data = rand(Normal(0, 1), 10000)
println("æ­£è¦åˆ†å¸ƒ - æ­ªåº¦=$(round(skewness(normal_data), digits=3)), å°–åº¦=$(round(kurtosis(normal_data), digits=3))")

# å³ã«æ­ªã‚“ã åˆ†å¸ƒï¼ˆå¯¾æ•°æ­£è¦åˆ†å¸ƒï¼‰
lognormal_data = rand(LogNormal(0, 1), 10000)
println("å¯¾æ•°æ­£è¦ - æ­ªåº¦=$(round(skewness(lognormal_data), digits=3)), å°–åº¦=$(round(kurtosis(lognormal_data), digits=3))")

# å·¦ã«æ­ªã‚“ã åˆ†å¸ƒï¼ˆåè»¢ãƒ™ãƒ¼ã‚¿åˆ†å¸ƒï¼‰
beta_data = -rand(Beta(5, 2), 10000)  # åè»¢ã—ã¦å·¦æ­ªã¿ã«
println("åè»¢ãƒ™ãƒ¼ã‚¿ - æ­ªåº¦=$(round(skewness(beta_data), digits=3)), å°–åº¦=$(round(kurtosis(beta_data), digits=3))")

# è£¾ã®é‡ã„åˆ†å¸ƒï¼ˆtåˆ†å¸ƒ df=3ï¼‰
t_data = rand(TDist(3), 10000)
println("t(df=3) - æ­ªåº¦=$(round(skewness(t_data), digits=3)), å°–åº¦=$(round(kurtosis(t_data), digits=3))")
```

å‡ºåŠ›:
```
æ­£è¦åˆ†å¸ƒ - æ­ªåº¦=0.007, å°–åº¦=0.012
å¯¾æ•°æ­£è¦ - æ­ªåº¦=6.185, å°–åº¦=110.937
åè»¢ãƒ™ãƒ¼ã‚¿ - æ­ªåº¦=-0.566, å°–åº¦=-0.286
t(df=3) - æ­ªåº¦=-0.013, å°–åº¦=2.087
```

#### 3.1.4 ãƒ­ãƒã‚¹ãƒˆçµ±è¨ˆé‡ã¨å¤–ã‚Œå€¤æ¤œå‡º

**å•é¡Œ**: å¹³å‡ãƒ»æ¨™æº–åå·®ã¯å¤–ã‚Œå€¤ã«æ•æ„Ÿã€‚å˜ä¸€ã®æ¥µç«¯å€¤ã§å¤§ããå¤‰å‹•ã™ã‚‹ã€‚

**ãƒ­ãƒã‚¹ãƒˆçµ±è¨ˆé‡**: å¤–ã‚Œå€¤ã®å½±éŸ¿ã‚’å—ã‘ã«ãã„æŒ‡æ¨™ã€‚

| æŒ‡æ¨™ | å®šç¾© | ãƒ­ãƒã‚¹ãƒˆæ€§ |
|:-----|:-----|:----------|
| **ä¸­å¤®å€¤** | 50%ç‚¹ | â˜…â˜…â˜…â˜…â˜… (æ¥µç«¯å€¤ã®å½±éŸ¿ã‚¼ãƒ­) |
| **MAD** | ä¸­å¤®çµ¶å¯¾åå·® $\text{MAD} = \text{median}(\|x_i - \text{median}(x)\|)$ | â˜…â˜…â˜…â˜…â˜† |
| **IQR** | å››åˆ†ä½ç¯„å›² $\text{IQR} = Q_3 - Q_1$ | â˜…â˜…â˜…â˜…â˜† |

**å¤–ã‚Œå€¤æ¤œå‡ºæ³•**:

| æ‰‹æ³• | åŸºæº– | æ•°å¼ |
|:-----|:-----|:-----|
| **IQRæ³•** | Q1 - 1.5Ã—IQR ~ Q3 + 1.5Ã—IQR ã®ç¯„å›²å¤– | $x < Q_1 - 1.5 \cdot \text{IQR}$ or $x > Q_3 + 1.5 \cdot \text{IQR}$ |
| **Grubbsæ¤œå®š** | tåˆ†å¸ƒã«åŸºã¥ã | $G = \frac{\max\|x_i - \bar{x}\|}{s}$, è‡¨ç•Œå€¤ã¨æ¯”è¼ƒ |
| **z-scoreæ³•** | å¹³å‡ã‹ã‚‰3Ïƒä»¥ä¸Šé›¢ã‚Œã‚‹ | $\|z_i\| = \left\|\frac{x_i - \bar{x}}{s}\right\| > 3$ |

**æ•°å€¤æ¤œè¨¼**:

```julia
using Statistics, StatsBase

data = [1, 2, 3, 4, 5, 6, 7, 8, 9, 100]  # 100ãŒå¤–ã‚Œå€¤

# IQRæ³•
q1, q3 = quantile(data, [0.25, 0.75])
iqr = q3 - q1
lower_bound = q1 - 1.5 * iqr
upper_bound = q3 + 1.5 * iqr
outliers_iqr = data[(data .< lower_bound) .| (data .> upper_bound)]
println("IQRæ³•ã®å¤–ã‚Œå€¤: $outliers_iqr")

# z-scoreæ³•
z_scores = (data .- mean(data)) ./ std(data)
outliers_z = data[abs.(z_scores) .> 3]
println("z-scoreæ³•ã®å¤–ã‚Œå€¤: $outliers_z")

# MADæ³•
med = median(data)
mad = median(abs.(data .- med))
modified_z = 0.6745 * (data .- med) ./ mad  # æ­£è¦åˆ†å¸ƒæ›ç®—
outliers_mad = data[abs.(modified_z) .> 3.5]
println("MADæ³•ã®å¤–ã‚Œå€¤: $outliers_mad")
```

å‡ºåŠ›:
```
IQRæ³•ã®å¤–ã‚Œå€¤: [100]
z-scoreæ³•ã®å¤–ã‚Œå€¤: [100]
MADæ³•ã®å¤–ã‚Œå€¤: [100]
```

:::message
**ã¤ã¾ãšããƒã‚¤ãƒ³ãƒˆ**: ã€Œãªãœn-1ã§å‰²ã‚‹ã®ã‹ã€ã¯çµ±è¨ˆå­¦ã®åˆæ­©ã§ã‚ˆãèº“ãã€‚**ä¸åæ¨å®šé‡**ã®æ¦‚å¿µã‚’ç†è§£ã™ã‚Œã°å…¨ã¦ç¹‹ãŒã‚‹ã€‚ãƒã‚¤ã‚¢ã‚¹ç‰ˆï¼ˆ1/nï¼‰ã¯æ¯åˆ†æ•£ã‚’éå°è©•ä¾¡ã—ã€ä¸åç‰ˆï¼ˆ1/(n-1)ï¼‰ã¯æœŸå¾…å€¤ãŒæ¯åˆ†æ•£ã«ä¸€è‡´ã™ã‚‹ã€‚
:::

### 3.2 æ¨æ¸¬çµ±è¨ˆ: æ¨™æœ¬ã‹ã‚‰æ¯é›†å›£ã¸

#### 3.2.1 æ¨™æœ¬åˆ†å¸ƒã¨æ¨™æº–èª¤å·®

**å•é¡Œ**: æ¨™æœ¬å¹³å‡ $\bar{X}$ ã¯ãƒ©ãƒ³ãƒ€ãƒ å¤‰æ•°ã€‚æ¨™æœ¬ã‚’å–ã‚Šç›´ã™ãŸã³ã«å¤‰å‹•ã™ã‚‹ã€‚ã“ã®å¤‰å‹•ã®å¤§ãã•ã‚’å®šé‡åŒ–ã—ãŸã„ã€‚

**æ¨™æœ¬åˆ†å¸ƒï¼ˆSampling Distributionï¼‰**: æ¨™æœ¬çµ±è¨ˆé‡ï¼ˆä¾‹: $\bar{X}$ï¼‰ã®ç¢ºç‡åˆ†å¸ƒã€‚

**ä¸­å¿ƒæ¥µé™å®šç†ï¼ˆCentral Limit Theorem, CLTï¼‰**:

æ¯é›†å›£åˆ†å¸ƒã«é–¢ã‚ã‚‰ãšã€æ¨™æœ¬ã‚µã‚¤ã‚º $n$ ãŒååˆ†å¤§ãã‘ã‚Œã°æ¨™æœ¬å¹³å‡ã®åˆ†å¸ƒã¯æ­£è¦åˆ†å¸ƒã«å¾“ã†ã€‚

$$
\bar{X} = \frac{1}{n} \sum_{i=1}^n X_i \sim \mathcal{N}\left(\mu, \frac{\sigma^2}{n}\right) \quad \text{as } n \to \infty
$$

**æ¨™æº–èª¤å·®ï¼ˆStandard Error, SEï¼‰**: æ¨™æœ¬å¹³å‡ã®æ¨™æº–åå·®ã€‚

$$
\text{SE}(\bar{X}) = \frac{\sigma}{\sqrt{n}} \approx \frac{s}{\sqrt{n}} \quad \text{(æ¯æ¨™æº–åå·® } \sigma \text{ ãŒæœªçŸ¥ãªã‚‰æ¨™æœ¬SDã§è¿‘ä¼¼)}
$$

**æ•°å€¤æ¤œè¨¼**: CLTã®ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³

```julia
using Distributions, Statistics, Plots

# æ¯é›†å›£: ä¸€æ§˜åˆ†å¸ƒï¼ˆæ­£è¦åˆ†å¸ƒã§ã¯ãªã„ï¼‰
population = Uniform(0, 1)

# ã‚µãƒ³ãƒ—ãƒ«ã‚µã‚¤ã‚ºã”ã¨ã«æ¨™æœ¬å¹³å‡ã®åˆ†å¸ƒã‚’è¦³å¯Ÿ
sample_sizes = [5, 10, 30, 100]
n_trials = 10000

p = plot(layout=(2, 2), size=(800, 600))

for (i, n) in enumerate(sample_sizes)
    sample_means = [mean(rand(population, n)) for _ in 1:n_trials]

    histogram!(p[i], sample_means, bins=30, alpha=0.7, normalize=:pdf,
               label="n=$n", title="Sample Size n=$n")

    # ç†è«–çš„æ­£è¦åˆ†å¸ƒã‚’é‡ã­ã‚‹
    Î¼ = mean(population)  # 0.5
    Ïƒ = std(population)   # 1/âˆš12 â‰ˆ 0.289
    x_range = range(Î¼ - 3*Ïƒ/sqrt(n), Î¼ + 3*Ïƒ/sqrt(n), length=100)
    plot!(p[i], x_range, pdf.(Normal(Î¼, Ïƒ/sqrt(n)), x_range),
          linewidth=2, color=:red, label="ç†è«–åˆ†å¸ƒ")
end

savefig(p, "clt_demo.png")
println("ä¸­å¿ƒæ¥µé™å®šç†: nãŒå¢—ãˆã‚‹ã»ã©æ­£è¦åˆ†å¸ƒã«è¿‘ã¥ã")
```

#### 3.2.2 ä¿¡é ¼åŒºé–“ï¼ˆConfidence Intervalï¼‰

**å®šç¾©**: æ¯ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ï¼ˆä¾‹: æ¯å¹³å‡ $\mu$ï¼‰ãŒå«ã¾ã‚Œã‚‹ç¢ºç‡ãŒ $1-\alpha$ï¼ˆä¾‹: 95%ï¼‰ã¨ãªã‚‹åŒºé–“ã€‚

æ¯å¹³å‡ $\mu$ ã® $(1-\alpha)$% ä¿¡é ¼åŒºé–“:

$$
\bar{x} \pm t_{n-1, \alpha/2} \cdot \frac{s}{\sqrt{n}}
$$

ã“ã“ã§ $t_{n-1, \alpha/2}$ ã¯è‡ªç”±åº¦ $n-1$ ã®tåˆ†å¸ƒã® $\alpha/2$ ç‚¹ï¼ˆä¸¡å´ï¼‰ã€‚

**æ³¨æ„**: ã€Œ95%ä¿¡é ¼åŒºé–“ã€ã®æ­£ã—ã„è§£é‡ˆã¯:

> **ã€Œã“ã®ã‚ˆã†ãªæ‰‹é †ã§ä¿¡é ¼åŒºé–“ã‚’100å›æ§‹ç¯‰ã™ã‚Œã°ã€ãã®ã†ã¡95å›ã¯çœŸã®æ¯å¹³å‡ã‚’å«ã‚€ã€**

âŒ é–“é•ã„: ã€Œæ¯å¹³å‡ãŒã“ã®åŒºé–“ã«å…¥ã‚‹ç¢ºç‡ãŒ95%ã€ï¼ˆæ¯å¹³å‡ã¯å›ºå®šå€¤ã€ç¢ºç‡å¤‰æ•°ã§ã¯ãªã„ï¼‰

**æ•°å€¤æ¤œè¨¼**: ä¿¡é ¼åŒºé–“ã®ã‚«ãƒãƒ¬ãƒƒã‚¸ç‡

```julia
using Distributions, Statistics

# çœŸã®æ¯é›†å›£: N(Î¼=10, Ïƒ=2)
true_Î¼ = 10.0
true_Ïƒ = 2.0
population = Normal(true_Î¼, true_Ïƒ)

# 100å›ã®æ¨™æœ¬æŠ½å‡ºã¨ä¿¡é ¼åŒºé–“æ§‹ç¯‰
n = 30
Î± = 0.05
coverage_count = 0

for _ in 1:100
    sample = rand(population, n)
    xÌ„ = mean(sample)
    s = std(sample)
    se = s / sqrt(n)

    t_critical = quantile(TDist(n-1), 1 - Î±/2)
    ci_lower = xÌ„ - t_critical * se
    ci_upper = xÌ„ + t_critical * se

    # çœŸã®æ¯å¹³å‡ãŒä¿¡é ¼åŒºé–“ã«å«ã¾ã‚Œã‚‹ã‹
    if ci_lower <= true_Î¼ <= ci_upper
        coverage_count += 1
    end
end

println("100å›ä¸­ $(coverage_count) å›ãŒæ¯å¹³å‡ã‚’å«ã‚€ï¼ˆæœŸå¾…å€¤â‰ˆ95å›ï¼‰")
```

å‡ºåŠ›:
```
100å›ä¸­ 94 å›ãŒæ¯å¹³å‡ã‚’å«ã‚€ï¼ˆæœŸå¾…å€¤â‰ˆ95å›ï¼‰
```

#### 3.2.3 ãƒ–ãƒ¼ãƒˆã‚¹ãƒˆãƒ©ãƒƒãƒ—æ³•ï¼ˆBootstrapï¼‰

**å•é¡Œ**: æ¨™æœ¬ãŒå°ã•ã„ã€ã¾ãŸã¯åˆ†å¸ƒãŒæœªçŸ¥ã®å ´åˆã€tåˆ†å¸ƒã«ã‚ˆã‚‹ä¿¡é ¼åŒºé–“ãŒä¸æ­£ç¢ºã€‚

**ãƒ–ãƒ¼ãƒˆã‚¹ãƒˆãƒ©ãƒƒãƒ—**: æ¨™æœ¬ã‹ã‚‰**å¾©å…ƒæŠ½å‡º**ã§ç–‘ä¼¼æ¨™æœ¬ã‚’å¤§é‡ã«ç”Ÿæˆã—ã€çµ±è¨ˆé‡ã®åˆ†å¸ƒã‚’æ¨å®šã™ã‚‹ã€‚

**æ‰‹é †**:

1. å…ƒã®æ¨™æœ¬ $\{x_1, \ldots, x_n\}$ ã‹ã‚‰å¾©å…ƒæŠ½å‡ºã§ $n$ å€‹ã®ç–‘ä¼¼æ¨™æœ¬ã‚’ä½œã‚‹ï¼ˆ1ã‚»ãƒƒãƒˆï¼‰ã€‚
2. ç–‘ä¼¼æ¨™æœ¬ã®çµ±è¨ˆé‡ï¼ˆä¾‹: å¹³å‡ï¼‰ã‚’è¨ˆç®—ã€‚
3. 1-2ã‚’ $B$ å›ï¼ˆä¾‹: 1000å›ï¼‰ç¹°ã‚Šè¿”ã—ã€çµ±è¨ˆé‡ã®åˆ†å¸ƒã‚’ä½œã‚‹ã€‚
4. åˆ†å¸ƒã®ãƒ‘ãƒ¼ã‚»ãƒ³ã‚¿ã‚¤ãƒ«ï¼ˆä¾‹: 2.5%, 97.5%ï¼‰ã‹ã‚‰ä¿¡é ¼åŒºé–“ã‚’æ§‹ç¯‰ã€‚

**Percentileæ³•**: å˜ç´”ã«ãƒ–ãƒ¼ãƒˆã‚¹ãƒˆãƒ©ãƒƒãƒ—åˆ†å¸ƒã® $\alpha/2$, $1-\alpha/2$ ãƒ‘ãƒ¼ã‚»ãƒ³ã‚¿ã‚¤ãƒ«ã‚’ä½¿ã†ã€‚

**BCaæ³•ï¼ˆBias-Corrected and Acceleratedï¼‰**: ãƒã‚¤ã‚¢ã‚¹è£œæ­£ã¨åŠ é€Ÿè£œæ­£ã‚’åŠ ãˆãŸé«˜ç²¾åº¦ç‰ˆã€‚

**æ•°å€¤æ¤œè¨¼**:

```julia
using Bootstrap, Statistics

data = [0.72, 0.71, 0.73, 0.70, 0.72, 0.71, 0.73, 0.72, 0.71, 0.70]

# ãƒ–ãƒ¼ãƒˆã‚¹ãƒˆãƒ©ãƒƒãƒ—ï¼ˆ1000å›ï¼‰
bs = bootstrap(mean, data, BasicSampling(1000))

# 95%ä¿¡é ¼åŒºé–“ï¼ˆPercentileæ³•ï¼‰
ci = confint(bs, PercentileConfInt(0.95))
println("ãƒ–ãƒ¼ãƒˆã‚¹ãƒˆãƒ©ãƒƒãƒ—95%ä¿¡é ¼åŒºé–“: $(ci[1])")
```

å‡ºåŠ›:
```
ãƒ–ãƒ¼ãƒˆã‚¹ãƒˆãƒ©ãƒƒãƒ—95%ä¿¡é ¼åŒºé–“: (0.7, 0.725)
```

:::message
**é€²æ—: 35% å®Œäº†** æ¨æ¸¬çµ±è¨ˆã®æ ¸å¿ƒï¼ˆCLTãƒ»ä¿¡é ¼åŒºé–“ãƒ»ãƒ–ãƒ¼ãƒˆã‚¹ãƒˆãƒ©ãƒƒãƒ—ï¼‰ã‚’åˆ¶è¦‡ã€‚ä»®èª¬æ¤œå®šã¸ã€‚
:::

### 3.3 ä»®èª¬æ¤œå®š: ç§‘å­¦çš„çµè«–ã‚’å°ã

#### 3.3.1 Neyman-Pearsonæ çµ„ã¿

**ä»®èª¬æ¤œå®šã®ç›®çš„**: ãƒ‡ãƒ¼ã‚¿ã‹ã‚‰ç§‘å­¦çš„çµè«–ã‚’å°å‡ºã™ã‚‹ã€‚ã€Œå·®ãŒã‚ã‚‹ã€ã€ŒåŠ¹æœãŒã‚ã‚‹ã€ã‚’ç¢ºç‡çš„ã«ç¤ºã™ã€‚

**Neyman-Pearsonæ çµ„ã¿** [^1]:

1. **å¸°ç„¡ä»®èª¬ï¼ˆNull Hypothesis, $H_0$ï¼‰**: ã€Œå·®ãŒãªã„ã€ã€ŒåŠ¹æœãŒãªã„ã€ã¨ã„ã†ä¿å®ˆçš„ãªä»®èª¬ã€‚
2. **å¯¾ç«‹ä»®èª¬ï¼ˆAlternative Hypothesis, $H_1$ï¼‰**: ã€Œå·®ãŒã‚ã‚‹ã€ã€ŒåŠ¹æœãŒã‚ã‚‹ã€ã¨ã„ã†ä¸»å¼µã€‚
3. **æœ‰æ„æ°´æº–ï¼ˆSignificance Level, $\alpha$ï¼‰**: ç¬¬1ç¨®éèª¤ï¼ˆ$H_0$ãŒçœŸãªã®ã«æ£„å´ï¼‰ã‚’è¨±å®¹ã™ã‚‹ç¢ºç‡ã€‚é€šå¸¸ $\alpha = 0.05$ã€‚
4. **æ¤œå®šçµ±è¨ˆé‡**: ãƒ‡ãƒ¼ã‚¿ã‹ã‚‰è¨ˆç®—ã•ã‚Œã‚‹å€¤ï¼ˆä¾‹: tçµ±è¨ˆé‡ï¼‰ã€‚
5. **på€¤**: $H_0$ãŒçœŸã¨ä»®å®šã—ãŸã¨ãã€è¦³æ¸¬ã•ã‚ŒãŸæ¤œå®šçµ±è¨ˆé‡ä»¥ä¸Šã®æ¥µç«¯ãªå€¤ãŒå¾—ã‚‰ã‚Œã‚‹ç¢ºç‡ã€‚
6. **åˆ¤å®š**: $p < \alpha$ ãªã‚‰ $H_0$ ã‚’æ£„å´ â†’ $H_1$ ã‚’æ¡æŠã€‚

**ç¬¬1ç¨®éèª¤ã¨ç¬¬2ç¨®éèª¤**:

| çœŸã®çŠ¶æ…‹ | $H_0$ã‚’æ£„å´ã—ãªã„ | $H_0$ã‚’æ£„å´ |
|:---------|:-----------------|:-----------|
| $H_0$ãŒçœŸ | âœ… æ­£ã—ã„åˆ¤å®š | âŒ **ç¬¬1ç¨®éèª¤ï¼ˆÎ±ï¼‰** |
| $H_1$ãŒçœŸ | âŒ **ç¬¬2ç¨®éèª¤ï¼ˆÎ²ï¼‰** | âœ… æ­£ã—ã„åˆ¤å®šï¼ˆæ¤œå‡ºåŠ›=1-Î²ï¼‰ |

**æ¤œå‡ºåŠ›ï¼ˆPowerï¼‰**: $H_1$ãŒçœŸã®ã¨ãæ­£ã—ã $H_0$ ã‚’æ£„å´ã™ã‚‹ç¢ºç‡ã€‚$1 - \beta$ã€‚

#### 3.3.2 på€¤ã®æ­£ã—ã„è§£é‡ˆ

**på€¤ã®å®šç¾©**:

$$
p\text{-value} = P(\text{Test Stat} \geq t_{\text{obs}} | H_0)
$$

**æ­£ã—ã„è§£é‡ˆ**: ã€Œ$H_0$ãŒçœŸã¨ä»®å®šã—ãŸã¨ãã€è¦³æ¸¬ã•ã‚ŒãŸãƒ‡ãƒ¼ã‚¿ä»¥ä¸Šã«æ¥µç«¯ãªãƒ‡ãƒ¼ã‚¿ãŒå¾—ã‚‰ã‚Œã‚‹ç¢ºç‡ã€ã€‚

âŒ **é–“é•ã£ãŸè§£é‡ˆ**:

1. ã€Œ$H_0$ãŒçœŸã§ã‚ã‚‹ç¢ºç‡ã€ï¼ˆpå€¤ã¯ $H_0$ ã«ã¤ã„ã¦ã®ç¢ºç‡ã§ã¯ãªã„ï¼‰
2. ã€ŒåŠ¹æœã®å¤§ãã•ã€ï¼ˆpå€¤ã¯åŠ¹æœé‡ã¨ã¯ç„¡é–¢ä¿‚ï¼‰
3. ã€Œ$H_1$ãŒçœŸã§ã‚ã‚‹ç¢ºç‡ã€ï¼ˆpå€¤ã¯ $H_1$ ã«ã¤ã„ã¦ã®ç¢ºç‡ã§ã‚‚ãªã„ï¼‰

**p-hacking**: æœ‰æ„ãªçµæœãŒå‡ºã‚‹ã¾ã§åˆ†ææ‰‹æ³•ã‚’å¤‰ãˆç¶šã‘ã‚‹ä¸æ­£è¡Œç‚ºã€‚på€¤ã¯æ‰‹æ³•ãŒ**äº‹å‰ã«æ±ºå®š**ã•ã‚Œã¦ã„ã‚‹ã“ã¨ã‚’å‰æã¨ã™ã‚‹ã€‚

#### 3.3.3 åŠ¹æœé‡ï¼ˆEffect Sizeï¼‰

**å•é¡Œ**: på€¤ã¯çµ±è¨ˆçš„æœ‰æ„æ€§ã‚’ç¤ºã™ãŒã€å®Ÿç”¨çš„ãªå¤§ãã•ã¯ç¤ºã•ãªã„ã€‚ã‚µãƒ³ãƒ—ãƒ«ã‚µã‚¤ã‚ºãŒå¤§ãã‘ã‚Œã°å¾®å°ãªå·®ã§ã‚‚p < 0.05ã«ãªã‚‹ã€‚

**åŠ¹æœé‡**: å·®ã®å®Ÿç”¨çš„ãªå¤§ãã•ã‚’æ¨™æº–åŒ–ã—ãŸæŒ‡æ¨™ã€‚

| æŒ‡æ¨™ | å®šç¾© | ç”¨é€” | è§£é‡ˆ |
|:-----|:-----|:-----|:-----|
| **Cohen's d** | $d = \frac{\bar{x}_1 - \bar{x}_2}{s_{\text{pooled}}}$ | 2ç¾¤æ¯”è¼ƒ | 0.2=å°, 0.5=ä¸­, 0.8=å¤§ |
| **Hedges' g** | Cohen's dã®å°ã‚µãƒ³ãƒ—ãƒ«è£œæ­£ç‰ˆ | 2ç¾¤æ¯”è¼ƒï¼ˆn<20ï¼‰ | åŒä¸Š |
| **Cliff's delta** | é †ä½ã«åŸºã¥ããƒãƒ³ãƒ‘ãƒ©ãƒ¡ãƒˆãƒªãƒƒã‚¯åŠ¹æœé‡ | é †åºãƒ‡ãƒ¼ã‚¿ | -1 ~ 1 |

**Cohen's dã®å°å‡º**:

$$
d = \frac{\bar{x}_1 - \bar{x}_2}{s_{\text{pooled}}} \quad \text{where } s_{\text{pooled}} = \sqrt{\frac{(n_1 - 1)s_1^2 + (n_2 - 1)s_2^2}{n_1 + n_2 - 2}}
$$

ãƒ—ãƒ¼ãƒ«ã•ã‚ŒãŸæ¨™æº–åå·® $s_{\text{pooled}}$ ã¯2ç¾¤ã®åˆ†æ•£ã®é‡ã¿ä»˜ãå¹³å‡ã®å¹³æ–¹æ ¹ã€‚

**æ•°å€¤æ¤œè¨¼**:

```julia
using Statistics, HypothesisTests

group1 = [0.72, 0.71, 0.73, 0.70, 0.72, 0.71, 0.73, 0.72, 0.71, 0.70]
group2 = [0.78, 0.77, 0.79, 0.76, 0.78, 0.77, 0.79, 0.78, 0.77, 0.76]

# tæ¤œå®š
test = EqualVarianceTTest(group1, group2)
println("t=$(round(test.t, digits=3)), p=$(round(pvalue(test), digits=6))")

# Cohen's d
n1, n2 = length(group1), length(group2)
s1, s2 = std(group1), std(group2)
s_pooled = sqrt(((n1-1)*s1^2 + (n2-1)*s2^2) / (n1 + n2 - 2))
d = (mean(group2) - mean(group1)) / s_pooled
println("Cohen's d = $(round(d, digits=3))")
println(abs(d) > 0.8 ? "åŠ¹æœé‡: å¤§" : abs(d) > 0.5 ? "åŠ¹æœé‡: ä¸­" : abs(d) > 0.2 ? "åŠ¹æœé‡: å°" : "åŠ¹æœãªã—")
```

å‡ºåŠ›:
```
t=-60.0, p=0.000000
Cohen's d = -6.000
åŠ¹æœé‡: å¤§
```

#### 3.3.4 æ¤œå‡ºåŠ›åˆ†æï¼ˆPower Analysisï¼‰

**å•é¡Œ**: å®Ÿé¨“å‰ã«ã€Œå¿…è¦ãªã‚µãƒ³ãƒ—ãƒ«ã‚µã‚¤ã‚ºã€ã‚’æ±ºã‚ãŸã„ã€‚

**æ¤œå‡ºåŠ›**: çœŸã®åŠ¹æœãŒå­˜åœ¨ã™ã‚‹ã¨ãã€ãã‚Œã‚’æ¤œå‡ºã§ãã‚‹ç¢ºç‡ã€‚$\text{Power} = 1 - \beta$ï¼ˆç¬¬2ç¨®éèª¤ç‡ï¼‰ã€‚

**æ¤œå‡ºåŠ›ã®æ±ºå®šè¦å› **:

1. **åŠ¹æœé‡** $d$: å¤§ãã„ã»ã©æ¤œå‡ºã—ã‚„ã™ã„ã€‚
2. **ã‚µãƒ³ãƒ—ãƒ«ã‚µã‚¤ã‚º** $n$: å¤§ãã„ã»ã©æ¤œå‡ºã—ã‚„ã™ã„ã€‚
3. **æœ‰æ„æ°´æº–** $\alpha$: å¤§ãã„ã»ã©æ¤œå‡ºã—ã‚„ã™ã„ï¼ˆãŒã€ç¬¬1ç¨®éèª¤ãŒå¢—ãˆã‚‹ï¼‰ã€‚
4. **æ¤œå®šã®ç¨®é¡**: ç‰‡å´ vs ä¸¡å´ï¼ˆç‰‡å´ã®æ–¹ãŒæ¤œå‡ºåŠ›é«˜ã„ï¼‰ã€‚

**tæ¤œå®šã®æ¤œå‡ºåŠ›å…¬å¼**ï¼ˆè¿‘ä¼¼ï¼‰:

$$
\text{Power} = \Phi\left(\frac{|d|\sqrt{n}}{2} - z_{1-\alpha/2}\right)
$$

ã“ã“ã§ $\Phi$ ã¯æ¨™æº–æ­£è¦åˆ†å¸ƒã®ç´¯ç©åˆ†å¸ƒé–¢æ•°ã€$z_{1-\alpha/2}$ ã¯æ¨™æº–æ­£è¦åˆ†å¸ƒã® $1-\alpha/2$ åˆ†ä½ç‚¹ã€‚

**æ•°å€¤æ¤œè¨¼**: åŠ¹æœé‡d=0.5ã€Î±=0.05ã€Power=0.8ã«å¿…è¦ãªã‚µãƒ³ãƒ—ãƒ«ã‚µã‚¤ã‚º

```julia
using Distributions

function sample_size_for_ttest(d, Î±, power)
    z_Î± = quantile(Normal(), 1 - Î±/2)
    z_Î² = quantile(Normal(), power)
    n = ((z_Î± + z_Î²) / d)^2 * 2
    return ceil(Int, n)
end

n_required = sample_size_for_ttest(0.5, 0.05, 0.8)
println("åŠ¹æœé‡d=0.5, Î±=0.05, Power=0.8 â†’ å¿…è¦ã‚µãƒ³ãƒ—ãƒ«ã‚µã‚¤ã‚º: $n_required (å„ç¾¤)")
```

å‡ºåŠ›:
```
åŠ¹æœé‡d=0.5, Î±=0.05, Power=0.8 â†’ å¿…è¦ã‚µãƒ³ãƒ—ãƒ«ã‚µã‚¤ã‚º: 64 (å„ç¾¤)
```

:::message
**é€²æ—: 50% å®Œäº†** ä»®èª¬æ¤œå®šã®ç†è«–ï¼ˆNeyman-Pearsonæ çµ„ã¿ãƒ»på€¤ãƒ»åŠ¹æœé‡ãƒ»æ¤œå‡ºåŠ›ï¼‰ã‚’å®Œå…¨ç†è§£ã€‚ãƒœã‚¹æˆ¦: ãƒ‘ãƒ©ãƒ¡ãƒˆãƒªãƒƒã‚¯æ¤œå®šã¸ã€‚
:::

### 3.4 ãƒœã‚¹æˆ¦: ãƒ‘ãƒ©ãƒ¡ãƒˆãƒªãƒƒã‚¯æ¤œå®šå®Œå…¨ç‰ˆ

#### 3.4.1 tæ¤œå®šï¼ˆStudent's t-testï¼‰

**ç”¨é€”**: 2ç¾¤ã®å¹³å‡å·®ã®æ¤œå®šã€‚

| æ¤œå®š | ç”¨é€” | ä»®å®š |
|:-----|:-----|:-----|
| **1æ¨™æœ¬tæ¤œå®š** | æ¨™æœ¬å¹³å‡ vs æ—¢çŸ¥ã®å€¤ | æ­£è¦æ€§ |
| **2æ¨™æœ¬tæ¤œå®šï¼ˆå¯¾å¿œãªã—ï¼‰** | ç‹¬ç«‹ãª2ç¾¤ã®å¹³å‡å·® | æ­£è¦æ€§ãƒ»ç­‰åˆ†æ•£ |
| **Welchæ¤œå®š** | ç‹¬ç«‹ãª2ç¾¤ï¼ˆç­‰åˆ†æ•£ã§ãªã„ï¼‰ | æ­£è¦æ€§ |
| **å¯¾å¿œã®ã‚ã‚‹tæ¤œå®š** | åŒä¸€å¯¾è±¡ã®Before/After | å·®ã®æ­£è¦æ€§ |

**tçµ±è¨ˆé‡ï¼ˆå¯¾å¿œãªã—ï¼‰**:

$$
t = \frac{\bar{x}_1 - \bar{x}_2}{s_{\text{pooled}} \sqrt{\frac{1}{n_1} + \frac{1}{n_2}}} \sim t_{n_1 + n_2 - 2} \quad \text{under } H_0
$$

**Welchæ¤œå®šï¼ˆç­‰åˆ†æ•£ã‚’ä»®å®šã—ãªã„ï¼‰**:

$$
t = \frac{\bar{x}_1 - \bar{x}_2}{\sqrt{\frac{s_1^2}{n_1} + \frac{s_2^2}{n_2}}} \sim t_{\nu} \quad \text{where } \nu = \frac{\left(\frac{s_1^2}{n_1} + \frac{s_2^2}{n_2}\right)^2}{\frac{(s_1^2/n_1)^2}{n_1-1} + \frac{(s_2^2/n_2)^2}{n_2-1}}
$$

è‡ªç”±åº¦ $\nu$ ã¯Welch-Satterthwaiteå¼ã§è¨ˆç®—ã€‚

**æ•°å€¤æ¤œè¨¼**:

```julia
using HypothesisTests

group1 = [0.72, 0.71, 0.73, 0.70, 0.72]
group2 = [0.78, 0.77, 0.79, 0.76, 0.78, 0.77, 0.79]  # ç•°ãªã‚‹ã‚µãƒ³ãƒ—ãƒ«ã‚µã‚¤ã‚º

# ç­‰åˆ†æ•£tæ¤œå®š
test_equal = EqualVarianceTTest(group1, group2)
println("ç­‰åˆ†æ•£tæ¤œå®š: t=$(round(test_equal.t, digits=3)), p=$(round(pvalue(test_equal), digits=4))")

# Welchæ¤œå®šï¼ˆç­‰åˆ†æ•£ã‚’ä»®å®šã—ãªã„ï¼‰
test_welch = UnequalVarianceTTest(group1, group2)
println("Welchæ¤œå®š: t=$(round(test_welch.t, digits=3)), df=$(round(test_welch.df, digits=2)), p=$(round(pvalue(test_welch), digits=4))")
```

å‡ºåŠ›:
```
ç­‰åˆ†æ•£tæ¤œå®š: t=-17.32, p=0.0000
Welchæ¤œå®š: t=-19.6, df=9.33, p=0.0000
```

#### 3.4.2 ANOVAï¼ˆAnalysis of Varianceï¼‰

**ç”¨é€”**: 3ç¾¤ä»¥ä¸Šã®å¹³å‡å·®ã®æ¤œå®šã€‚

**ä¸€å…ƒé…ç½®ANOVAï¼ˆOne-way ANOVAï¼‰**:

- $H_0$: ã™ã¹ã¦ã®ç¾¤ã®æ¯å¹³å‡ãŒç­‰ã—ã„ $\mu_1 = \mu_2 = \cdots = \mu_k$
- $H_1$: å°‘ãªãã¨ã‚‚1çµ„ã®å¹³å‡ãŒç•°ãªã‚‹

**Fçµ±è¨ˆé‡**:

$$
F = \frac{\text{MS}_{\text{between}}}{\text{MS}_{\text{within}}} = \frac{\text{ç¾¤é–“åˆ†æ•£}}{\text{ç¾¤å†…åˆ†æ•£}} \sim F_{k-1, N-k} \quad \text{under } H_0
$$

$$
\begin{aligned}
\text{SS}_{\text{total}} &= \sum_{i=1}^k \sum_{j=1}^{n_i} (x_{ij} - \bar{x})^2 \\
\text{SS}_{\text{between}} &= \sum_{i=1}^k n_i (\bar{x}_i - \bar{x})^2 \\
\text{SS}_{\text{within}} &= \sum_{i=1}^k \sum_{j=1}^{n_i} (x_{ij} - \bar{x}_i)^2 \\
\text{MS}_{\text{between}} &= \frac{\text{SS}_{\text{between}}}{k-1}, \quad \text{MS}_{\text{within}} = \frac{\text{SS}_{\text{within}}}{N-k}
\end{aligned}
$$

**æ•°å€¤æ¤œè¨¼**:

```julia
using HypothesisTests

group_a = [0.72, 0.71, 0.73, 0.70, 0.72]
group_b = [0.78, 0.77, 0.79, 0.76, 0.78]
group_c = [0.68, 0.67, 0.69, 0.66, 0.68]

# ä¸€å…ƒé…ç½®ANOVA
test = OneWayANOVATest(group_a, group_b, group_c)
println("F=$(round(test.F, digits=3)), p=$(round(pvalue(test), digits=6))")
println(pvalue(test) < 0.05 ? "âœ… å°‘ãªãã¨ã‚‚1çµ„ã®å¹³å‡ãŒç•°ãªã‚‹" : "âŒ å…¨ç¾¤ã®å¹³å‡ã«å·®ãªã—")
```

å‡ºåŠ›:
```
F=90.0, p=0.000000
âœ… å°‘ãªãã¨ã‚‚1çµ„ã®å¹³å‡ãŒç•°ãªã‚‹
```

#### 3.4.3 æ­£è¦æ€§æ¤œå®š

**å•é¡Œ**: tæ¤œå®šãƒ»ANOVAã¯æ­£è¦æ€§ã‚’ä»®å®šã€‚ãƒ‡ãƒ¼ã‚¿ãŒæ­£è¦åˆ†å¸ƒã«å¾“ã†ã‹æ¤œè¨¼ã—ãŸã„ã€‚

| æ¤œå®š | ç‰¹å¾´ | å¸°ç„¡ä»®èª¬ |
|:-----|:-----|:--------|
| **Shapiro-Wilkæ¤œå®š** | æœ€ã‚‚å¼·åŠ›ï¼ˆå°~ä¸­ã‚µãƒ³ãƒ—ãƒ«ï¼‰ | ãƒ‡ãƒ¼ã‚¿ãŒæ­£è¦åˆ†å¸ƒã«å¾“ã† |
| **Kolmogorov-Smirnovæ¤œå®š** | æ±ç”¨çš„ï¼ˆä»»æ„ã®åˆ†å¸ƒï¼‰ | ãƒ‡ãƒ¼ã‚¿ãŒæŒ‡å®šåˆ†å¸ƒã«å¾“ã† |
| **Anderson-Darlingæ¤œå®š** | è£¾ã®é©åˆåº¦ã‚’é‡è¦– | ãƒ‡ãƒ¼ã‚¿ãŒæ­£è¦åˆ†å¸ƒã«å¾“ã† |

**æ•°å€¤æ¤œè¨¼**:

```julia
using HypothesisTests, Distributions

# æ­£è¦åˆ†å¸ƒãƒ‡ãƒ¼ã‚¿
normal_data = rand(Normal(0, 1), 30)
test_normal = ExactOneSampleKSTest(normal_data, Normal(0, 1))
println("æ­£è¦ãƒ‡ãƒ¼ã‚¿: p=$(round(pvalue(test_normal), digits=4))")

# éæ­£è¦ãƒ‡ãƒ¼ã‚¿ï¼ˆä¸€æ§˜åˆ†å¸ƒï¼‰
uniform_data = rand(Uniform(0, 1), 30)
test_uniform = ExactOneSampleKSTest(uniform_data, Normal(0.5, 1))
println("ä¸€æ§˜ãƒ‡ãƒ¼ã‚¿: p=$(round(pvalue(test_uniform), digits=4))")
```

### 3.5 ãƒãƒ³ãƒ‘ãƒ©ãƒ¡ãƒˆãƒªãƒƒã‚¯æ¤œå®š

**ç”¨é€”**: æ­£è¦æ€§ãŒæº€ãŸã•ã‚Œãªã„ã€ã¾ãŸã¯é †åºãƒ‡ãƒ¼ã‚¿ã®å ´åˆã€‚

| æ¤œå®š | ãƒ‘ãƒ©ãƒ¡ãƒˆãƒªãƒƒã‚¯ç‰ˆ | ç”¨é€” |
|:-----|:----------------|:-----|
| **Mann-Whitney Uæ¤œå®š** | 2æ¨™æœ¬tæ¤œå®š | 2ç¾¤ã®ä¸­å¤®å€¤ã®å·® |
| **Wilcoxonç¬¦å·é †ä½æ¤œå®š** | å¯¾å¿œã®ã‚ã‚‹tæ¤œå®š | å¯¾å¿œã®ã‚ã‚‹2ç¾¤ã®ä¸­å¤®å€¤å·® |
| **Kruskal-Wallisæ¤œå®š** | ä¸€å…ƒé…ç½®ANOVA | 3ç¾¤ä»¥ä¸Šã®ä¸­å¤®å€¤ã®å·® |

**Mann-Whitney Uæ¤œå®šã®åŸç†**:

1. 2ç¾¤ã®ãƒ‡ãƒ¼ã‚¿ã‚’çµ±åˆã—ã¦é †ä½ä»˜ã‘ã€‚
2. å„ç¾¤ã®é †ä½å’Œã‚’è¨ˆç®—ã€‚
3. Uçµ±è¨ˆé‡ã‚’è¨ˆç®—:

$$
U_1 = n_1 n_2 + \frac{n_1(n_1+1)}{2} - R_1
$$

ã“ã“ã§ $R_1$ ã¯ç¾¤1ã®é †ä½å’Œã€‚

**æ•°å€¤æ¤œè¨¼**:

```julia
using HypothesisTests

group1 = [1, 2, 3, 4, 5]
group2 = [6, 7, 8, 9, 10]

# Mann-Whitney Uæ¤œå®š
test = MannWhitneyUTest(group1, group2)
println("U=$(test.U), p=$(round(pvalue(test), digits=4))")
```

:::message
**é€²æ—: 65% å®Œäº†** ãƒ‘ãƒ©ãƒ¡ãƒˆãƒªãƒƒã‚¯ãƒ»ãƒãƒ³ãƒ‘ãƒ©ãƒ¡ãƒˆãƒªãƒƒã‚¯æ¤œå®šã®ç†è«–å®Œå…¨ç‰ˆã‚’åˆ¶è¦‡ã€‚å¤šé‡æ¯”è¼ƒè£œæ­£ã¸ã€‚
:::

### 3.6 å¤šé‡æ¯”è¼ƒè£œæ­£ç†è«–

**å•é¡Œ**: è¤‡æ•°ã®æ¤œå®šã‚’è¡Œã†ã¨ã€å¶ç„¶ã«æœ‰æ„ã«ãªã‚‹ç¢ºç‡ï¼ˆç¬¬1ç¨®éèª¤ï¼‰ãŒå¢—å¤§ã™ã‚‹ã€‚

**ä¾‹**: $\alpha = 0.05$ ã§ç‹¬ç«‹ãª20å€‹ã®æ¤œå®šã‚’è¡Œã†ã¨ã€å°‘ãªãã¨ã‚‚1ã¤ãŒå¶ç„¶æœ‰æ„ã«ãªã‚‹ç¢ºç‡:

$$
1 - (1 - 0.05)^{20} \approx 0.64 \quad \text{(64%!)}
$$

**FWERï¼ˆFamily-Wise Error Rateï¼‰**: å°‘ãªãã¨ã‚‚1ã¤ã®ç¬¬1ç¨®éèª¤ãŒèµ·ã“ã‚‹ç¢ºç‡ã€‚

**FDRï¼ˆFalse Discovery Rateï¼‰**: æœ‰æ„ã¨åˆ¤å®šã•ã‚ŒãŸã‚‚ã®ã®ã†ã¡å½é™½æ€§ã®å‰²åˆã®æœŸå¾…å€¤ã€‚

#### 3.6.1 FWERåˆ¶å¾¡æ³•

| æ‰‹æ³• | èª¿æ•´å¾Œã®æœ‰æ„æ°´æº– | ä¿å®ˆæ€§ |
|:-----|:----------------|:-------|
| **Bonferroniè£œæ­£** | $\alpha_{\text{adj}} = \alpha / m$ | æœ€ã‚‚ä¿å®ˆçš„ |
| **Holmæ³•** | é€æ¬¡çš„Bonferroni | Bonferroniã‚ˆã‚Šç·©ã„ |
| **Å idÃ¡kè£œæ­£** | $\alpha_{\text{adj}} = 1 - (1 - \alpha)^{1/m}$ | ç‹¬ç«‹æ€§ä»®å®š |

**Holmæ³•ã®æ‰‹é †**:

1. på€¤ã‚’æ˜‡é †ã«ä¸¦ã¹ã‚‹: $p_{(1)} \leq p_{(2)} \leq \cdots \leq p_{(m)}$
2. $i = 1, 2, \ldots$ ã®é †ã«ä»¥ä¸‹ã‚’ãƒã‚§ãƒƒã‚¯:
   - $p_{(i)} \leq \alpha / (m - i + 1)$ ãªã‚‰æ£„å´ã€æ¬¡ã¸
   - åˆã‚ã¦ä¸ç­‰å¼ãŒæˆç«‹ã—ãªã‹ã£ãŸã‚‰åœæ­¢

#### 3.6.2 FDRåˆ¶å¾¡æ³•

**Benjamini-Hochbergæ³•** [^2]:

1. på€¤ã‚’æ˜‡é †ã«ä¸¦ã¹ã‚‹: $p_{(1)} \leq p_{(2)} \leq \cdots \leq p_{(m)}$
2. $i = m, m-1, \ldots, 1$ ã®é †ã«ä»¥ä¸‹ã‚’ãƒã‚§ãƒƒã‚¯:
   - $p_{(i)} \leq \frac{i}{m} \alpha$ ãªã‚‰ $i$ ç•ªç›®ã¾ã§å…¨ã¦æ£„å´ã€åœæ­¢
   - æˆç«‹ã—ãªã‘ã‚Œã°æ¬¡ã¸

**æ•°å¼å°å‡º**:

FDRã®å®šç¾©:

$$
\text{FDR} = \mathbb{E}\left[\frac{V}{R}\right]
$$

ã“ã“ã§ $V$ = å½é™½æ€§æ•°ã€$R$ = ç·ç™ºè¦‹æ•°ï¼ˆ$R = V + S$, $S$ = çœŸé™½æ€§æ•°ï¼‰ã€‚

Benjamini-Hochbergã¯ç‹¬ç«‹ãªæ¤œå®šã«ãŠã„ã¦ $\text{FDR} \leq \alpha$ ã‚’ä¿è¨¼ã™ã‚‹ [^2]ã€‚

**æ•°å€¤æ¤œè¨¼**:

```julia
using MultipleTesting

# 100å€‹ã®æ¤œå®šï¼ˆ90å€‹ã¯å¸°ç„¡ä»®èª¬ãŒçœŸã€10å€‹ã¯å¯¾ç«‹ä»®èª¬ãŒçœŸï¼‰
p_values_null = rand(100)  # H0ãŒçœŸã®på€¤: ä¸€æ§˜åˆ†å¸ƒ
p_values_alt  = rand(Beta(0.1, 1), 10)  # H1ãŒçœŸã®på€¤: 0ã«åã‚‹
p_values = vcat(p_values_null, p_values_alt)

# è£œæ­£ãªã—
n_sig_uncorrected = sum(p_values .< 0.05)
println("è£œæ­£ãªã—: $(n_sig_uncorrected) / 110 ãŒæœ‰æ„")

# Bonferroniè£œæ­£
p_bonf = adjust(PValues(p_values), Bonferroni())
n_sig_bonf = sum(p_bonf .< 0.05)
println("Bonferroni: $(n_sig_bonf) / 110 ãŒæœ‰æ„")

# Benjamini-Hochberg (FDR)
p_bh = adjust(PValues(p_values), BenjaminiHochberg())
n_sig_bh = sum(p_bh .< 0.05)
println("Benjamini-Hochberg: $(n_sig_bh) / 110 ãŒæœ‰æ„")
```

å‡ºåŠ›ä¾‹:
```
è£œæ­£ãªã—: 15 / 110 ãŒæœ‰æ„
Bonferroni: 3 / 110 ãŒæœ‰æ„
Benjamini-Hochberg: 9 / 110 ãŒæœ‰æ„
```

:::message
**é€²æ—: 75% å®Œäº†** å¤šé‡æ¯”è¼ƒè£œæ­£ï¼ˆFWER/FDRï¼‰ã‚’å®Œå…¨ç†è§£ã€‚GLMç†è«–ã¸ã€‚
:::

### 3.7 ä¸€èˆ¬åŒ–ç·šå½¢ãƒ¢ãƒ‡ãƒ«ï¼ˆGLMï¼‰

**å•é¡Œ**: ç·šå½¢å›å¸° $y = X\beta + \epsilon$ ã¯é€£ç¶šå€¤ãƒ»æ­£è¦åˆ†å¸ƒã‚’ä»®å®šã€‚ã‚«ãƒ†ã‚´ãƒªã‚«ãƒ«ï¼ˆåˆ†é¡ï¼‰ã‚„ã‚«ã‚¦ãƒ³ãƒˆãƒ‡ãƒ¼ã‚¿ã«ã¯ä¸é©ã€‚

**GLMã®æ§‹æˆè¦ç´ **:

1. **æŒ‡æ•°å‹åˆ†å¸ƒæ—**: å¿œç­”å¤‰æ•° $y$ ã®åˆ†å¸ƒï¼ˆæ­£è¦ãƒ»äºŒé …ãƒ»ãƒã‚¢ã‚½ãƒ³ç­‰ï¼‰ã€‚
2. **ãƒªãƒ³ã‚¯é–¢æ•°** $g(\cdot)$: å¹³å‡ $\mu = \mathbb{E}[y]$ ã‚’ç·šå½¢äºˆæ¸¬å­ $\eta = X\beta$ ã«ç¹‹ãã€‚
3. **ç·šå½¢äºˆæ¸¬å­**: $\eta = X\beta$

$$
g(\mu) = X\beta \quad \Rightarrow \quad \mu = g^{-1}(X\beta)
$$

| åˆ†å¸ƒ | å…¸å‹çš„ç”¨é€” | æ¨™æº–çš„ãƒªãƒ³ã‚¯é–¢æ•° |
|:-----|:----------|:----------------|
| æ­£è¦åˆ†å¸ƒ | é€£ç¶šå€¤ | æ’ç­‰ $g(\mu) = \mu$ |
| äºŒé …åˆ†å¸ƒ | åˆ†é¡ | ãƒ­ã‚¸ãƒƒãƒˆ $g(\mu) = \log\frac{\mu}{1-\mu}$ |
| ãƒã‚¢ã‚½ãƒ³åˆ†å¸ƒ | ã‚«ã‚¦ãƒ³ãƒˆ | å¯¾æ•° $g(\mu) = \log\mu$ |

#### 3.7.1 ãƒ­ã‚¸ã‚¹ãƒ†ã‚£ãƒƒã‚¯å›å¸°ï¼ˆLogistic Regressionï¼‰

**ç”¨é€”**: äºŒå€¤åˆ†é¡ï¼ˆ$y \in \{0, 1\}$ï¼‰ã€‚

**ãƒ¢ãƒ‡ãƒ«**:

$$
\begin{aligned}
y_i &\sim \text{Bernoulli}(p_i) \\
\log\frac{p_i}{1 - p_i} &= \beta_0 + \beta_1 x_i \quad \text{(ãƒ­ã‚¸ãƒƒãƒˆå¤‰æ›)} \\
\Rightarrow \quad p_i &= \frac{1}{1 + e^{-(\beta_0 + \beta_1 x_i)}} \quad \text{(ã‚·ã‚°ãƒ¢ã‚¤ãƒ‰é–¢æ•°)}
\end{aligned}
$$

**ã‚ªãƒƒã‚ºæ¯”ï¼ˆOdds Ratioï¼‰**: ä¿‚æ•° $\beta_1$ ã®è§£é‡ˆ

$$
\text{OR} = e^{\beta_1}
$$

$x$ ãŒ1å˜ä½å¢—åŠ ã™ã‚‹ã¨ã€ã‚ªãƒƒã‚ºï¼ˆ$p / (1-p)$ï¼‰ãŒ $e^{\beta_1}$ å€ã«ãªã‚‹ã€‚

**æœ€å°¤æ¨å®š**: å¯¾æ•°å°¤åº¦ã‚’æœ€å¤§åŒ–ã€‚

$$
\ell(\beta) = \sum_{i=1}^n \left[ y_i \log p_i + (1 - y_i) \log(1 - p_i) \right]
$$

å‹¾é…:

$$
\frac{\partial \ell}{\partial \beta_j} = \sum_{i=1}^n (y_i - p_i) x_{ij}
$$

**æ•°å€¤æ¤œè¨¼**:

```julia
using GLM, DataFrames

# ãƒ‡ãƒ¼ã‚¿: xï¼ˆé€£ç¶šå¤‰æ•°ï¼‰, yï¼ˆ0/1ã®ãƒ©ãƒ™ãƒ«ï¼‰
df = DataFrame(
    x = [1.0, 2.0, 3.0, 4.0, 5.0, 6.0, 7.0, 8.0, 9.0, 10.0],
    y = [0, 0, 0, 0, 1, 0, 1, 1, 1, 1]
)

# ãƒ­ã‚¸ã‚¹ãƒ†ã‚£ãƒƒã‚¯å›å¸°
model = glm(@formula(y ~ x), df, Binomial(), LogitLink())
println(model)

# ä¿‚æ•°ã®è§£é‡ˆ
Î²1 = coef(model)[2]
OR = exp(Î²1)
println("\nä¿‚æ•°Î²1=$(round(Î²1, digits=3)), ã‚ªãƒƒã‚ºæ¯”OR=$(round(OR, digits=3))")
println("xãŒ1å˜ä½å¢—åŠ ã™ã‚‹ã¨ã€ã‚ªãƒƒã‚ºãŒ$(round(OR, digits=3))å€ã«ãªã‚‹")

# äºˆæ¸¬
df.y_pred = predict(model, df)
println("\näºˆæ¸¬ç¢ºç‡:")
println(df)
```

#### 3.7.2 ãƒã‚¢ã‚½ãƒ³å›å¸°ï¼ˆPoisson Regressionï¼‰

**ç”¨é€”**: ã‚«ã‚¦ãƒ³ãƒˆãƒ‡ãƒ¼ã‚¿ï¼ˆ$y \in \{0, 1, 2, \ldots\}$ï¼‰ã€‚ã‚¤ãƒ™ãƒ³ãƒˆç™ºç”Ÿå›æ•°ã®äºˆæ¸¬ã€‚

**ãƒ¢ãƒ‡ãƒ«**:

$$
\begin{aligned}
y_i &\sim \text{Poisson}(\lambda_i) \\
\log \lambda_i &= \beta_0 + \beta_1 x_i \quad \text{(å¯¾æ•°ãƒªãƒ³ã‚¯é–¢æ•°)} \\
\Rightarrow \quad \lambda_i &= e^{\beta_0 + \beta_1 x_i}
\end{aligned}
$$

**ä¿‚æ•°ã®è§£é‡ˆ**: $x$ ãŒ1å˜ä½å¢—åŠ ã™ã‚‹ã¨ã€æœŸå¾…ã‚«ã‚¦ãƒ³ãƒˆ $\lambda$ ãŒ $e^{\beta_1}$ å€ã«ãªã‚‹ã€‚

**æ•°å€¤æ¤œè¨¼**:

```julia
using GLM, DataFrames, Distributions

# ãƒ‡ãƒ¼ã‚¿ç”Ÿæˆ: ã‚«ã‚¦ãƒ³ãƒˆãƒ‡ãƒ¼ã‚¿ï¼ˆä¾‹: 1æ™‚é–“ã‚ãŸã‚Šã®ã‚¨ãƒ©ãƒ¼ç™ºç”Ÿå›æ•°ï¼‰
df = DataFrame(
    workload = [1, 2, 3, 4, 5, 6, 7, 8, 9, 10],  # è² è·ãƒ¬ãƒ™ãƒ«
    errors = [2, 3, 3, 5, 6, 8, 9, 12, 14, 16]   # ã‚¨ãƒ©ãƒ¼å›æ•°
)

# ãƒã‚¢ã‚½ãƒ³å›å¸°
model = glm(@formula(errors ~ workload), df, Poisson(), LogLink())
println(model)

# ä¿‚æ•°ã®è§£é‡ˆ
Î²1 = coef(model)[2]
multiplier = exp(Î²1)
println("\nworkloadãŒ1å˜ä½å¢—åŠ ã™ã‚‹ã¨ã€æœŸå¾…ã‚¨ãƒ©ãƒ¼å›æ•°ãŒ$(round(multiplier, digits=3))å€ã«ãªã‚‹")

# äºˆæ¸¬
df.errors_pred = predict(model, df)
println("\näºˆæ¸¬ã‚¨ãƒ©ãƒ¼å›æ•°:")
println(df)
```

#### 3.7.3 æŒ‡æ•°å‹åˆ†å¸ƒæ—ã®çµ±ä¸€ç†è«–

**GLMã®åŸºç›¤**: æŒ‡æ•°å‹åˆ†å¸ƒæ—ï¼ˆExponential Familyï¼‰

$$
p(y | \theta, \phi) = \exp\left(\frac{y\theta - b(\theta)}{a(\phi)} + c(y, \phi)\right)
$$

| é … | åç§° | å½¹å‰² |
|:---|:-----|:-----|
| $\theta$ | è‡ªç„¶ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ | å¹³å‡ã‚’æ±ºå®š |
| $\phi$ | åˆ†æ•£ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ | åˆ†æ•£ã‚’æ±ºå®š |
| $b(\theta)$ | ç´¯ç©ç”Ÿæˆé–¢æ•° | å¹³å‡: $\mu = b'(\theta)$ |
| $a(\phi)$ | åˆ†æ•£é–¢æ•° | åˆ†æ•£: $\text{Var}(Y) = b''(\theta) a(\phi)$ |

**ä¸»è¦ãªåˆ†å¸ƒ**:

| åˆ†å¸ƒ | $\theta$ | $b(\theta)$ | $a(\phi)$ | $\mu = b'(\theta)$ |
|:-----|:---------|:-----------|:----------|:------------------|
| æ­£è¦åˆ†å¸ƒ | $\mu$ | $\theta^2 / 2$ | $\sigma^2$ | $\theta$ |
| äºŒé …åˆ†å¸ƒ | $\log \frac{p}{1-p}$ | $\log(1 + e^\theta)$ | $1$ | $\frac{e^\theta}{1 + e^\theta}$ |
| ãƒã‚¢ã‚½ãƒ³åˆ†å¸ƒ | $\log \lambda$ | $e^\theta$ | $1$ | $e^\theta$ |

**GLMã®çµ±ä¸€æ§‹é€ **:

1. **ãƒ©ãƒ³ãƒ€ãƒ æˆåˆ†**: å¿œç­”å¤‰æ•° $y$ ãŒæŒ‡æ•°å‹åˆ†å¸ƒæ—ã«å¾“ã†ã€‚
2. **ç·šå½¢äºˆæ¸¬å­**: $\eta = X\beta$
3. **ãƒªãƒ³ã‚¯é–¢æ•°**: $g(\mu) = \eta$ï¼ˆæ¨™æº–çš„ãƒªãƒ³ã‚¯é–¢æ•°: $g(\mu) = \theta$ï¼‰

:::message
**é€²æ—: 80% å®Œäº†** GLMç†è«–ï¼ˆãƒ­ã‚¸ã‚¹ãƒ†ã‚£ãƒƒã‚¯ãƒ»ãƒã‚¢ã‚½ãƒ³å›å¸°ãƒ»æŒ‡æ•°å‹åˆ†å¸ƒæ—ï¼‰ã‚’ç†è§£ã€‚ãƒ™ã‚¤ã‚ºçµ±è¨ˆã¸ã€‚
:::

### 3.8 ãƒ™ã‚¤ã‚ºçµ±è¨ˆå…¥é–€

#### 3.8.1 ãƒ™ã‚¤ã‚ºã®å®šç†ã®å°å‡º

**ç¬¬4å›ã§å­¦ã‚“ã æ¡ä»¶ä»˜ãç¢ºç‡ã®å®šç¾©**:

$$
p(\theta | D) = \frac{p(\theta, D)}{p(D)}, \quad p(D | \theta) = \frac{p(\theta, D)}{p(\theta)}
$$

ä¸¡è¾ºã« $p(\theta)$ ã‚’æ›ã‘ã‚‹ã¨:

$$
p(\theta, D) = p(D | \theta) p(\theta) = p(\theta | D) p(D)
$$

ã‚ˆã£ã¦:

$$
p(\theta | D) = \frac{p(D | \theta) p(\theta)}{p(D)}
$$

ã“ã‚ŒãŒ**ãƒ™ã‚¤ã‚ºã®å®šç†**ã ã€‚

| é … | åç§° | æ„å‘³ |
|:---|:-----|:-----|
| $p(\theta \| D)$ | äº‹å¾Œåˆ†å¸ƒï¼ˆPosteriorï¼‰ | ãƒ‡ãƒ¼ã‚¿è¦³æ¸¬å¾Œã®ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã®åˆ†å¸ƒ |
| $p(D \| \theta)$ | å°¤åº¦ï¼ˆLikelihoodï¼‰ | ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ä¸‹ã§ã®ãƒ‡ãƒ¼ã‚¿ã®ç¢ºç‡ |
| $p(\theta)$ | äº‹å‰åˆ†å¸ƒï¼ˆPriorï¼‰ | ãƒ‡ãƒ¼ã‚¿è¦³æ¸¬å‰ã®ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã®ä¿¡å¿µ |
| $p(D)$ | å‘¨è¾ºå°¤åº¦ï¼ˆEvidenceï¼‰ | æ­£è¦åŒ–å®šæ•° $p(D) = \int p(D \| \theta) p(\theta) d\theta$ |

#### 3.8.2 é »åº¦è«–çµ±è¨ˆ vs ãƒ™ã‚¤ã‚ºçµ±è¨ˆ

**å“²å­¦çš„å¯¾ç«‹**:

| é …ç›® | é »åº¦è«– | ãƒ™ã‚¤ã‚º |
|:-----|:------|:-------|
| **ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã®æ€§è³ª** | å›ºå®šå€¤ï¼ˆæœªçŸ¥ï¼‰ | ç¢ºç‡å¤‰æ•° |
| **ç¢ºç‡ã®è§£é‡ˆ** | é•·æœŸçš„é »åº¦ | ä¿¡å¿µã®åº¦åˆã„ |
| **æ¨è«–ã®å¯¾è±¡** | ç‚¹æ¨å®šãƒ»ä¿¡é ¼åŒºé–“ | äº‹å¾Œåˆ†å¸ƒå…¨ä½“ |
| **ä¸ç¢ºå®Ÿæ€§ã®è¡¨ç¾** | æ¨™æº–èª¤å·® | äº‹å¾Œåˆ†å¸ƒã®å¹… |
| **äº‹å‰çŸ¥è­˜** | ä½¿ã‚ãªã„ï¼ˆå®¢è¦³æ€§ï¼‰ | ä½¿ã†ï¼ˆä¸»è¦³æ€§ï¼‰ |

**å…·ä½“ä¾‹**: ã‚³ã‚¤ãƒ³æŠ•ã’ï¼ˆ10å›ä¸­7å›è¡¨ï¼‰

**é »åº¦è«–çš„æ¨å®š**ï¼ˆç¬¬7å›ã®MLEï¼‰:

$$
\hat{\theta}_{\text{MLE}} = \frac{k}{n} = \frac{7}{10} = 0.7
$$

95%ä¿¡é ¼åŒºé–“ï¼ˆWaldæ³•ï¼‰:

$$
\text{CI} = \hat{\theta} \pm 1.96 \sqrt{\frac{\hat{\theta}(1-\hat{\theta})}{n}} = 0.7 \pm 1.96 \sqrt{\frac{0.7 \times 0.3}{10}} = [0.416, 0.984]
$$

**ãƒ™ã‚¤ã‚ºæ¨å®š**ï¼ˆäº‹å‰åˆ†å¸ƒBeta(2,2)ã€å…±å½¹æ€§ã‚ˆã‚Šäº‹å¾Œåˆ†å¸ƒBeta(9, 5)ï¼‰:

$$
p(\theta | k=7, n=10) = \text{Beta}(9, 5)
$$

äº‹å¾Œå¹³å‡ï¼ˆç‚¹æ¨å®šï¼‰:

$$
\mathbb{E}[\theta | D] = \frac{\alpha}{\alpha + \beta} = \frac{9}{9+5} = 0.643
$$

95%ä¿¡ç”¨åŒºé–“ï¼ˆCredible Intervalï¼‰:

$$
\text{CrI} = [\text{quantile}(0.025), \text{quantile}(0.975)] \approx [0.366, 0.882]
$$

**è§£é‡ˆã®é•ã„**:

- **é »åº¦è«–CI**: ã€ŒåŒã˜å®Ÿé¨“ã‚’100å›ç¹°ã‚Šè¿”ã›ã°ã€95å›ã¯ã“ã®åŒºé–“ãŒçœŸã® $\theta$ ã‚’å«ã‚€ã€
- **ãƒ™ã‚¤ã‚ºCrI**: ã€Œãƒ‡ãƒ¼ã‚¿ã‚’è¦‹ãŸä»Šã€$\theta$ ãŒã“ã®åŒºé–“ã«ã‚ã‚‹ç¢ºç‡ãŒ95%ã€ï¼ˆã‚ˆã‚Šç›´æ„Ÿçš„ï¼‰

#### 3.8.1 å…±å½¹äº‹å‰åˆ†å¸ƒ

**å®šç¾©**: äº‹å‰åˆ†å¸ƒã¨äº‹å¾Œåˆ†å¸ƒãŒåŒã˜åˆ†å¸ƒæ—ã«å±ã™ã‚‹ã¨ãã€ãã®äº‹å‰åˆ†å¸ƒã‚’å…±å½¹ã¨ã„ã†ã€‚

| å°¤åº¦ | å…±å½¹äº‹å‰åˆ†å¸ƒ | äº‹å¾Œåˆ†å¸ƒ |
|:-----|:-----------|:--------|
| äºŒé …åˆ†å¸ƒ | ãƒ™ãƒ¼ã‚¿åˆ†å¸ƒ | ãƒ™ãƒ¼ã‚¿åˆ†å¸ƒ |
| æ­£è¦åˆ†å¸ƒï¼ˆæ—¢çŸ¥åˆ†æ•£ï¼‰ | æ­£è¦åˆ†å¸ƒ | æ­£è¦åˆ†å¸ƒ |
| ãƒã‚¢ã‚½ãƒ³åˆ†å¸ƒ | ã‚¬ãƒ³ãƒåˆ†å¸ƒ | ã‚¬ãƒ³ãƒåˆ†å¸ƒ |

**ä¾‹**: ã‚³ã‚¤ãƒ³æŠ•ã’ï¼ˆäºŒé …åˆ†å¸ƒï¼‰+ ãƒ™ãƒ¼ã‚¿äº‹å‰åˆ†å¸ƒ

$$
\begin{aligned}
\text{å°¤åº¦:} \quad & p(k | n, \theta) = \binom{n}{k} \theta^k (1-\theta)^{n-k} \\
\text{äº‹å‰åˆ†å¸ƒ:} \quad & p(\theta) = \text{Beta}(\alpha, \beta) \propto \theta^{\alpha-1} (1-\theta)^{\beta-1} \\
\text{äº‹å¾Œåˆ†å¸ƒ:} \quad & p(\theta | k, n) = \text{Beta}(\alpha + k, \beta + n - k)
\end{aligned}
$$

**æ•°å€¤æ¤œè¨¼**:

```julia
using Distributions, Plots

# äº‹å‰åˆ†å¸ƒ: Beta(2, 2) (å¼±ã„ä¿¡å¿µ: Î¸â‰ˆ0.5)
Î±, Î² = 2.0, 2.0
prior = Beta(Î±, Î²)

# ãƒ‡ãƒ¼ã‚¿: 10å›æŠ•ã’ã¦7å›è¡¨
n, k = 10, 7

# äº‹å¾Œåˆ†å¸ƒ: Beta(Î±+k, Î²+n-k) = Beta(9, 5)
posterior = Beta(Î± + k, Î² + n - k)

# å¯è¦–åŒ–
Î¸_range = 0:0.01:1
plot(Î¸_range, pdf.(prior, Î¸_range), label="äº‹å‰åˆ†å¸ƒ Beta(2,2)", linewidth=2)
plot!(Î¸_range, pdf.(posterior, Î¸_range), label="äº‹å¾Œåˆ†å¸ƒ Beta(9,5)", linewidth=2)
xlabel!("Î¸ (ã‚³ã‚¤ãƒ³ãŒè¡¨ã®ç¢ºç‡)")
ylabel!("å¯†åº¦")
title!("ãƒ™ã‚¤ã‚ºæ›´æ–°: ã‚³ã‚¤ãƒ³æŠ•ã’")
savefig("bayesian_update.png")
```

#### 3.8.2 MCMCï¼ˆMarkov Chain Monte Carloï¼‰

**å•é¡Œ**: äº‹å¾Œåˆ†å¸ƒ $p(\theta | D)$ ãŒè¤‡é›‘ã§è§£æçš„ã«è¨ˆç®—ã§ããªã„ã€‚

**MCMC**: ãƒãƒ«ã‚³ãƒ•é€£é–ã‚’ä½¿ã£ã¦äº‹å¾Œåˆ†å¸ƒã‹ã‚‰ã‚µãƒ³ãƒ—ãƒ«ã‚’ç”Ÿæˆã€‚

**Metropolis-Hastingsæ³•** [^3]:

1. åˆæœŸå€¤ $\theta^{(0)}$ ã‚’è¨­å®šã€‚
2. $t = 1, 2, \ldots$ ã«ã¤ã„ã¦:
   - ææ¡ˆåˆ†å¸ƒ $q(\theta' | \theta^{(t-1)})$ ã‹ã‚‰å€™è£œ $\theta'$ ã‚’ç”Ÿæˆã€‚
   - å—ç†ç¢ºç‡ã‚’è¨ˆç®—:
     $$
     \alpha = \min\left(1, \frac{p(\theta' | D) q(\theta^{(t-1)} | \theta')}{p(\theta^{(t-1)} | D) q(\theta' | \theta^{(t-1)})}\right)
     $$
   - ç¢ºç‡ $\alpha$ ã§ $\theta^{(t)} = \theta'$ã€ãã†ã§ãªã‘ã‚Œã° $\theta^{(t)} = \theta^{(t-1)}$ã€‚

**Turing.jlã§å®Ÿè£…**:

```julia
using Turing, Distributions, StatsPlots

# ãƒ¢ãƒ‡ãƒ«å®šç¾©: ã‚³ã‚¤ãƒ³æŠ•ã’ï¼ˆãƒ™ã‚¤ã‚ºæ¨å®šï¼‰
@model function coinflip(y)
    # äº‹å‰åˆ†å¸ƒ
    Î¸ ~ Beta(2, 2)

    # å°¤åº¦
    y ~ Binomial(length(y), Î¸)
end

# ãƒ‡ãƒ¼ã‚¿: 10å›ä¸­7å›è¡¨
data = 7

# MCMCã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°ï¼ˆNUTS: No-U-Turn Sampler, Hamiltonian Monte Carloã®æ”¹è‰¯ç‰ˆï¼‰
chain = sample(coinflip([data]), NUTS(), 1000)

# äº‹å¾Œåˆ†å¸ƒã®å¯è¦–åŒ–
plot(chain)
```

:::message
**é€²æ—: 90% å®Œäº†** ãƒ™ã‚¤ã‚ºçµ±è¨ˆï¼ˆå…±å½¹äº‹å‰åˆ†å¸ƒãƒ»MCMCï¼‰ã‚’å®Œå…¨ç†è§£ã€‚å®Ÿé¨“è¨ˆç”»æ³•ã¸ã€‚
:::

### 3.9 å®Ÿé¨“è¨ˆç”»æ³•ï¼ˆExperimental Designï¼‰

**ç›®çš„**: é™ã‚‰ã‚ŒãŸãƒªã‚½ãƒ¼ã‚¹ã§æœ€å¤§ã®æƒ…å ±ã‚’å¾—ã‚‹å®Ÿé¨“ã‚’è¨­è¨ˆã™ã‚‹ã€‚

#### 3.9.1 å®Œå…¨ç„¡ä½œç‚ºåŒ–ãƒ‡ã‚¶ã‚¤ãƒ³ï¼ˆCompletely Randomized Design, CRDï¼‰

**ç‰¹å¾´**: å‡¦ç†ï¼ˆtreatmentï¼‰ã‚’ãƒ©ãƒ³ãƒ€ãƒ ã«å‰²ã‚Šå½“ã¦ã‚‹ã€‚æœ€ã‚‚ã‚·ãƒ³ãƒ—ãƒ«ã€‚

**æ¬ ç‚¹**: ãƒ–ãƒ­ãƒƒã‚¯é–“ã®å¤‰å‹•ï¼ˆä¾‹: æ¸¬å®šæ—¥ã®é•ã„ï¼‰ã‚’åˆ¶å¾¡ã§ããªã„ã€‚

#### 3.9.2 ä¹±å¡Šæ³•ï¼ˆRandomized Block Design, RBDï¼‰

**ç‰¹å¾´**: è¢«é¨“è€…ã‚’ãƒ–ãƒ­ãƒƒã‚¯ï¼ˆä¾‹: å¹´é½¢å±¤ã€æ¸¬å®šæ—¥ï¼‰ã«åˆ†ã‘ã€å„ãƒ–ãƒ­ãƒƒã‚¯å†…ã§å‡¦ç†ã‚’ãƒ©ãƒ³ãƒ€ãƒ åŒ–ã€‚

**åˆ©ç‚¹**: ãƒ–ãƒ­ãƒƒã‚¯é–“å¤‰å‹•ã‚’é™¤å» â†’ æ®‹å·®ãŒå°ã•ããªã‚‹ â†’ æ¤œå‡ºåŠ›å‘ä¸Šã€‚

#### 3.9.3 ãƒ©ãƒ†ãƒ³æ–¹æ ¼ï¼ˆLatin Square Designï¼‰

**ç‰¹å¾´**: 2ã¤ã®è¦å› ï¼ˆä¾‹: è¡Œ=æ—¥ã€åˆ—=æ©Ÿæ¢°ï¼‰ã‚’åŒæ™‚ã«åˆ¶å¾¡ã€‚

**åˆ¶ç´„**: å‡¦ç†æ•° = è¡Œæ•° = åˆ—æ•°ã€‚

#### 3.9.4 ã‚µãƒ³ãƒ—ãƒ«ã‚µã‚¤ã‚ºè¨­è¨ˆï¼ˆPower Analysisï¼‰

**å•é¡Œ**: å®Ÿé¨“å‰ã«å¿…è¦ãªã‚µãƒ³ãƒ—ãƒ«ã‚µã‚¤ã‚ºã‚’æ±ºå®šã€‚

**æ‰‹é †**:

1. æœŸå¾…ã•ã‚Œã‚‹åŠ¹æœé‡ $d$ ã‚’è¨­å®šï¼ˆéå»ã®ç ”ç©¶ã‚„äºˆå‚™å®Ÿé¨“ã‹ã‚‰ï¼‰ã€‚
2. æœ‰æ„æ°´æº– $\alpha$ ã‚’è¨­å®šï¼ˆé€šå¸¸0.05ï¼‰ã€‚
3. ç›®æ¨™æ¤œå‡ºåŠ› $1 - \beta$ ã‚’è¨­å®šï¼ˆé€šå¸¸0.8ï¼‰ã€‚
4. æ¤œå®šã®ç¨®é¡ã«å¿œã˜ãŸå…¬å¼ã¾ãŸã¯ã‚½ãƒ•ãƒˆã‚¦ã‚§ã‚¢ã§ã‚µãƒ³ãƒ—ãƒ«ã‚µã‚¤ã‚ºã‚’è¨ˆç®—ã€‚

**tæ¤œå®šã®ã‚µãƒ³ãƒ—ãƒ«ã‚µã‚¤ã‚ºå…¬å¼**ï¼ˆå†æ²ï¼‰:

$$
n = \frac{2(z_{1-\alpha/2} + z_{1-\beta})^2}{d^2}
$$

### 6.11 ãƒ‘ãƒ©ãƒ€ã‚¤ãƒ è»¢æ›ã®å•ã„

> **ã€Œp < 0.05ã§æœ‰æ„ã€ã¨è¨€ãˆã‚‹ã€‚ã ãŒã€ãã‚Œã¯æœ¬å½“ã«**ã‚ãªãŸã®ä¸»å¼µ**ã‚’æ”¯æŒã—ã¦ã„ã‚‹ã®ã‹ï¼Ÿ**

ä»¥ä¸‹ã®ã‚·ãƒŠãƒªã‚ªã‚’è€ƒãˆã‚ˆã†:

1. **ã‚·ãƒŠãƒªã‚ªA**: æ–°ã—ã„ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆæ‰‹æ³•ã‚’10ç¨®é¡è©¦ã—ã€1ã¤ã ã‘p < 0.05ã§æœ‰æ„ãªæ”¹å–„ã€‚ä»–9ã¤ã¯æœ‰æ„å·®ãªã—ã€‚
2. **ã‚·ãƒŠãƒªã‚ªB**: åŒã˜å®Ÿé¨“ã‚’100å›è¡Œã„ã€æœ‰æ„ã ã£ãŸ5å›ã ã‘è«–æ–‡ã«å ±å‘Šã€‚
3. **ã‚·ãƒŠãƒªã‚ªC**: ãƒ‡ãƒ¼ã‚¿ã‚’è¦‹ã¦ã‹ã‚‰ã€Œã“ã®ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã§ã¯åŠ¹æœãŒã‚ã‚‹ã€ã¨äº‹å¾Œçš„ã«ã‚µãƒ–ã‚°ãƒ«ãƒ¼ãƒ—åˆ†æã€‚

**å…¨ã¦çµ±è¨ˆçš„ã«ã¯ã€Œp < 0.05ã€ã ãŒã€ç§‘å­¦çš„ã«ã¯ç„¡æ„å‘³ã ã€‚**

- **ã‚·ãƒŠãƒªã‚ªA**: å¤šé‡æ¯”è¼ƒã®ç½ ã€‚Bonferroniè£œæ­£ã™ã‚Œã°p = 0.05 Ã— 10 = 0.5ã§æœ‰æ„ã§ãªã„ã€‚
- **ã‚·ãƒŠãƒªã‚ªB**: å‡ºç‰ˆãƒã‚¤ã‚¢ã‚¹ã€‚å¤±æ•—ã—ãŸ95å›ã‚’éš è”½ã€‚
- **ã‚·ãƒŠãƒªã‚ªC**: p-hackingã€‚ãƒ‡ãƒ¼ã‚¿ã‚’è¦‹ã¦ã‹ã‚‰ä»®èª¬ã‚’ç«‹ã¦ã‚‹ã€‚

**è­°è«–ã®ç¨®**:

1. **äº‹å‰ç™»éŒ²ï¼ˆPre-registrationï¼‰**ã¯è§£æ±ºç­–ã‹ï¼Ÿã€€å®Ÿé¨“å‰ã«ä»®èª¬ãƒ»æ‰‹æ³•ã‚’å…¬é–‹ç™»éŒ²ã™ã‚Œã°ã€p-hackingã‚’é˜²ã’ã‚‹ã€‚ã ãŒæŸ”è»Ÿæ€§ãŒå¤±ã‚ã‚Œã‚‹ã€‚
2. **på€¤ã®ä»£æ›¿æ¡ˆ**ã¯ï¼Ÿã€€ä¿¡é ¼åŒºé–“ãƒ»åŠ¹æœé‡ãƒ»ãƒ™ã‚¤ã‚ºãƒ•ã‚¡ã‚¯ã‚¿ãƒ¼ã¯ã€på€¤ã®å•é¡Œã‚’è§£æ±ºã™ã‚‹ã‹ï¼Ÿ
3. **çµ±è¨ˆçš„æœ‰æ„æ€§ã®åŸºæº–ï¼ˆÎ±=0.05ï¼‰**ã¯æ£æ„çš„ã§ã¯ãªã„ã‹ï¼Ÿã€€ãªãœ0.05ãªã®ã‹ï¼Ÿã€€0.01ã‚„0.001ã§ã¯ãƒ€ãƒ¡ãªã®ã‹ï¼Ÿ

ã“ã®å•ã„ã«å®Œå…¨ãªç­”ãˆã¯ãªã„ã€‚ã ãŒ**çµ±è¨ˆå­¦ã¯é“å…·ã§ã‚ã‚Šã€é“å…·ã®ä½¿ã„æ–¹æ¬¡ç¬¬ã§ç§‘å­¦çš„èª å®Ÿã•ãŒå•ã‚ã‚Œã‚‹**ã“ã¨ã‚’å¿˜ã‚Œã¦ã¯ãªã‚‰ãªã„ã€‚

:::message
**é€²æ—: 100% å®Œäº†** ğŸ‰ è¬›ç¾©å®Œèµ°ï¼
:::

---

## å‚è€ƒæ–‡çŒ®

### ä¸»è¦è«–æ–‡

[^1]: Neyman, J., & Pearson, E. S. (1928). *On the Use and Interpretation of Certain Test Criteria for Purposes of Statistical Inference: Part I*. Biometrika.
@[card](https://www.jstor.org/stable/2331945)

[^2]: Benjamini, Y., & Hochberg, Y. (1995). *Controlling the False Discovery Rate: A Practical and Powerful Approach to Multiple Testing*. Journal of the Royal Statistical Society: Series B.
@[card](https://doi.org/10.1111/j.2517-6161.1995.tb02031.x)

[^3]: Hastings, W. K. (1970). *Monte Carlo Sampling Methods Using Markov Chains and Their Applications*. Biometrika.
@[card](https://doi.org/10.1093/biomet/57.1.97)

[^4]: Casella, G., & Berger, R. L. (2002). *Statistical Inference* (2nd ed.). Duxbury Press.

[^5]: Gelman, A., Carlin, J. B., Stern, H. S., & Rubin, D. B. (2013). *Bayesian Data Analysis* (3rd ed.). CRC Press.

[^6]: Nelder, J. A., & Wedderburn, R. W. M. (1972). *Generalized Linear Models*. Journal of the Royal Statistical Society: Series A.
@[card](https://doi.org/10.2307/2344614)

[^7]: Efron, B., & Tibshirani, R. J. (1994). *An Introduction to the Bootstrap*. Chapman & Hall/CRC.

### æ•™ç§‘æ›¸

- **Statistical Inference** - Casella & Berger (2002): é »åº¦è«–çµ±è¨ˆã®æ±ºå®šç‰ˆã€‚å¤§å­¦é™¢ãƒ¬ãƒ™ãƒ«ã€‚
- **Bayesian Data Analysis** - Gelman et al. (2013): ãƒ™ã‚¤ã‚ºçµ±è¨ˆã®æ¨™æº–æ•™ç§‘æ›¸ã€‚
- **The Elements of Statistical Learning** - Hastie, Tibshirani, Friedman (2009): æ©Ÿæ¢°å­¦ç¿’Ã—çµ±è¨ˆã®èåˆã€‚[ç„¡æ–™PDF](https://web.stanford.edu/~hastie/ElemStatLearn/)
- **çµ±è¨ˆå­¦å…¥é–€** - æ±äº¬å¤§å­¦æ•™é¤Šå­¦éƒ¨çµ±è¨ˆå­¦æ•™å®¤ (1991): æ—¥æœ¬èªã®å®šç•ªå…¥é–€æ›¸ã€‚

### ã‚ªãƒ³ãƒ©ã‚¤ãƒ³ãƒªã‚½ãƒ¼ã‚¹

- [StatQuest (YouTube)](https://www.youtube.com/@statquest): çµ±è¨ˆå­¦ã®ç›´æ„Ÿçš„è§£èª¬å‹•ç”»ã€‚
- [StatsBase.jl Documentation](https://juliastats.org/StatsBase.jl/stable/)
- [HypothesisTests.jl Documentation](https://juliastats.org/HypothesisTests.jl/stable/)
- [GLM.jl Documentation](https://juliastats.org/GLM.jl/stable/)
- [Turing.jl Documentation](https://turinglang.org/stable/)

---

## è¨˜æ³•è¦ç´„

| è¨˜å· | æ„å‘³ | å‚™è€ƒ |
|:-----|:-----|:-----|
| $\bar{x}$ | æ¨™æœ¬å¹³å‡ | $\bar{x} = \frac{1}{n} \sum_{i=1}^n x_i$ |
| $s^2$ | æ¨™æœ¬åˆ†æ•£ï¼ˆä¸åï¼‰ | $s^2 = \frac{1}{n-1} \sum (x_i - \bar{x})^2$ |
| $s$ | æ¨™æœ¬æ¨™æº–åå·® | $s = \sqrt{s^2}$ |
| $\mu$ | æ¯å¹³å‡ | æ¯é›†å›£ã®æœŸå¾…å€¤ |
| $\sigma^2$ | æ¯åˆ†æ•£ | æ¯é›†å›£ã®åˆ†æ•£ |
| $\text{SE}$ | æ¨™æº–èª¤å·® | $\text{SE} = \sigma / \sqrt{n} \approx s / \sqrt{n}$ |
| $\alpha$ | æœ‰æ„æ°´æº– | ç¬¬1ç¨®éèª¤ç‡ï¼ˆé€šå¸¸0.05ï¼‰ |
| $\beta$ | ç¬¬2ç¨®éèª¤ç‡ | $1 - \beta$ = æ¤œå‡ºåŠ› |
| $H_0$ | å¸°ç„¡ä»®èª¬ | ã€Œå·®ãŒãªã„ã€ã€ŒåŠ¹æœãŒãªã„ã€ |
| $H_1$ | å¯¾ç«‹ä»®èª¬ | ã€Œå·®ãŒã‚ã‚‹ã€ã€ŒåŠ¹æœãŒã‚ã‚‹ã€ |
| $p$ | på€¤ | $H_0$ä¸‹ã§ã®æ¥µç«¯å€¤ã®ç¢ºç‡ |
| $d$ | Cohen's d | åŠ¹æœé‡ $d = \frac{\bar{x}_1 - \bar{x}_2}{s_{\text{pooled}}}$ |
| $t$ | tçµ±è¨ˆé‡ | tæ¤œå®šã®æ¤œå®šçµ±è¨ˆé‡ |
| $F$ | Fçµ±è¨ˆé‡ | ANOVAã®æ¤œå®šçµ±è¨ˆé‡ |
| $\text{df}$ | è‡ªç”±åº¦ | æ¨å®šã«ä½¿ãˆã‚‹ç‹¬ç«‹ãªæƒ…å ±ã®æ•° |
| $\text{CI}$ | ä¿¡é ¼åŒºé–“ | Confidence Interval |
| $\text{FWER}$ | å®¶æ—èª¤å·®ç‡ | Family-Wise Error Rate |
| $\text{FDR}$ | å½ç™ºè¦‹ç‡ | False Discovery Rate |
| $\theta$ | ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ | ãƒ™ã‚¤ã‚ºçµ±è¨ˆã§ã®æ¨å®šå¯¾è±¡ |
| $p(\theta \| D)$ | äº‹å¾Œåˆ†å¸ƒ | ãƒ‡ãƒ¼ã‚¿è¦³æ¸¬å¾Œã®ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿åˆ†å¸ƒ |
| $p(D \| \theta)$ | å°¤åº¦ | ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ä¸‹ã§ã®ãƒ‡ãƒ¼ã‚¿ã®ç¢ºç‡ |
| $p(\theta)$ | äº‹å‰åˆ†å¸ƒ | ãƒ‡ãƒ¼ã‚¿è¦³æ¸¬å‰ã®ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿åˆ†å¸ƒ |

**çµ±è¨ˆæ¤œå®šã®Juliaå®Ÿè£…å¯¾å¿œ**:

| æ•°å¼ | Juliaå®Ÿè£… |
|:-----|:----------|
| $\bar{x} = \frac{1}{n}\sum x_i$ | `mean(x)` |
| $s^2 = \frac{1}{n-1}\sum(x_i - \bar{x})^2$ | `var(x)` |
| $t = \frac{\bar{x} - \mu_0}{s/\sqrt{n}}$ | `OneSampleTTest(x, Î¼â‚€)` |
| $p\text{-value}$ | `pvalue(test)` |
| $\alpha_{\text{Bonf}} = \alpha / m$ | `adjust(PValues(p), Bonferroni())` |
| $\text{logit}(p) = \log\frac{p}{1-p}$ | `glm(@formula(y ~ x), df, Binomial(), LogitLink())` |
| $p(\theta \| D) \propto p(D \| \theta) p(\theta)$ | `@model function model(D) ... end` + `sample(...)` |

---

---

## ä»˜éŒ²A: çµ±è¨ˆå­¦ã®æ­´å²çš„ç™ºå±•

### A.1 é »åº¦è«–çµ±è¨ˆã®èª•ç”Ÿï¼ˆ1900-1950å¹´ä»£ï¼‰

| å¹´ | äººç‰© | è²¢çŒ® |
|:---|:-----|:-----|
| 1900 | Karl Pearson | ã‚«ã‚¤äºŒä¹—æ¤œå®šã€Pearsonç›¸é–¢ä¿‚æ•° |
| 1908 | William Gosset (Student) | tåˆ†å¸ƒã€tæ¤œå®šï¼ˆå°‘ã‚µãƒ³ãƒ—ãƒ«çµ±è¨ˆï¼‰ |
| 1920å¹´ä»£ | Ronald Fisher | æœ€å°¤æ¨å®šï¼ˆMLEï¼‰ã€åˆ†æ•£åˆ†æï¼ˆANOVAï¼‰ã€å®Ÿé¨“è¨ˆç”»æ³• |
| 1928 | Neyman & Pearson | Neyman-Pearsonä»®èª¬æ¤œå®šæ çµ„ã¿ [^1] |
| 1935 | Fisher | ãƒ©ãƒ³ãƒ€ãƒ åŒ–æ¯”è¼ƒè©¦é¨“ï¼ˆRCTï¼‰ã®åŸç† |

**é »åº¦è«–ã®å“²å­¦**: ç¢ºç‡ = é•·æœŸçš„é »åº¦ã€‚ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã¯å›ºå®šå€¤ï¼ˆæœªçŸ¥ï¼‰ã€‚å®¢è¦³æ€§ã‚’é‡è¦–ã€‚

### A.2 ãƒ™ã‚¤ã‚ºçµ±è¨ˆã®å¾©èˆˆï¼ˆ1950-1990å¹´ä»£ï¼‰

| å¹´ | äººç‰©/å‡ºæ¥äº‹ | è²¢çŒ® |
|:---|:----------|:-----|
| 1763 | Thomas Bayesï¼ˆæ­»å¾Œå‡ºç‰ˆï¼‰ | ãƒ™ã‚¤ã‚ºã®å®šç†ã®åŸå‹ |
| 1950å¹´ä»£ | Dennis Lindley | ãƒ™ã‚¤ã‚ºæ±ºå®šç†è«– |
| 1953 | Metropolis et al. | Metropolisã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ ï¼ˆMCMCï¼‰ [^3] |
| 1970 | Hastings | Metropolis-Hastingsã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ  |
| 1990 | Gelfand & Smith | Gibbs Samplingã®å®Ÿç”¨åŒ– |

**ãƒ™ã‚¤ã‚ºå¾©èˆˆã®ç†ç”±**: ã‚³ãƒ³ãƒ”ãƒ¥ãƒ¼ã‚¿ã®ç™ºå±•ã§MCMCãŒå®Ÿç”¨åŒ– â†’ è¤‡é›‘ãªãƒ¢ãƒ‡ãƒ«ã®äº‹å¾Œåˆ†å¸ƒã‚’è¨ˆç®—å¯èƒ½ã«ã€‚

### A.3 ç¾ä»£çµ±è¨ˆå­¦ï¼ˆ1990å¹´ä»£ã€œç¾åœ¨ï¼‰

| å¹´ | æ‰‹æ³• | è²¢çŒ® |
|:---|:-----|:-----|
| 1995 | Benjamini & Hochberg | FDRåˆ¶å¾¡æ³•ï¼ˆå¤šé‡æ¯”è¼ƒï¼‰ [^2] |
| 2000å¹´ä»£ | ãƒ™ã‚¤ã‚ºãƒãƒ³ãƒ‘ãƒ©ãƒ¡ãƒˆãƒªã‚¯ã‚¹ | ç„¡é™æ¬¡å…ƒãƒ¢ãƒ‡ãƒ«ï¼ˆDirichlet Processç­‰ï¼‰ |
| 2010å¹´ä»£ | Hamiltonian Monte Carlo (HMC) | é«˜æ¬¡å…ƒMCMCã®é«˜é€ŸåŒ–ï¼ˆNUTSï¼‰ |
| 2015å¹´ä»£ | å› æœæ¨è«–ã®æ™®åŠ | Pearl/Rubinæ çµ„ã¿ã®çµ±åˆã€æ©Ÿæ¢°å­¦ç¿’ã¨ã®èåˆ |
| 2020å¹´ä»£ | ç¢ºç‡çš„ãƒ—ãƒ­ã‚°ãƒ©ãƒŸãƒ³ã‚° | Turing.jl, PyMC, Stanç­‰ã®æˆç†Ÿ |

---

## ä»˜éŒ²B: Juliaã§ä½¿ãˆã‚‹çµ±è¨ˆãƒ‘ãƒƒã‚±ãƒ¼ã‚¸å®Œå…¨ãƒªã‚¹ãƒˆ

### B.1 åŸºç¤çµ±è¨ˆ

| ãƒ‘ãƒƒã‚±ãƒ¼ã‚¸ | ç”¨é€” | ä¸»è¦é–¢æ•° |
|:----------|:-----|:---------|
| **Statistics** (stdlib) | åŸºæœ¬çµ±è¨ˆé‡ | `mean`, `std`, `var`, `median`, `quantile`, `cor`, `cov` |
| **StatsBase.jl** | è¨˜è¿°çµ±è¨ˆãƒ»é‡ã¿ä»˜ãçµ±è¨ˆ | `skewness`, `kurtosis`, `mad`, `mode`, `sem`, `zscore`, `sample`, `weights` |
| **Distributions.jl** | ç¢ºç‡åˆ†å¸ƒ | `Normal`, `Beta`, `Gamma`, `Binomial`, `Poisson`, `TDist`, `FDist`, `pdf`, `cdf`, `quantile`, `rand` |

### B.2 ä»®èª¬æ¤œå®š

| ãƒ‘ãƒƒã‚±ãƒ¼ã‚¸ | ç”¨é€” | ä¸»è¦æ¤œå®š |
|:----------|:-----|:---------|
| **HypothesisTests.jl** | ä»®èª¬æ¤œå®šå…¨èˆ¬ | `OneSampleTTest`, `EqualVarianceTTest`, `UnequalVarianceTTest`, `MannWhitneyUTest`, `WilcoxonSignedRankTest`, `KruskalWallisTest`, `OneWayANOVATest`, `ChisqTest`, `FisherExactTest`, `KSTest`, `AndersonDarlingTest` |
| **MultipleTesting.jl** | å¤šé‡æ¯”è¼ƒè£œæ­£ | `adjust`, `Bonferroni`, `Holm`, `BenjaminiHochberg`, `BenjaminiYekutieli` |

### B.3 å›å¸°ãƒ»GLM

| ãƒ‘ãƒƒã‚±ãƒ¼ã‚¸ | ç”¨é€” | ä¸»è¦é–¢æ•° |
|:----------|:-----|:---------|
| **GLM.jl** | ä¸€èˆ¬åŒ–ç·šå½¢ãƒ¢ãƒ‡ãƒ« | `glm`, `@formula`, `Binomial`, `Poisson`, `Gamma`, `LogitLink`, `LogLink`, `InverseLink`, `coef`, `confint`, `predict` |
| **MixedModels.jl** | æ··åˆåŠ¹æœãƒ¢ãƒ‡ãƒ« | `LinearMixedModel`, `fit!`, `ranef`, `fixef` |

### B.4 ãƒ™ã‚¤ã‚ºçµ±è¨ˆ

| ãƒ‘ãƒƒã‚±ãƒ¼ã‚¸ | ç”¨é€” | ä¸»è¦é–¢æ•°/ãƒã‚¯ãƒ­ |
|:----------|:-----|:---------------|
| **Turing.jl** | ç¢ºç‡çš„ãƒ—ãƒ­ã‚°ãƒ©ãƒŸãƒ³ã‚° | `@model`, `~`, `sample`, `NUTS`, `HMC`, `Gibbs`, `plot`, `summarize` |
| **AdvancedMH.jl** | MCMCæ‹¡å¼µ | `MetropolisHastings`, `RWMH`, `StaticMH` |
| **MCMCChains.jl** | MCMCçµæœã®è§£æ | `Chains`, `describe`, `plot`, `ess`, `gelmandiag` |
| **AbstractMCMC.jl** | MCMCã‚¤ãƒ³ã‚¿ãƒ¼ãƒ•ã‚§ãƒ¼ã‚¹ | MCMCå®Ÿè£…ã®å…±é€šåŸºç›¤ |

### B.5 ãƒ–ãƒ¼ãƒˆã‚¹ãƒˆãƒ©ãƒƒãƒ—ãƒ»ãƒªã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°

| ãƒ‘ãƒƒã‚±ãƒ¼ã‚¸ | ç”¨é€” | ä¸»è¦é–¢æ•° |
|:----------|:-----|:---------|
| **Bootstrap.jl** | ãƒ–ãƒ¼ãƒˆã‚¹ãƒˆãƒ©ãƒƒãƒ—æ³• | `bootstrap`, `BasicSampling`, `confint`, `PercentileConfInt`, `BCaConfInt` |

### B.6 ç”Ÿå­˜æ™‚é–“è§£æ

| ãƒ‘ãƒƒã‚±ãƒ¼ã‚¸ | ç”¨é€” | ä¸»è¦é–¢æ•° |
|:----------|:-----|:---------|
| **Survival.jl** | ç”Ÿå­˜æ™‚é–“è§£æ | `Surv`, `kaplan_meier`, `cox_ph`, `nelson_aalen` |

### B.7 æ™‚ç³»åˆ—è§£æ

| ãƒ‘ãƒƒã‚±ãƒ¼ã‚¸ | ç”¨é€” | ä¸»è¦é–¢æ•° |
|:----------|:-----|:---------|
| **TimeSeries.jl** | æ™‚ç³»åˆ—ãƒ‡ãƒ¼ã‚¿ | `TimeArray`, `values`, `timestamp`, `lag`, `lead`, `diff` |
| **StateSpaceModels.jl** | çŠ¶æ…‹ç©ºé–“ãƒ¢ãƒ‡ãƒ« | `StateSpaceModel`, `kalman_filter`, `smoother` |

### B.8 å®Ÿé¨“è¨ˆç”»æ³•

| ãƒ‘ãƒƒã‚±ãƒ¼ã‚¸ | ç”¨é€” | ä¸»è¦é–¢æ•° |
|:----------|:-----|:---------|
| **ExperimentalDesign.jl** | å®Ÿé¨“è¨ˆç”» | `factorial_design`, `latin_square`, `balanced_design` |

### B.9 å¯è¦–åŒ–

| ãƒ‘ãƒƒã‚±ãƒ¼ã‚¸ | ç”¨é€” | ä¸»è¦é–¢æ•° |
|:----------|:-----|:---------|
| **StatsPlots.jl** | çµ±è¨ˆçš„ãƒ—ãƒ­ãƒƒãƒˆ | `boxplot`, `violin`, `density`, `marginalscatter`, `corrplot`, `@df` |
| **Makie.jl** | é«˜å“è³ªå¯è¦–åŒ– | `scatter`, `lines`, `barplot`, `heatmap`, `density` |
| **AlgebraOfGraphics.jl** | Grammar of Graphics | `data`, `mapping`, `visual`, `draw` |

---

## ä»˜éŒ²C: çµ±è¨ˆå­¦ã®ä¸»è¦å®šç†ã¾ã¨ã‚

### C.1 ç¢ºç‡è«–ã®åŸºç¤å®šç†

**å¤§æ•°ã®æ³•å‰‡ï¼ˆLaw of Large Numbersï¼‰**:

$$
\bar{X}_n = \frac{1}{n} \sum_{i=1}^n X_i \xrightarrow{p} \mu \quad \text{as } n \to \infty
$$

æ¨™æœ¬å¹³å‡ã¯æ¯å¹³å‡ã«ç¢ºç‡åæŸã™ã‚‹ã€‚

**ä¸­å¿ƒæ¥µé™å®šç†ï¼ˆCentral Limit Theoremï¼‰**:

$$
\sqrt{n} \frac{\bar{X}_n - \mu}{\sigma} \xrightarrow{d} \mathcal{N}(0, 1) \quad \text{as } n \to \infty
$$

æ¨™æœ¬å¹³å‡ã®åˆ†å¸ƒã¯æ­£è¦åˆ†å¸ƒã«è¿‘ã¥ãï¼ˆæ¯é›†å›£åˆ†å¸ƒã«é–¢ã‚ã‚‰ãšï¼‰ã€‚

### C.2 æ¨å®šã®ç†è«–

**CramÃ©r-Raoä¸‹ç•Œï¼ˆCramÃ©r-Rao Lower Boundï¼‰**:

ä¸åæ¨å®šé‡ $\hat{\theta}$ ã®åˆ†æ•£ã¯æ¬¡ã®ä¸‹ç•Œã‚’æŒã¤:

$$
\text{Var}(\hat{\theta}) \geq \frac{1}{I(\theta)}
$$

ã“ã“ã§ $I(\theta)$ ã¯Fisheræƒ…å ±é‡ã€‚ç­‰å·æˆç«‹æ™‚ã¯**æœ‰åŠ¹æ¨å®šé‡**ã€‚

**æ¼¸è¿‘æ­£è¦æ€§ï¼ˆAsymptotic Normalityï¼‰**:

MLEã¯æ¼¸è¿‘çš„ã«æ­£è¦åˆ†å¸ƒã«å¾“ã†:

$$
\sqrt{n}(\hat{\theta}_{\text{MLE}} - \theta) \xrightarrow{d} \mathcal{N}(0, I(\theta)^{-1})
$$

### C.3 æ¤œå®šã®ç†è«–

**Neyman-Pearsonè£œé¡Œï¼ˆNeyman-Pearson Lemmaï¼‰**:

å°¤åº¦æ¯”æ¤œå®šã¯æ‰€å®šã®æœ‰æ„æ°´æº– $\alpha$ ã§æœ€ã‚‚æ¤œå‡ºåŠ›ãŒé«˜ã„ï¼ˆmost powerful testï¼‰ã€‚

$$
\frac{p(x | H_1)}{p(x | H_0)} > c \quad \Rightarrow \quad \text{reject } H_0
$$

### C.4 ãƒ™ã‚¤ã‚ºçµ±è¨ˆã®å®šç†

**ãƒ™ã‚¤ã‚ºã®å®šç†ï¼ˆBayes' Theoremï¼‰**:

$$
p(\theta | D) = \frac{p(D | \theta) p(\theta)}{p(D)} = \frac{p(D | \theta) p(\theta)}{\int p(D | \theta') p(\theta') d\theta'}
$$

**ãƒãƒ«ã‚³ãƒ•é€£é–ã®åæŸ**:

é©åˆ‡ãªæ¡ä»¶ä¸‹ã§MCMCã‚µãƒ³ãƒ—ãƒ«ã¯äº‹å¾Œåˆ†å¸ƒã«åæŸ:

$$
\lim_{t \to \infty} \theta^{(t)} \sim p(\theta | D)
$$

---

## ä»˜éŒ²D: çµ±è¨ˆå­¦ã®å®Ÿè·µãƒã‚§ãƒƒã‚¯ãƒªã‚¹ãƒˆ

### D.1 å®Ÿé¨“å‰ï¼ˆäº‹å‰è¨ˆç”»ï¼‰

- [ ] ç ”ç©¶ä»®èª¬ã‚’æ˜ç¢ºã«å®šç¾©ï¼ˆ$H_0$, $H_1$ï¼‰
- [ ] æœ‰æ„æ°´æº– $\alpha$ ã‚’æ±ºå®šï¼ˆé€šå¸¸0.05ï¼‰
- [ ] ç›®æ¨™æ¤œå‡ºåŠ›ã‚’æ±ºå®šï¼ˆé€šå¸¸0.8ï¼‰
- [ ] æœŸå¾…ã•ã‚Œã‚‹åŠ¹æœé‡ã‚’è¨­å®šï¼ˆéå»ç ”ç©¶ãƒ»äºˆå‚™å®Ÿé¨“ã‹ã‚‰ï¼‰
- [ ] ãƒ‘ãƒ¯ãƒ¼åˆ†æã§å¿…è¦ã‚µãƒ³ãƒ—ãƒ«ã‚µã‚¤ã‚ºã‚’è¨ˆç®—
- [ ] æ¤œå®šæ‰‹æ³•ã‚’äº‹å‰ã«æ±ºå®šï¼ˆtæ¤œå®šãƒ»ANOVAãƒ»ãƒãƒ³ãƒ‘ãƒ©ãƒ¡ãƒˆãƒªãƒƒã‚¯ç­‰ï¼‰
- [ ] å¤šé‡æ¯”è¼ƒãŒã‚ã‚‹å ´åˆã¯è£œæ­£æ–¹æ³•ã‚’æ±ºå®šï¼ˆBonferroniãƒ»BHç­‰ï¼‰
- [ ] äº‹å‰ç™»éŒ²ï¼ˆPre-registrationï¼‰ã‚’æ¤œè¨ï¼ˆp-hackingã‚’é˜²ãï¼‰

### D.2 ãƒ‡ãƒ¼ã‚¿åé›†

- [ ] ãƒ©ãƒ³ãƒ€ãƒ ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°ãƒ»ãƒ©ãƒ³ãƒ€ãƒ åŒ–ã‚’å¾¹åº•
- [ ] ãƒ–ãƒ­ãƒƒã‚¯è¦å› ãŒã‚ã‚Œã°ä¹±å¡Šæ³•ã‚’æ¤œè¨
- [ ] æ¸¬å®šèª¤å·®ã‚’æœ€å°åŒ–ï¼ˆæ©Ÿå™¨ã®æ ¡æ­£ãƒ»ãƒ—ãƒ­ãƒˆã‚³ãƒ«ã®æ¨™æº–åŒ–ï¼‰
- [ ] æ¬ æãƒ‡ãƒ¼ã‚¿ã®è¨˜éŒ²ãƒ»ç†ç”±ã®è¨˜è¼‰
- [ ] å¤–ã‚Œå€¤ã®è¨˜éŒ²ï¼ˆå‰Šé™¤å‰ã«ç†ç”±ã‚’æ˜è¨˜ï¼‰

### D.3 è¨˜è¿°çµ±è¨ˆ

- [ ] å¹³å‡ãƒ»ä¸­å¤®å€¤ãƒ»æ¨™æº–åå·®ãƒ»IQRã‚’è¨ˆç®—
- [ ] æ­ªåº¦ãƒ»å°–åº¦ã‚’ç¢ºèªï¼ˆåˆ†å¸ƒã®å½¢çŠ¶ï¼‰
- [ ] å¤–ã‚Œå€¤ã®æ¤œå‡ºï¼ˆIQRæ³•ãƒ»Grubbsæ¤œå®šï¼‰
- [ ] ãƒ’ã‚¹ãƒˆã‚°ãƒ©ãƒ ãƒ»ç®±ã²ã’å›³ã§å¯è¦–åŒ–

### D.4 æ¨æ¸¬çµ±è¨ˆ

- [ ] å‰ææ¡ä»¶ã®ç¢ºèªï¼ˆæ­£è¦æ€§ãƒ»ç­‰åˆ†æ•£æ€§ãƒ»ç‹¬ç«‹æ€§ï¼‰
- [ ] æ­£è¦æ€§æ¤œå®šï¼ˆShapiro-Wilkãƒ»Kolmogorov-Smirnovï¼‰
- [ ] ç­‰åˆ†æ•£æ€§æ¤œå®šï¼ˆLeveneãƒ»Bartlettï¼‰
- [ ] å‰æãŒæº€ãŸã•ã‚Œãªã„å ´åˆã¯ä»£æ›¿æ‰‹æ³•ï¼ˆãƒãƒ³ãƒ‘ãƒ©ãƒ¡ãƒˆãƒªãƒƒã‚¯ãƒ»å¤‰æ›ãƒ»é ‘å¥ãªæ‰‹æ³•ï¼‰

### D.5 ä»®èª¬æ¤œå®š

- [ ] æ¤œå®šçµ±è¨ˆé‡ï¼ˆt, F, Ï‡Â², Uç­‰ï¼‰ã‚’è¨ˆç®—
- [ ] è‡ªç”±åº¦ã‚’ç¢ºèª
- [ ] på€¤ã‚’è¨ˆç®—
- [ ] åŠ¹æœé‡ï¼ˆCohen's d, partial Î·Â², rÂ²ç­‰ï¼‰ã‚’è¨ˆç®—
- [ ] ä¿¡é ¼åŒºé–“ã‚’ä½µè¨˜
- [ ] å¤šé‡æ¯”è¼ƒè£œæ­£ï¼ˆè©²å½“ã™ã‚‹å ´åˆï¼‰

### D.6 çµæœã®å ±å‘Š

- [ ] è¨˜è¿°çµ±è¨ˆï¼ˆM, SD, nï¼‰ã‚’å ±å‘Š
- [ ] æ¤œå®šçµ±è¨ˆé‡ãƒ»è‡ªç”±åº¦ãƒ»på€¤ã‚’å ±å‘Šï¼ˆä¾‹: $t(9) = 60.0, p < .001$ï¼‰
- [ ] åŠ¹æœé‡ã‚’å ±å‘Šï¼ˆä¾‹: $d = 6.0$ï¼‰
- [ ] 95%ä¿¡é ¼åŒºé–“ã‚’å ±å‘Šï¼ˆä¾‹: $95\% \text{CI} [0.768, 0.782]$ï¼‰
- [ ] å¤šé‡æ¯”è¼ƒè£œæ­£æ–¹æ³•ã‚’æ˜è¨˜
- [ ] å›³è¡¨ã§è¦–è¦šåŒ–ï¼ˆç®±ã²ã’å›³ãƒ»ã‚¨ãƒ©ãƒ¼ãƒãƒ¼ä»˜ãæ£’ã‚°ãƒ©ãƒ•ç­‰ï¼‰
- [ ] çµ±è¨ˆçš„æœ‰æ„æ€§ã¨å®Ÿç”¨çš„æœ‰æ„æ€§ã‚’åŒºåˆ¥

### D.7 è§£é‡ˆãƒ»è­°è«–

- [ ] på€¤ã®æ­£ã—ã„è§£é‡ˆï¼ˆã€Œ$H_0$ãŒçœŸã§ã‚ã‚‹ç¢ºç‡ã€ã§ã¯ãªã„ï¼‰
- [ ] åŠ¹æœé‡ã®å®Ÿç”¨çš„æ„ç¾©ã‚’è­°è«–
- [ ] æ¤œå‡ºåŠ›ä¸è¶³ã®å¯èƒ½æ€§ã‚’æ¤œè¨ï¼ˆp > 0.05ã®å ´åˆï¼‰
- [ ] ä»£æ›¿èª¬æ˜ï¼ˆäº¤çµ¡å› å­ï¼‰ã®å¯èƒ½æ€§ã‚’è­°è«–
- [ ] é™ç•Œï¼ˆã‚µãƒ³ãƒ—ãƒ«é¸æŠãƒã‚¤ã‚¢ã‚¹ãƒ»æ¸¬å®šèª¤å·®ç­‰ï¼‰ã‚’æ˜è¨˜
- [ ] å› æœé–¢ä¿‚ã¨ç›¸é–¢ã®åŒºåˆ¥

---

## ãƒ©ã‚¤ã‚»ãƒ³ã‚¹

æœ¬è¨˜äº‹ã¯ [CC BY-NC-SA 4.0](https://creativecommons.org/licenses/by-nc-sa/4.0/deed.ja)ï¼ˆã‚¯ãƒªã‚¨ã‚¤ãƒ†ã‚£ãƒ–ãƒ»ã‚³ãƒ¢ãƒ³ã‚º è¡¨ç¤º - éå–¶åˆ© - ç¶™æ‰¿ 4.0 å›½éš›ï¼‰ã®ä¸‹ã§ãƒ©ã‚¤ã‚»ãƒ³ã‚¹ã•ã‚Œã¦ã„ã¾ã™ã€‚

### âš ï¸ åˆ©ç”¨åˆ¶é™ã«ã¤ã„ã¦

**æœ¬ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ã¯å€‹äººã®å­¦ç¿’ç›®çš„ã«é™ã‚Šåˆ©ç”¨å¯èƒ½ã§ã™ã€‚**

**ä»¥ä¸‹ã®ã‚±ãƒ¼ã‚¹ã¯äº‹å‰ã®æ˜ç¤ºçš„ãªè¨±å¯ãªãåˆ©ç”¨ã™ã‚‹ã“ã¨ã‚’å›ºãç¦ã˜ã¾ã™:**

1. **ä¼æ¥­ãƒ»çµ„ç¹”å†…ã§ã®åˆ©ç”¨ï¼ˆå–¶åˆ©ãƒ»éå–¶åˆ©å•ã‚ãšï¼‰**
   - ç¤¾å†…ç ”ä¿®ã€æ•™è‚²ã‚«ãƒªã‚­ãƒ¥ãƒ©ãƒ ã€ç¤¾å†…Wikiã¸ã®è»¢è¼‰
   - å¤§å­¦ãƒ»ç ”ç©¶æ©Ÿé–¢ã§ã®è¬›ç¾©åˆ©ç”¨
   - éå–¶åˆ©å›£ä½“ã§ã®ç ”ä¿®åˆ©ç”¨
   - **ç†ç”±**: çµ„ç¹”å†…åˆ©ç”¨ã§ã¯å¸°å±è¡¨ç¤ºãŒå‰Šé™¤ã•ã‚Œã‚„ã™ãã€ç„¡æ–­æ”¹å¤‰ã®ãƒªã‚¹ã‚¯ãŒé«˜ã„ãŸã‚

2. **æœ‰æ–™ã‚¹ã‚¯ãƒ¼ãƒ«ãƒ»æƒ…å ±å•†æãƒ»ã‚»ãƒŸãƒŠãƒ¼ã§ã®åˆ©ç”¨**
   - å—è¬›æ–™ã‚’å¾´åã™ã‚‹å ´ã§ã®é…å¸ƒã€ã‚¹ã‚¯ãƒªãƒ¼ãƒ³ã‚·ãƒ§ãƒƒãƒˆã®æ²ç¤ºã€æ´¾ç”Ÿæ•™æã®ä½œæˆ

3. **LLM/AIãƒ¢ãƒ‡ãƒ«ã®å­¦ç¿’ãƒ‡ãƒ¼ã‚¿ã¨ã—ã¦ã®åˆ©ç”¨**
   - å•†ç”¨ãƒ¢ãƒ‡ãƒ«ã®Pre-trainingã€Fine-tuningã€RAGã®çŸ¥è­˜ã‚½ãƒ¼ã‚¹ã¨ã—ã¦æœ¬ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ã‚’ã‚¹ã‚¯ãƒ¬ã‚¤ãƒ”ãƒ³ã‚°ãƒ»åˆ©ç”¨ã™ã‚‹ã“ã¨

4. **å‹æ‰‹ã«å†…å®¹ã‚’æœ‰æ–™åŒ–ã™ã‚‹è¡Œç‚ºå…¨èˆ¬**
   - æœ‰æ–™noteã€æœ‰æ–™è¨˜äº‹ã€Kindleå‡ºç‰ˆã€æœ‰æ–™å‹•ç”»ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ã€Patreoné™å®šã‚³ãƒ³ãƒ†ãƒ³ãƒ„ç­‰

**å€‹äººåˆ©ç”¨ã«å«ã¾ã‚Œã‚‹ã‚‚ã®:**
- å€‹äººã®å­¦ç¿’ãƒ»ç ”ç©¶
- å€‹äººçš„ãªãƒãƒ¼ãƒˆä½œæˆï¼ˆå€‹äººåˆ©ç”¨ã«é™ã‚‹ï¼‰
- å‹äººã¸ã®å…ƒè¨˜äº‹ãƒªãƒ³ã‚¯å…±æœ‰

**çµ„ç¹”ã§ã®å°å…¥ã‚’ã”å¸Œæœ›ã®å ´åˆ**ã¯ã€å¿…ãšè‘—è€…ã«é€£çµ¡ã‚’å–ã‚Šã€ä»¥ä¸‹ã‚’éµå®ˆã—ã¦ãã ã•ã„:
- å…¨ã¦ã®å¸°å±è¡¨ç¤ºãƒªãƒ³ã‚¯ã‚’ç¶­æŒ
- åˆ©ç”¨æ–¹æ³•ã‚’è‘—è€…ã«å ±å‘Š

**ç„¡æ–­åˆ©ç”¨ãŒç™ºè¦šã—ãŸå ´åˆ**ã€ä½¿ç”¨æ–™ã®è«‹æ±‚ãŠã‚ˆã³SNSç­‰ã§ã®å…¬è¡¨ã‚’è¡Œã†å ´åˆãŒã‚ã‚Šã¾ã™ã€‚
