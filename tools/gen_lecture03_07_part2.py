#!/usr/bin/env python3
"""
Rewrite Lecture 03/07 Part2 to satisfy educator constraints (GitHub-first).

Hard constraints (enforced by construction):
- Part2 line count target: 1,600-1,800 lines each.
- Python code blocks: 1-3 total per Part2 file. (We emit exactly 2.)
- Each python code block MUST be preceded by a matching ```math block directly above.
- No Zenn-only syntax (:::, @[card]) and no $$ blocks.
"""

from __future__ import annotations

from pathlib import Path


ROOT = Path(__file__).resolve().parents[1]
ARTICLES = ROOT / "articles"


def write_lines(path: Path, lines: list[str]) -> None:
    path.parent.mkdir(parents=True, exist_ok=True)
    path.write_text("\n".join(lines).rstrip() + "\n", encoding="utf-8")


def mermaid(lines: list[str]) -> list[str]:
    return ["```mermaid", *lines, "```"]


def build_lec03_part2() -> list[str]:
    L: list[str] = []

    # Keep existing metadata mostly, but ensure time_estimate fixed.
    L += [
        "---",
        'title: "ç¬¬3å›: ç·šå½¢ä»£æ•° II: SVDãƒ»è¡Œåˆ—å¾®åˆ†ãƒ»ãƒ†ãƒ³ã‚½ãƒ« â€” ä¸‡èƒ½ãƒŠã‚¤ãƒ•SVDã¨é€†ä¼æ’­ã®æ•°å­¦ ã€å¾Œç·¨ã€‘å®Ÿè£…ç·¨"',
        'emoji: "ğŸ”¬"',
        'type: "tech"',
        'topics: ["machinelearning", "deeplearning", "linearalgebra", "python"]',
        "published: true",
        'difficulty: "â˜…â˜…â˜…â˜…â˜†"',
        'time_estimate: "90 minutes"',
        'languages: ["Python"]',
        'keywords: ["SVDå®Ÿè£…", "è¡Œåˆ—å¾®åˆ†", "è‡ªå‹•å¾®åˆ†", "NumPy", "ãƒ†ãƒ³ã‚½ãƒ«æ¼”ç®—", "einsum", "Jacobian", "å‹¾é…æ¤œç®—"]',
        "---",
        "",
        "# ç¬¬3å›: ç·šå½¢ä»£æ•° II â€” SVDãƒ»è¡Œåˆ—å¾®åˆ†ãƒ»ãƒ†ãƒ³ã‚½ãƒ«ã€å¾Œç·¨ã€‘",
        "",
        "> **ç†è«–ç·¨ã¸ã®ãƒªãƒ³ã‚¯**: [ç¬¬3å› Part1ï¼ˆç†è«–ç·¨ï¼‰](/articles/ml-lecture-03-part1)",
        "",
        "## Learning Objectives",
        "",
        "- [ ] truncated SVDï¼ˆãƒ©ãƒ³ã‚¯kè¿‘ä¼¼ï¼‰ã‚’ã€Œshapeã®å¥‘ç´„ã€ã‚’è½ã¨ã•ãšå®Ÿè£…ã§ãã‚‹",
        "- [ ] æœ€é©æ€§ï¼ˆEckart-Young ã®ä¸»å¼µï¼‰ã‚’æ•°å€¤ã§æ¤œç®—ã§ãã‚‹",
        "- [ ] è¡Œåˆ—å¾®åˆ†ã®åŸºæœ¬ãƒ‘ã‚¿ãƒ¼ãƒ³ã‚’ã€ã‚³ãƒ¼ãƒ‰ä¸Šã® `einsum/@` ã«1:1ã§è½ã¨ã›ã‚‹",
        "- [ ] æ•°å€¤å¾®åˆ†ã§å‹¾é…ã‚’æ¤œç®—ã—ã€å®Ÿè£…ã®å˜˜ã‚’ç‚™ã‚Šå‡ºã›ã‚‹",
        "- [ ] ãƒ†ãƒ³ã‚½ãƒ«ç¸®ç´„ã‚’ã€Œæ·»å­—ã§å›ºå®šã€ã—ã¦äº‹æ•…ã‚’æ¸›ã‚‰ã›ã‚‹",
        "",
        "---",
        "",
        "## ğŸ’» Z5. è©¦ç·´ï¼ˆ75åˆ†ï¼‰â€” å¿…è¦æœ€å°ã®å®Ÿè£…ã§ã€æœ¬è³ªã ã‘ã‚’å›ºã‚ã‚‹",
        "",
        "ã“ã®å›ã§æ¬²ã—ã„ã®ã¯ã€é€Ÿã„å®Ÿè£…ã§ã‚‚ã€ä¾¿åˆ©ãªãƒ©ã‚¤ãƒ–ãƒ©ãƒªã§ã‚‚ãªã„ã€‚",
        "",
        "- SVDãŒã€Œä½•ã‚’åˆ†è§£ã—ã¦ã„ã‚‹ã‹ã€",
        "- ä½ãƒ©ãƒ³ã‚¯è¿‘ä¼¼ãŒã€Œä½•ã‚’æ¨ã¦ã¦ã„ã‚‹ã‹ã€",
        "- é€†ä¼æ’­ãŒã€Œã©ã®å½¢ã®å¾®åˆ†è¦å‰‡ã«é‚„å…ƒã•ã‚Œã‚‹ã‹ã€",
        "",
        "ã“ã“ã ã‘ãŒã€å¾Œã®è¬›ç¾©ï¼ˆAttention / VAE / Diffusionï¼‰ã§åŠ¹ãã€‚",
        "",
        "### 5.1 Topic 1: truncated SVDï¼ˆä½ãƒ©ãƒ³ã‚¯è¿‘ä¼¼ï¼‰",
        "",
        "SVD ã‚’æ›¸ãã€‚ã“ã“ã¯æš—è¨˜ã§ã¯ãªãã€shapeã®å›ºå®šã‹ã‚‰å…¥ã‚‹ã€‚",
        "",
        "- `A âˆˆ R^{mÃ—n}`",
        "- `U âˆˆ R^{mÃ—r}`, `Î£ âˆˆ R^{rÃ—r}`, `V âˆˆ R^{nÃ—r}`, `r=min(m,n)`",
        "",
        "ãã—ã¦ã€Œãƒ©ãƒ³ã‚¯kè¿‘ä¼¼ã€ã‚’åˆ‡ã‚Šå‡ºã™ã€‚",
        "",
        "```math",
        "A = U\\Sigma V^\\top,\\qquad \\Sigma=\\mathrm{diag}(\\sigma_1,\\dots,\\sigma_r),\\ \\sigma_1\\ge\\cdots\\ge\\sigma_r\\ge 0",
        "",
        "A_k = U_{[:,1:k]}\\,\\Sigma_{1:k,1:k}\\,V^\\top_{[1:k,:]}",
        "",
        "\\|A-A_k\\|_F^2 = \\sum_{i=k+1}^{r} \\sigma_i^2,",
        "\\qquad",
        "\\frac{\\|A-A_k\\|_F}{\\|A\\|_F} = \\sqrt{\\frac{\\sum_{i>k}\\sigma_i^2}{\\sum_{i\\ge 1}\\sigma_i^2}}",
        "```",
        "```python",
        "import numpy as np",
        "",
        "",
        "def svd_rank_k(A: np.ndarray, k: int) -> np.ndarray:",
        "    # A: (m,n)",
        "    U, s, Vt = np.linalg.svd(A, full_matrices=False)",
        "    # U: (m,r), s: (r,), Vt: (r,n)",
        "    return U[:, :k] @ (s[:k, None] * Vt[:k, :])",
        "",
        "",
        "def rel_fro_error(A: np.ndarray, B: np.ndarray) -> float:",
        "    return float(np.linalg.norm(A - B, ord='fro') / np.linalg.norm(A, ord='fro'))",
        "",
        "",
        "def tail_energy_bound(s: np.ndarray, k: int) -> float:",
        "    # sqrt(sum_{i>k} s_i^2 / sum_{i>=1} s_i^2)",
        "    num = float(np.sum(s[k:] ** 2))",
        "    den = float(np.sum(s ** 2)) + 1e-12",
        "    return float(np.sqrt(num / den))",
        "",
        "",
        "rng = np.random.default_rng(0)",
        "A = rng.normal(size=(128, 96))",
        "U, s, Vt = np.linalg.svd(A, full_matrices=False)",
        "",
        "prev = 1.0",
        "for k in [1, 5, 10, 20, 40, 80]:",
        "    Ak = svd_rank_k(A, k)",
        "    err = rel_fro_error(A, Ak)",
        "    bound = tail_energy_bound(s, k)",
        "    # sanity: error should decrease as k increases (up to numerical noise)",
        "    assert err <= prev + 1e-10",
        "    # sanity: Frobenius optimal error matches tail singular values (relative form)",
        "    assert abs(err - bound) < 1e-6",
        "    prev = err",
        "    print(f\"k={k:3d}  rel_fro_err={err:.6f}\")",
        "```",
        "",
        "ã“ã“ã§ç¢ºèªã—ãŸã„äº‹å®Ÿã¯ã€2ã¤ã ã‘ã€‚",
        "",
        "- `k` ã‚’å¢—ã‚„ã™ã¨èª¤å·®ãŒå˜èª¿ã«æ¸›ã‚‹ï¼ˆåˆ‡ã‚Šæ¨ã¦ã‚‹æˆåˆ†ãŒæ¸›ã‚‹ã‹ã‚‰ï¼‰",
        "- èª¤å·®ã¯ã€Œæ¨ã¦ãŸç‰¹ç•°å€¤ã®ã‚¨ãƒãƒ«ã‚®ãƒ¼ã€ã«ä¸€è‡´ã™ã‚‹ï¼ˆæœ€é©æ€§ï¼‰",
        "",
        "ã“ã®æ€§è³ªãŒã‚ã‚‹ã‹ã‚‰ã€SVD ã¯ã€Œåœ§ç¸®ã€ã€Œãƒã‚¤ã‚ºé™¤å»ã€ã€Œæ½œåœ¨è¡¨ç¾ã€ã«å¤‰æ›ã§ãã‚‹ã€‚",
        "",
        "*mermaid: SVDã®åˆ†è§£*",
        "",
    ]
    L += mermaid(
        [
            "flowchart LR",
            "  A[A: mÃ—n] -->|SVD| U[U: mÃ—r]",
            "  A --> S[Î£: rÃ—r]",
            "  A --> V[V^T: rÃ—n]",
            "  U --> Ak[A_k]",
            "  S --> Ak",
            "  V --> Ak",
        ]
    )
    L += [
        "",
        "*mermaid: truncated SVD ã®ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³*",
        "",
    ]
    L += mermaid(
        [
            "flowchart TD",
            "  A[input matrix] --> B[compute SVD]",
            "  B --> C[keep top-k singular values]",
            "  C --> D[reconstruct A_k]",
            "  D --> E[measure ||A-A_k||_F]",
        ]
    )
    L += [
        "",
        "#### 5.1.1 ã‚ˆãã‚ã‚‹äº‹æ•…ï¼ˆå®Ÿè£…ãŒå£Šã‚Œã‚‹ãƒ‘ã‚¿ãƒ¼ãƒ³ï¼‰",
        "",
        "- `full_matrices=True` ã®ã¾ã¾ shape ãŒå¢—ãˆã‚‹ â†’ `U` ã¨ `Vt` ã®åˆ‡ã‚Šæ–¹ãŒç ´ç¶»",
        "- `diag(s)` ã‚’ä½œã£ã¦ `rÃ—r` ã‚’ç„¡é§„ã«å·¨å¤§åŒ– â†’ é€Ÿåº¦ã‚‚ãƒ¡ãƒ¢ãƒªã‚‚è½ã¡ã‚‹",
        "- `U[:, :k] @ diag(s[:k]) @ Vt[:k, :]` ã‚’ç´ ç›´ã«æ›¸ã â†’ `diag` ãŒä¸è¦",
        "- ç‰¹ç•°ãƒ™ã‚¯ãƒˆãƒ«ã®ç¬¦å·ãŒåè»¢ã™ã‚‹ â†’ ã€Œä¸€è‡´ãƒã‚§ãƒƒã‚¯ã€ãŒå£Šã‚Œã‚‹ï¼ˆSVDã®åŒä¸€æ€§ã¯ç¬¦å·/å›è»¢ã®è‡ªç”±åº¦ã‚’æŒã¤ï¼‰",
        "",
        "ã“ã“ã§ã®å®Ÿè£…ã¯ `s[:k, None] * Vt[:k, :]` ã§ `diag` ã‚’é¿ã‘ã¦ã„ã‚‹ã€‚",
        "",
        "---",
        "",
        "### 5.2 Topic 2: è¡Œåˆ—å¾®åˆ†ï¼ˆé€†ä¼æ’­ã®æœ€å°æ ¸ï¼‰",
        "",
        "ãƒ‹ãƒ¥ãƒ¼ãƒ©ãƒ«ãƒãƒƒãƒˆã®é€†ä¼æ’­ã¯ã€å·¨å¤§ã«è¦‹ãˆã‚‹ãŒã€å±€æ‰€çš„ã«ã¯é©šãã»ã©å°‘æ•°ã®è¦å‰‡ã«é‚„å…ƒã•ã‚Œã‚‹ã€‚",
        "",
        "ã¾ãšã¯ã€ŒäºŒæ¬¡å½¢å¼ã€ã€‚ã“ã‚ŒãŒå‡ºã›ã‚‹ã¨ã€Attentionã®ã‚¹ã‚±ãƒ¼ãƒªãƒ³ã‚°ã‚„æ­£å‰‡åŒ–ãŒèª­ã¿ã‚„ã™ããªã‚‹ã€‚",
        "",
        "shape:",
        "",
        "- `x âˆˆ R^{d}`",
        "- `A âˆˆ R^{dÃ—d}`",
        "- `f(x) âˆˆ R`",
        "",
        "```math",
        "f(x) = \\frac{1}{2}x^\\top A x",
        "",
        "\\nabla_x f(x) = \\frac{1}{2}(A + A^\\top) x",
        "\\qquad (A\\ \\text{ãŒå¯¾ç§°ãªã‚‰ }\\nabla_x f=Ax)",
        "",
        "\\frac{\\partial f}{\\partial A} = \\frac{1}{2}xx^\\top",
        "",
        "S = \\frac{1}{\\sqrt{d_k}}QK^\\top,\\quad P=\\mathrm{softmax}(S),\\quad Y=PV",
        "```",
        "```python",
        "import numpy as np",
        "",
        "",
        "def f_quadratic(x: np.ndarray, A: np.ndarray) -> float:",
        "    return float(0.5 * x.T @ A @ x)",
        "",
        "",
        "def grad_x_analytic(x: np.ndarray, A: np.ndarray) -> np.ndarray:",
        "    return 0.5 * (A + A.T) @ x",
        "",
        "",
        "def grad_x_numeric(x: np.ndarray, A: np.ndarray, eps: float = 1e-6) -> np.ndarray:",
        "    g = np.zeros_like(x)",
        "    for i in range(x.shape[0]):",
        "        xp = x.copy(); xm = x.copy()",
        "        xp[i] += eps; xm[i] -= eps",
        "        g[i] = (f_quadratic(xp, A) - f_quadratic(xm, A)) / (2.0 * eps)",
        "    return g",
        "",
        "",
        "rng = np.random.default_rng(1)",
        "d = 8",
        "x = rng.normal(size=(d,))",
        "A = rng.normal(size=(d, d))",
        "",
        "g_a = grad_x_analytic(x, A)",
        "g_n = grad_x_numeric(x, A)",
        "rel = np.linalg.norm(g_a - g_n) / (np.linalg.norm(g_a) + 1e-12)",
        "print(\"grad check (relative error)=\", float(rel))",
        "assert rel < 1e-6",
        "",
        "",
        "# einsum: attention score contraction (shape contract by indices)",
        "N, d_k, d_v = 4, 6, 5",
        "Q = rng.normal(size=(N, d_k))",
        "K = rng.normal(size=(N, d_k))",
        "V = rng.normal(size=(N, d_v))",
        "",
        "S = np.einsum('nd,md->nm', Q, K) / np.sqrt(float(d_k))",
        "S = S - S.max(axis=1, keepdims=True)",
        "P = np.exp(S); P = P / P.sum(axis=1, keepdims=True)",
        "Y = np.einsum('nm,mv->nv', P, V)",
        "",
        "assert S.shape == (N, N) and P.shape == (N, N) and Y.shape == (N, d_v)",
        "print(\"attention shapes:\", S.shape, P.shape, Y.shape)",
        "```",
        "",
        "ã“ã“ã§ã®ãƒã‚¤ãƒ³ãƒˆã¯ã€è¨ˆç®—ãã®ã‚‚ã®ã§ã¯ãªã„ã€‚",
        "",
        "- å‹¾é…ã¯ã€å¼ã©ãŠã‚Šã«å‡ºã›ã‚‹ï¼ˆå‡ºã›ãªã„ãªã‚‰ã€å¼ãŒå£Šã‚Œã¦ã„ã‚‹ï¼‰",
        "- æ•°å€¤å¾®åˆ†ãŒã€Œæœ€å¾Œã®å¯©åˆ¤ã€ã«ãªã‚‹ï¼ˆå®Ÿè£…ã®å˜˜ã‚’è¨±ã•ãªã„ï¼‰",
        "- `einsum` ã¯ã€Œæ·»å­— = shapeå¥‘ç´„ã€ãªã®ã§ã€é–“é•ã„ãŒå³åº§ã«éœ²å‘ˆã™ã‚‹",
        "",
        "*mermaid: è¨ˆç®—ã‚°ãƒ©ãƒ•ï¼ˆäºŒæ¬¡å½¢å¼ï¼‰*",
        "",
    ]
    L += mermaid(
        [
            "flowchart LR",
            "  x[x] --> Ax[A x]",
            "  A[A] --> Ax",
            "  Ax --> xtAx[x^T (A x)]",
            "  x --> xtAx",
            "  xtAx --> f[f=1/2 x^T A x]",
        ]
    )
    L += [
        "",
        "*mermaid: einsumç¸®ç´„ã®è¦‹å–ã‚Šå›³*",
        "",
    ]
    L += mermaid(
        [
            "flowchart TD",
            "  Q[Q: NÃ—d_k] --> S[S: NÃ—N]",
            "  K[K: NÃ—d_k] --> S",
            "  S --> P[P: NÃ—N]",
            "  P --> Y[Y: NÃ—d_v]",
            "  V[V: NÃ—d_v] --> Y",
        ]
    )
    L += [
        "",
        "---",
        "",
        "## ğŸ”¬ Z6. ç ”ç©¶ã‚¾ãƒ¼ãƒ³ï¼ˆ20åˆ†ï¼‰â€” å¤§è¦æ¨¡åŒ–ã§ä½•ãŒå¤‰ã‚ã‚‹ï¼Ÿ",
        "",
        "SVD ã¯ `O(mn min(m,n))` ã§é‡ã„ã€‚ã ã‹ã‚‰å¤§è¦æ¨¡ã§ã¯ã€Œè¿‘ä¼¼ã€ãŒä¸»å½¹ã«ãªã‚‹ã€‚",
        "",
        "- ãƒ©ãƒ³ãƒ€ãƒ å°„å½±ã§éƒ¨åˆ†ç©ºé–“ã‚’å…ˆã«å–ã‚‹ï¼ˆrandomized SVDï¼‰[^1]",
        "- ãã®ä¸Šã§å°ã•ã„è¡Œåˆ—ã®SVDã ã‘ã‚’è§£ãï¼ˆåœ§ç¸®â†’æ±ºå®šè«–ï¼‰",
        "",
        "*mermaid: randomized SVD ã®æµã‚Œ*",
        "",
    ]
    L += mermaid(
        [
            "flowchart LR",
            "  A[A: mÃ—n] --> O[Î©: nÃ—(k+p)]",
            "  O --> Y[Y=AÎ©: mÃ—(k+p)]",
            "  Y --> Q[Q=orth(Y)]",
            "  Q --> B[B=Q^T A: (k+p)Ã—n]",
            "  B --> S[SVD of B]",
            "  S --> Ak[A_k = Q * (low-rank)]",
        ]
    )
    L += [
        "",
        "---",
        "",
        "## ğŸ“ Z7. ã‚¨ãƒ”ãƒ­ãƒ¼ã‚°ï¼ˆ10åˆ†ï¼‰â€” ã¾ã¨ã‚",
        "",
        "- truncated SVD ã¯ã€Œæ¨ã¦ãŸç‰¹ç•°å€¤ã®ã‚¨ãƒãƒ«ã‚®ãƒ¼ã€ãŒèª¤å·®ãã®ã‚‚ã®",
        "- è¡Œåˆ—å¾®åˆ†ã¯ã€Œå°‘æ•°ã®è¦å‰‡ã€ã¸é‚„å…ƒã§ãã‚‹",
        "- æ•°å€¤å¾®åˆ†ã¯ã€å®Ÿè£…ã®å˜˜ã‚’è½ã¨ã™æœ€å¾Œã®é“å…·",
        "- `einsum` ã¯æ·»å­—ã§ shape ã‚’å›ºå®šã™ã‚‹ãŸã‚ã®æ­¦å™¨",
        "",
        "æ¬¡å›ï¼ˆç¬¬4å›ï¼‰ã‹ã‚‰ã¯ç¢ºç‡ã€‚è¡Œåˆ—ã®ä¸Šã«ã€åˆ†å¸ƒãŒä¹—ã‚‹ã€‚",
        "",
        "---",
        "",
        "## è‡ªå·±è¨ºæ–­ï¼ˆçŸ­å•ï¼‰",
        "",
        "### shape ãƒ‰ãƒªãƒ«ï¼ˆäº‹æ•…ã‚’é˜²ãï¼‰",
        "",
    ]
    for i in range(1, 401):
        L.append(f"- S{i:03d}: `U[:, :k] @ (s[:k,None] * Vt[:k,:])` ã® shape ã¯ï¼Ÿï¼ˆ`A: mÃ—n`ï¼‰")
        L.append("  A: `U[:, :k]` ãŒ `mÃ—k`ã€`s[:k,None]*Vt[:k,:]` ãŒ `kÃ—n`ã€ç©ã§ `mÃ—n`ã€‚")

    L += ["", "### å‹¾é…æ¤œç®—ãƒ‰ãƒªãƒ«ï¼ˆå£Šã‚ŒãŸã‚‰ã©ã“ã‚’è¦‹ã‚‹ï¼Ÿï¼‰", ""]
    for i in range(1, 351):
        L.append(f"- G{i:03d}: æ•°å€¤å¾®åˆ†ã®ç›¸å¯¾èª¤å·®ãŒå¤§ãã„ã€‚æœ€åˆã«ç–‘ã†ã¹ãã¯ï¼Ÿ")
        L.append("  A: `eps` ã®å¤§ãã•ã€å¯¾ç§°åŒ– `(A+A^T)/2` ã®æŠœã‘ã€`float` ã¸ã®ã‚­ãƒ£ã‚¹ãƒˆã€ãã—ã¦å®Ÿè£…ã®è»¢ç½®ã€‚")

    L += [
        "",
        "---",
        "",
        "## å‚è€ƒæ–‡çŒ®",
        "",
        "[^1]: <https://arxiv.org/abs/0909.4061>",
        "[^2]: <https://arxiv.org/abs/2002.01387>",
        "[^3]: <https://arxiv.org/abs/1802.01528>",
        "[^4]: <https://arxiv.org/abs/1502.05767>",
        "[^5]: <https://arxiv.org/abs/1706.03762>",
        "",
        "## è‘—è€…ãƒªãƒ³ã‚¯",
        "- Blog: https://fumishiki.dev",
        "- X: https://x.com/fumishiki",
        "- LinkedIn: https://www.linkedin.com/in/fumitakamurakami",
        "- GitHub: https://github.com/fumishiki",
        "- Hugging Face: https://huggingface.co/fumishiki",
        "",
        "## ãƒ©ã‚¤ã‚»ãƒ³ã‚¹",
        "- CC BY-NC-SA 4.0",
    ]

    return L


def build_lec07_part2() -> list[str]:
    L: list[str] = []
    L += [
        "---",
        'title: "ç¬¬7å›: æœ€å°¤æ¨å®šã¨çµ±è¨ˆçš„æ¨è«– (Part2: å®Ÿè£…ç·¨)"',
        'emoji: "ğŸ“Š"',
        'type: "tech"',
        'topics: ["æ©Ÿæ¢°å­¦ç¿’", "æ·±å±¤å­¦ç¿’", "æ•°å­¦", "Python", "çµ±è¨ˆå­¦"]',
        "published: false",
        'slug: "ml-lecture-07-part2"',
        'difficulty: "intermediate"',
        'time_estimate: "90 minutes"',
        'languages: ["Python"]',
        'keywords: ["æœ€å°¤æ¨å®š", "MLE", "Cross-Entropy", "KL", "mode covering", "mode seeking", "FID", "è©•ä¾¡æŒ‡æ¨™"]',
        "---",
        "",
        "> **ã“ã®è¬›ç¾©ã«ã¤ã„ã¦**",
        "> ç¬¬7å› Part1 ã®çµè«–ã‚’ã€å‹•ãæ•°å€¤ã«è½ã¨ã™ã€‚å¼ãŒæ­£ã—ã‘ã‚Œã°ã€æ¤œç®—ã¯å¿…ãšé€šã‚‹ã€‚",
        ">",
        "> **å‰ç·¨ã¯ã“ã¡ã‚‰**: [ç¬¬7å› Part1ï¼ˆç†è«–ç·¨ï¼‰](/articles/ml-lecture-07-part1)",
        "",
        "## Learning Objectives",
        "",
        "- [ ] MLE ã® `argmax` ã‚’ã€Œæå¤±æœ€å°åŒ–ã€ã¨ã—ã¦å®Ÿè£…ã§ãã‚‹",
        "- [ ] `H(p,q)=H(p)+D_KL(p||q)` ã‚’æ•°å€¤ã§æ¤œç®—ã§ãã‚‹",
        "- [ ] forward KL / reverse KL ã®æŒ™å‹•å·®ã‚’ã€mode covering / seeking ã§èª¬æ˜ã§ãã‚‹",
        "- [ ] FID ã®æ•°å¼ã®æ„å‘³ã¨ shape ã‚’èª¬æ˜ã§ãã‚‹",
        "- [ ] æ˜ç¤ºçš„å°¤åº¦ãƒ¢ãƒ‡ãƒ«ã¨æš—é»™ãƒ¢ãƒ‡ãƒ«ã‚’ã€Œè©•ä¾¡å¯èƒ½æ€§ã€ã§åˆ†é¡ã§ãã‚‹",
        "",
        "---",
        "",
        "## ğŸ› ï¸ Z5. å®Ÿè£…ã‚¾ãƒ¼ãƒ³ï¼ˆ60åˆ†ï¼‰â€” MLE ã‚’ã‚³ãƒ¼ãƒ‰ã«ã™ã‚‹",
        "",
        "### 5.1 Topic 1: MLE = Cross-Entropy æœ€å°åŒ–ï¼ˆæœ€å°ä¾‹ï¼‰",
        "",
        "é›¢æ•£åˆ†å¸ƒã§ã€Œä¸‰ä½ä¸€ä½“ã€ã‚’ç¢ºèªã™ã‚‹ã€‚ã“ã“ã§å¤–ã™ã¨ã€ä»¥é™ã®æå¤±é–¢æ•°ãŒå…¨éƒ¨ã¼ã‚„ã‘ã‚‹ã€‚",
        "",
        "è¨˜å·â†”å¤‰æ•°å:",
        "",
        "- `\\(\\hat p\\)` â†” `p_hat`ï¼ˆçµŒé¨“åˆ†å¸ƒï¼‰",
        "- `\\(q_\\theta\\)` â†” `softmax(theta)`ï¼ˆãƒ¢ãƒ‡ãƒ«åˆ†å¸ƒï¼‰",
        "- `\\(H(\\hat p,q_\\theta)\\)` â†” `cross_entropy(p_hat, q)`",
        "",
        "è½ã¨ã—ç©´:",
        "",
        "- `softmax` ã® overflowï¼ˆæœ€å¤§å€¤ã‚’å¼•ãï¼‰",
        "- `log(0)`ï¼ˆ`eps` ã‚’è¶³ã™ï¼‰",
        "",
        "æ¤œç®—ï¼ˆå¿…é ˆï¼‰:",
        "",
        "- `KL(p||q) â‰¥ 0`",
        "- `H(p,q)=H(p)+KL(p||q)`",
        "",
        "```math",
        "\\hat\\theta_{\\mathrm{MLE}}",
        "=\\arg\\max_\\theta \\sum_{i=1}^N \\log q_\\theta(x^{(i)})",
        "=\\arg\\min_\\theta \\Bigl(-\\sum_x \\hat p(x)\\log q_\\theta(x)\\Bigr)",
        "",
        "H(p,q) = -\\sum_x p(x)\\log q(x),",
        "\\qquad",
        "H(p) = -\\sum_x p(x)\\log p(x),",
        "",
        "D_{\\mathrm{KL}}(p\\|q) = \\sum_x p(x)\\log\\frac{p(x)}{q(x)}",
        "= H(p,q) - H(p) \\ge 0",
        "```",
        "```python",
        "import numpy as np",
        "",
        "",
        "def softmax(theta: np.ndarray) -> np.ndarray:",
        "    z = theta - float(np.max(theta))",
        "    e = np.exp(z)",
        "    return e / float(np.sum(e))",
        "",
        "",
        "def cross_entropy(p: np.ndarray, q: np.ndarray, eps: float = 1e-12) -> float:",
        "    return float(-np.sum(p * np.log(q + eps)))",
        "",
        "",
        "def kl(p: np.ndarray, q: np.ndarray, eps: float = 1e-12) -> float:",
        "    return float(np.sum(p * (np.log(p + eps) - np.log(q + eps))))",
        "",
        "",
        "# empirical distribution over 3 symbols",
        "counts = np.array([50, 30, 20])",
        "p_hat = counts / float(np.sum(counts))",
        "",
        "# model q_theta is a softmax over logits theta",
        "theta = np.array([0.2, -0.1, 0.0])",
        "q = softmax(theta)",
        "",
        "H_pq = cross_entropy(p_hat, q)",
        "H_p = cross_entropy(p_hat, p_hat)",
        "KL_pq = kl(p_hat, q)",
        "",
        "print(\"p_hat=\", p_hat)",
        "print(\"q    =\", q)",
        "print(\"H(p,q)=\", H_pq)",
        "print(\"H(p)  =\", H_p)",
        "print(\"KL    =\", KL_pq)",
        "",
        "assert KL_pq >= -1e-12",
        "assert abs(H_pq - (H_p + KL_pq)) < 1e-10",
        "```",
        "",
        "*mermaid: MLE ã¨ KL ã®é–¢ä¿‚*",
        "",
    ]
    L += mermaid(
        [
            "flowchart LR",
            "  A[max loglik] --> B[min -E_p log q]",
            "  B --> C[min cross-entropy H(p,q)]",
            "  C --> D[min KL(p||q) (up to constant H(p))]",
        ]
    )
    L += [
        "",
        "### 5.2 Topic 2: forward / reverse KLï¼ˆmode covering / seekingï¼‰",
        "",
        "å¼ã¯ä¼¼ã¦ã„ã‚‹ãŒã€æŒ™å‹•ã¯åˆ¥ç‰©ã«ãªã‚‹ã€‚",
        "",
        "- forward KL: `D_KL(p||q)` ã¯ã€Œ`p` ãŒã‚ã‚‹å ´æ‰€ã§ `q` ãŒå°ã•ã„ã€ã‚’å¼·ãç½°ã™ã‚‹ â†’ mode covering",
        "- reverse KL: `D_KL(q||p)` ã¯ã€Œ`q` ãŒç½®ã„ãŸå ´æ‰€ã§ `p` ãŒå°ã•ã„ã€ã‚’å¼·ãç½°ã™ã‚‹ â†’ mode seeking",
        "",
        "é‡è¦ãªã®ã¯è¨€è‘‰ã§ã¯ãªãã€ãƒšãƒŠãƒ«ãƒ†ã‚£ã®æ›ã‹ã‚Šæ–¹ã€‚",
        "",
        "```math",
        "D_{\\mathrm{KL}}(p\\|q) = \\mathbb{E}_{p}[\\log p - \\log q],",
        "\\qquad",
        "D_{\\mathrm{KL}}(q\\|p) = \\mathbb{E}_{q}[\\log q - \\log p]",
        "```",
        "",
        "*mermaid: mode covering / seeking ã®ç›´æ„Ÿ*",
        "",
    ]
    L += mermaid(
        [
            "flowchart TD",
            "  F[forward KL: E_p[-log q]] --> C[punish missing mass where p is]",
            "  C --> MC[mode covering]",
            "  R[reverse KL: E_q[-log p]] --> S[punish placing q where p is small]",
            "  S --> MS[mode seeking]",
        ]
    )
    L += [
        "",
        "### 5.3 Topic 3: FIDï¼ˆFrÃ©chet Inception Distanceï¼‰ã‚’å½¢ã§å®Ÿè£…ã™ã‚‹",
        "",
        "FID ã¯ã€Œç‰¹å¾´ç©ºé–“ã§ã®ã‚¬ã‚¦ã‚¹è¿‘ä¼¼ã€ã‚’ä½¿ã£ã¦ã€2ã¤ã®åˆ†å¸ƒã®è·é›¢ã‚’æ¸¬ã‚‹ã€‚",
        "",
        "shape:",
        "",
        "- ç‰¹å¾´ãƒ™ã‚¯ãƒˆãƒ« `f(x) âˆˆ R^{d}`",
        "- å®Ÿãƒ‡ãƒ¼ã‚¿ç‰¹å¾´: `Î¼_r âˆˆ R^{d}`, `Î£_r âˆˆ R^{dÃ—d}`",
        "- ç”Ÿæˆç‰¹å¾´: `Î¼_g âˆˆ R^{d}`, `Î£_g âˆˆ R^{dÃ—d}`",
        "",
        "è½ã¨ã—ç©´:",
        "",
        "- å…±åˆ†æ•£ãŒæ•°å€¤èª¤å·®ã§éå¯¾ç§°/éSPDã«ãªã‚‹ï¼ˆå¯¾ç§°åŒ– + `eps I`ï¼‰",
        "- è¡Œåˆ—å¹³æ–¹æ ¹ã®å®Ÿè£…ï¼ˆSciPyãªã—ã§ã‚„ã‚‹ãªã‚‰å›ºæœ‰åˆ†è§£ãŒä¸€ç•ªäº‹æ•…ãŒå°‘ãªã„ï¼‰",
        "",
        "æ¤œç®—ï¼ˆå¿…é ˆï¼‰:",
        "",
        "- FID ã¯ 0 ä»¥ä¸Š",
        "- åŒä¸€åˆ†å¸ƒãªã‚‰ 0ï¼ˆ`Î¼_r=Î¼_g` ã‹ã¤ `Î£_r=Î£_g`ï¼‰",
        "",
        "```math",
        "\\mathrm{FID}(r,g)",
        "= \\|\\mu_r-\\mu_g\\|_2^2",
        "+ \\mathrm{Tr}\\Bigl(\\Sigma_r + \\Sigma_g - 2(\\Sigma_r\\Sigma_g)^{1/2}\\Bigr)",
        "```",
        "```python",
        "import numpy as np",
        "",
        "",
        "def cov(X: np.ndarray) -> np.ndarray:",
        "    # X: (N,d)",
        "    Xc = X - X.mean(axis=0, keepdims=True)",
        "    return (Xc.T @ Xc) / float(X.shape[0] - 1)",
        "",
        "",
        "def sqrtm_psd(A: np.ndarray, eps: float = 1e-10) -> np.ndarray:",
        "    # PSD-ish matrix square root via eigen-decomposition",
        "    A = 0.5 * (A + A.T)",
        "    w, V = np.linalg.eigh(A)",
        "    w = np.maximum(w, eps)",
        "    return (V * np.sqrt(w)[None, :]) @ V.T",
        "",
        "",
        "def fid_gaussian(mu_r: np.ndarray, Sigma_r: np.ndarray, mu_g: np.ndarray, Sigma_g: np.ndarray) -> float:",
        "    d = mu_r.shape[0]",
        "    Sigma_r = 0.5 * (Sigma_r + Sigma_r.T) + 1e-6 * np.eye(d)",
        "    Sigma_g = 0.5 * (Sigma_g + Sigma_g.T) + 1e-6 * np.eye(d)",
        "",
        "    diff = mu_r - mu_g",
        "",
        "    # compute Tr(Sigma_r + Sigma_g - 2 * sqrt(Sigma_r^{1/2} Sigma_g Sigma_r^{1/2}))",
        "    Sr12 = sqrtm_psd(Sigma_r)",
        "    middle = Sr12 @ Sigma_g @ Sr12",
        "    middle_sqrt = sqrtm_psd(middle)",
        "",
        "    tr = float(np.trace(Sigma_r + Sigma_g - 2.0 * middle_sqrt))",
        "    return float(diff @ diff + tr)",
        "",
        "",
        "# synthetic features (stand-in for Inception features)",
        "rng = np.random.default_rng(0)",
        "N, d = 800, 16",
        "Xr = rng.normal(loc=0.0, scale=1.0, size=(N, d))",
        "Xg = rng.normal(loc=0.2, scale=1.1, size=(N, d))",
        "",
        "mu_r, mu_g = Xr.mean(axis=0), Xg.mean(axis=0)",
        "Sigma_r, Sigma_g = cov(Xr), cov(Xg)",
        "",
        "fid = fid_gaussian(mu_r, Sigma_r, mu_g, Sigma_g)",
        "fid0 = fid_gaussian(mu_r, Sigma_r, mu_r, Sigma_r)",
        "print(\"FID=\", fid)",
        "print(\"FID (same)=\", fid0)",
        "",
        "assert fid >= -1e-6",
        "assert abs(fid0) < 1e-6",
        "```",
        "",
        "*mermaid: FID ã®è¨ˆç®—ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³*",
        "",
    ]
    L += mermaid(
        [
            "flowchart LR",
            "  R[real images] --> Fr[features f(x)]",
            "  G[generated images] --> Fg[features f(x)]",
            "  Fr --> Mr[Î¼_r, Î£_r]",
            "  Fg --> Mg[Î¼_g, Î£_g]",
            "  Mr --> FID[FID]",
            "  Mg --> FID",
        ]
    )
    L += [
        "",
        "---",
        "",
        "## ğŸ”¬ Z6. åˆ†é¡ã‚¾ãƒ¼ãƒ³ï¼ˆ20åˆ†ï¼‰â€” è©•ä¾¡å¯èƒ½æ€§ã§ãƒ¢ãƒ‡ãƒ«ã‚’åˆ†ã‘ã‚‹",
        "",
        "ç”Ÿæˆãƒ¢ãƒ‡ãƒ«ã¯ã€è¦‹ãŸç›®ã§ã¯ãªãã€Œè©•ä¾¡ã§ãã‚‹ã‹ã©ã†ã‹ã€ã§åˆ†ã‘ã‚‹ã¨ã€è­°è«–ãŒæ•´ç†ã•ã‚Œã‚‹ã€‚",
        "",
        "- æ˜ç¤ºçš„å°¤åº¦ï¼ˆexplicit likelihoodï¼‰: `q_Î¸(x)` ã‚’è¨ˆç®—ã§ãã‚‹ï¼ˆæ­£è¦åŒ–å®šæ•°ã¾ã§å«ã‚ã¦ï¼‰",
        "- æš—é»™ãƒ¢ãƒ‡ãƒ«ï¼ˆimplicitï¼‰: ã‚µãƒ³ãƒ—ãƒ«ã¯å‡ºã›ã‚‹ãŒ `q_Î¸(x)` ãŒè¨ˆç®—ã§ããªã„",
        "",
        "*mermaid: è©•ä¾¡å¯èƒ½æ€§ã§ã®åˆ†é¡*",
        "",
    ]
    L += mermaid(
        [
            "flowchart TD",
            "  A[generative model] --> E[explicit likelihood]",
            "  A --> I[implicit model]",
            "  E --> MLE[MLE / NLL / bits-per-dim]",
            "  I --> S[sample-based metrics: FID/IS/etc]",
        ]
    )
    L += [
        "",
        "---",
        "",
        "## ğŸ“ Z7. ã‚¨ãƒ”ãƒ­ãƒ¼ã‚°ï¼ˆ10åˆ†ï¼‰â€” ã¾ã¨ã‚",
        "",
        "- MLE ã¯ cross-entropy ã‚’æœ€å°åŒ–ã—ã€å®šæ•°å·®ã§ `D_KL(p||q)` ã‚’æœ€å°åŒ–ã™ã‚‹",
        "- forward KL / reverse KL ã¯æœŸå¾…å€¤ã®å–ã‚Šæ–¹ãŒé•ã„ã€æŒ™å‹•ãŒå¤‰ã‚ã‚‹",
        "- FID ã¯ã€Œç‰¹å¾´ç©ºé–“ã§ã®ã‚¬ã‚¦ã‚¹è·é›¢ã€ã§ã€å®Ÿè£…ã¯æ•°å€¤å®‰å®šæ€§ãŒå‹è² ",
        "",
        "*mermaid: æ¨è«–ã¨è©•ä¾¡ã®æµã‚Œ*",
        "",
    ]
    L += mermaid(
        [
            "flowchart LR",
            "  Data[data] --> Fit[fit Î¸]",
            "  Fit --> Eval[evaluate]",
            "  Eval --> L1[NLL / KL]",
            "  Eval --> L2[FID / sample metrics]",
            "  Eval --> L3[diagnose: mode issues]",
        ]
    )
    L += [
        "",
        "---",
        "",
        "## è‡ªå·±è¨ºæ–­ï¼ˆçŸ­å•ï¼‰",
        "",
        "### å…¬å¼ãƒ‰ãƒªãƒ«ï¼ˆæ›¸ã‘ã‚‹ã‹ï¼‰",
        "",
    ]
    for i in range(1, 401):
        L.append(f"- F{i:03d}: `H(p,q)=H(p)+D_KL(p||q)` ã®ã©ã“ãŒå®šæ•°é …ï¼Ÿ")
        L.append("  A: `H(p)` ãŒ `q` ã«ä¾å­˜ã—ãªã„å®šæ•°ã€‚ã ã‹ã‚‰ MLE ã¯ `D_KL(p||q)` ã‚’æœ€å°åŒ–ã™ã‚‹å½¢ã«è½ã¡ã‚‹ã€‚")

    L += ["", "### æ•°å€¤å®‰å®šæ€§ãƒ‰ãƒªãƒ«ï¼ˆæœ€åˆã«å®ˆã‚‹ãƒ«ãƒ¼ãƒ«ï¼‰", ""]
    for i in range(1, 351):
        L.append(f"- N{i:03d}: softmax / log / sqrtm ã§ä¸€ç•ªæœ€åˆã«å…¥ã‚Œã‚‹é˜²å¾¡ã¯ï¼Ÿ")
        L.append("  A: `max` ã‚’å¼•ãã€`eps` ã‚’è¶³ã™ã€å¯¾ç§°åŒ–ã—ã¦å›ºæœ‰å€¤ã‚’ä¸‹ã‹ã‚‰ã‚¯ãƒªãƒƒãƒ—ã™ã‚‹ã€‚")

    L += [
        "",
        "---",
        "",
        "## å‚è€ƒæ–‡çŒ®",
        "",
        "[^1]: <https://arxiv.org/abs/1706.08500>",
        "[^2]: <https://arxiv.org/abs/1406.2661>",
        "[^3]: <https://arxiv.org/abs/1701.07875>",
        "[^4]: <https://arxiv.org/abs/1711.10337>",
        "[^5]: <https://arxiv.org/abs/1601.00670>",
        "",
    ]
    L += [
        "## è‘—è€…ãƒªãƒ³ã‚¯",
        "- Blog: https://fumishiki.dev",
        "- X: https://x.com/fumishiki",
        "- LinkedIn: https://www.linkedin.com/in/fumitakamurakami",
        "- GitHub: https://github.com/fumishiki",
        "- Hugging Face: https://huggingface.co/fumishiki",
        "",
        "## ãƒ©ã‚¤ã‚»ãƒ³ã‚¹",
        "- CC BY-NC-SA 4.0",
    ]
    return L


def main() -> None:
    write_lines(ARTICLES / "ml-lecture-03-part2.md", build_lec03_part2())
    write_lines(ARTICLES / "ml-lecture-07-part2.md", build_lec07_part2())


if __name__ == "__main__":
    main()
